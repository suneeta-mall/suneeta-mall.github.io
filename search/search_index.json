{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Random Musings","text":"<p>Random musings of a curious engineer and data scientist exploring the intersection of technology, science, and creativity.</p>"},{"location":"#featured-content","title":"Featured Content","text":""},{"location":"#latest-book-release","title":"Latest Book Release","text":"<p>Deep Learning at Scale - An O'Reilly Book</p> <p>I am thrilled to announce the release of \"Deep Learning at Scale: At the Intersection of Hardware, Software, and Data\" - an O'Reilly Book! This project represents over 2 years of work with my team at O'Reilly media.</p> <p>\"Deep Learning at Scale: At the Intersection of Hardware, Software, and Data\" (O'Reilly) by Suneeta Mall illustrates complex concepts of full stack deep learning and reinforces them through hands-on exercises to arm you with tools and techniques to scale your project. A scaling effort is only beneficial when it's effective and efficient. To that end, this guide explains the intricate concepts and techniques that will help you scale effectively and efficiently.</p> <p></p>"},{"location":"#order-your-copy-today","title":"Order your copy today","text":"<p>Kindle Edition</p> <p> Amazon US |  Amazon AU</p> <p>Paperback Edition</p> <p> Amazon US |  Amazon AU</p> <p>30 Days Trial Access</p> <p>30 days trial - </p> <p>For more information, see details in the project</p>"},{"location":"#recent-blog-posts","title":"Recent Blog Posts","text":"<p>Latest Articles</p> <ul> <li>May 10, 2025 - Curious Cassie 2.0: Revolutionizing Children's Education Through AI-Powered Storytelling</li> <li>May 30, 2024 - Deep Learning at Scale</li> <li>January 07, 2024 - ChatGPT vs Me: As a Children's Authors</li> </ul>"},{"location":"#featured-projects","title":"Featured Projects","text":"<p>Explore My Work</p> <ul> <li>Deep Learning at Scale</li> <li>Label Noise with Clean Lab</li> <li>Reproducible ML</li> </ul>"},{"location":"#upcoming-talks","title":"Upcoming Talks","text":"<p>Speaking Engagements</p> <ul> <li>Knowledge Graph Conference 2022</li> <li>KubeCon NA 2021</li> <li>Kafka Summit APAC 2021</li> </ul>"},{"location":"#connect-with-me","title":"Connect With Me","text":"<p>Let's Connect</p> <ul> <li> LinkedIn</li> <li> GitHub</li> <li> Twitter</li> <li> Medium</li> <li> Google Scholar</li> <li> ResearchGate</li> <li> Email</li> </ul>"},{"location":"#subscribe-to-updates","title":"Subscribe to Updates","text":"<p>Stay Updated</p> <p>Subscribe to my newsletter to receive updates about new articles, projects, and speaking engagements.</p> <p> RSS Feed</p>"},{"location":"about/","title":"About Me","text":""},{"location":"about/#current-role","title":"Current Role","text":"<p>As Head of AI Engineering at harrison.ai, I lead teams developing breakthrough AI solutions that transform healthcare delivery across radiology and pathology. My work has created impact at scale\u2014from pioneering Harrison.rad.1 (radiology's first foundation model) to deploying AI systems serving millions of patients in over 1,000 healthcare facilities worldwide.</p> <p>I believe that \"Transforming a formidable vision into reality by serving the team with empathy, courage, and action is leadership.\" This philosophy guides my approach to solving complex challenges through collaborative innovation. Whether developing regulatory-cleared medical AI solutions, authoring \"Deep Learning at Scale\" (O'Reilly), or mentoring the next generation of technologists, I remain focused on creating technology that genuinely improves lives.</p> <p>My career spans pioneering research, enterprise AI scaling at Nearmap, and now healthcare transformation\u2014all united by a commitment to technical excellence, responsible innovation, and building diverse teams that challenge each other toward better outcomes.</p>"},{"location":"about/#featured-publications-books","title":"Featured Publications &amp; Books","text":""},{"location":"about/#books","title":"Books","text":"<ul> <li>Deep Learning at Scale: At the Intersection of Hardware, Software, and Data, 2024 by O'reilly Media</li> <li>Curious Cassie's Beach Ride Quest 2023</li> <li>IBM Redbooks: Creating Plugins for Lotus Notes, Sametime, and Symphony. IBM RedBook 2011</li> <li>Face-Off: collection of 21 self-composed poems. Poems, 2009</li> </ul>"},{"location":"about/#key-publications","title":"Key Publications","text":"<ul> <li>Can a Machine Learn from Radiologists' Visual Search Behaviour and Their Interpretation of Mammograms\u2014a Deep-Learning Study. Journal of Digital Imaging 2019</li> <li>Missed cancer and visual search of mammograms: what feature-based Machine Learning can tell us that deep-convolution learning cannot. SPIE Medical Imaging 2019</li> <li>Can digital breast tomosynthesis perform better than standard digital mammography work-up in breast cancer assessment clinic? European Radiology 2018</li> <li>A deep (learning) dive into visual search behaviour of breast radiologists. SPIE Medical Imaging 2018</li> <li>Modeling visual search behavior of breast radiologists using a deep convolution neural network. SPIE Journal of Medical Imaging, 2018</li> </ul>"},{"location":"about/#patents","title":"Patents","text":"<ul> <li>Display of information in computing devices, 2013</li> </ul>"},{"location":"about/#education-research","title":"Education &amp; Research","text":""},{"location":"about/#education","title":"Education","text":"<ul> <li>University of Sydney, 2019, Doctor of Philosophy. (Medical Image Optimisation and Perception/Breast Cancer/Machine Learning/Radiology)</li> <li>University of Sydney, 2015, Master of Applied Science (by research), Medical Image Optimisation and Perception.</li> <li>Harcourt Butler Technological Institute, Kanpur, India, 2007, Bachelor of Technology (BTech) Computer Science and Engineering.</li> </ul>"},{"location":"about/#thesis","title":"Thesis","text":"<ul> <li>Modelling the interpretation of digital mammography using high order statistics and deep machine learning</li> </ul>"},{"location":"about/#additional-publications","title":"Additional Publications","text":""},{"location":"about/#academic-publications","title":"Academic Publications","text":"<ul> <li>Modelling the interpretation of digital mammography using high order statistics and deep machine learning. University of Sydney, 2018</li> <li>Fixated and Not Fixated Regions of Mammograms  A Higher-Order Statistical Analysis of Visual Search Behavior. Academic radiology 2017</li> <li>The role of digital breast tomosynthesis in the breast assessment clinic: a review. Journal of Medical Radiation Science, 2017</li> <li>Implementation and value of using a split-plot reader design in a study of digital breast tomosynthesis in a breast cancer assessment clinic. SPIE  Medical Imaging 2015</li> </ul>"},{"location":"about/#technical-publications","title":"Technical Publications","text":"<ul> <li>Automated voice marking of a data/voice streams basing on end users profile and related data. ip.com 2012</li> <li>Folksonomic approach to security systems. ip.com 2011</li> <li>System and method to automatically provide optimal content based on vision and eye movement. ip.com 2011</li> <li>Mechanism to conduct a whiteboard based conference session using gyroscopic enabled mobile devices. ip.com 2011</li> <li>Acceptability indicators in emails. ip.com 2011</li> <li>An optimized human face detection and feature extraction algorithm. ip.com 2010</li> </ul>"},{"location":"about/#teaching-courses","title":"Teaching &amp; Courses","text":""},{"location":"about/#published-courses","title":"Published Courses","text":"<ul> <li>Reproducible Deep Learning is published on O'reilly platform as an interactive katacoda scenario series. It is four parts course:<ul> <li>Reproducible Deep Learning: Semantic Segmentation on Oxford Pets Dataset</li> <li>Reproducible Deep Learning: Identifying the Reproducibility Challenge</li> <li>Reproducible Deep Learning: Random Seeds and Process-Parallelism</li> <li>Reproducible Deep Learning: Achieving 100% Reproducibility</li> </ul> </li> </ul>"},{"location":"about/#external-content","title":"External Content","text":""},{"location":"about/#blogs","title":"Blogs","text":"<ul> <li>Suneeta@Towards Data Science</li> </ul>"},{"location":"tags/","title":"Content Tags","text":"<p>This page provides an overview of all tags used across the content. Click on any tag to see all content tagged with it.</p>"},{"location":"tags/#content-types","title":"Content Types","text":"<ul> <li>blog - Blog posts and articles</li> <li>project - Project showcases and documentation</li> <li>talk - Conference talks and presentations</li> <li>poem - Poetry and creative writing</li> <li>children-book - Children's literature</li> </ul>"},{"location":"tags/#topics","title":"Topics","text":"<ul> <li>machine-learning - Machine learning concepts and applications</li> <li>deep-learning - Deep learning and neural networks</li> <li>kubernetes - Kubernetes and container orchestration</li> <li>reproducibility - Reproducible research and ML pipelines</li> <li>data-science - Data science and analytics</li> <li>feature-analysis - Feature analysis and visualization</li> <li>clean-lab - Clean Lab and data quality</li> <li>chatgpt - ChatGPT and AI applications</li> <li>children-literature - Children's books and stories</li> </ul>"},{"location":"tags/#technical","title":"Technical","text":"<ul> <li>python - Python programming</li> <li>tensorflow - TensorFlow framework</li> <li>hydra - Hydra configuration</li> <li>pydantic - Pydantic data validation</li> <li>tsne - t-SNE visualization</li> <li>umap - UMAP dimensionality reduction</li> <li>k8s - Kubernetes</li> </ul>"},{"location":"tags/#experience-level","title":"Experience Level","text":"<ul> <li>beginner - Beginner-friendly content</li> <li>intermediate - Intermediate level content</li> <li>advanced - Advanced topics and concepts </li> </ul>"},{"location":"tags/#advanced","title":"advanced","text":"<ul> <li>Data in Deep Learning</li> <li>Deep Learning at Scale</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#ai","title":"ai","text":"<ul> <li>Life of AI Engineer</li> <li>Singularity</li> </ul>"},{"location":"tags/#beginner","title":"beginner","text":"<ul> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Life of AI Engineer</li> <li>Curious Cassie Books</li> </ul>"},{"location":"tags/#blog","title":"blog","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>Data in Deep Learning</li> <li>Hydra Pydantic Config Management</li> <li>Confident Learning and Clean Data</li> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#children-book","title":"children-book","text":"<ul> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Curious Cassie Books</li> </ul>"},{"location":"tags/#children-literature","title":"children-literature","text":"<ul> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Curious Cassie Books</li> </ul>"},{"location":"tags/#clean-lab","title":"clean-lab","text":"<ul> <li>Confident Learning and Clean Data</li> </ul>"},{"location":"tags/#data-science","title":"data-science","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>Data in Deep Learning</li> <li>Confident Learning and Clean Data</li> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Feature Analysis</li> <li>Knowledge Graph Conference 2022</li> </ul>"},{"location":"tags/#deep-learning","title":"deep-learning","text":"<ul> <li>Data in Deep Learning</li> <li>Deep Learning at Scale</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#feature-analysis","title":"feature-analysis","text":"<ul> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Feature Analysis</li> </ul>"},{"location":"tags/#hydra","title":"hydra","text":"<ul> <li>Hydra Pydantic Config Management</li> </ul>"},{"location":"tags/#intermediate","title":"intermediate","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>Hydra Pydantic Config Management</li> <li>Confident Learning and Clean Data</li> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Singularity</li> <li>Feature Analysis</li> <li>AWS Community Day 2020</li> <li>Knowledge Graph Conference 2022</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#k8s","title":"k8s","text":"<ul> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>AWS Community Day 2020</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#kubernetes","title":"kubernetes","text":"<ul> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>AWS Community Day 2020</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#machine-learning","title":"machine-learning","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>Data in Deep Learning</li> <li>Hydra Pydantic Config Management</li> <li>Confident Learning and Clean Data</li> <li>Deep Learning at Scale</li> <li>Life of AI Engineer</li> <li>Singularity</li> <li>Feature Analysis</li> <li>Deep Learning at Scale</li> <li>Knowledge Graph Conference 2022</li> </ul>"},{"location":"tags/#poem","title":"poem","text":"<ul> <li>Life of AI Engineer</li> <li>Singularity</li> </ul>"},{"location":"tags/#project","title":"project","text":"<ul> <li>Curious Cassie Books</li> <li>Feature Analysis</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#pydantic","title":"pydantic","text":"<ul> <li>Hydra Pydantic Config Management</li> </ul>"},{"location":"tags/#python","title":"python","text":"<ul> <li>Hydra Pydantic Config Management</li> </ul>"},{"location":"tags/#reproducibility","title":"reproducibility","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> </ul>"},{"location":"tags/#talk","title":"talk","text":"<ul> <li>AWS Community Day 2020</li> <li>Knowledge Graph Conference 2022</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#tensorflow","title":"tensorflow","text":"<ul> <li>Reproducible ML with TensorFlow</li> </ul>"},{"location":"tags/#tsne","title":"tsne","text":"<ul> <li>Feature Analysis - t-SNE vs UMAP</li> </ul>"},{"location":"tags/#umap","title":"umap","text":"<ul> <li>Feature Analysis - t-SNE vs UMAP</li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2019/09/10/links-to-open-source-ml-datasets/","title":"Links to open source ML datasets","text":"<ul> <li>Google Dataset Search</li> <li>[Wikipedia ML dataset]</li> <li>Pathmind's aggregation</li> <li>[Computer Vision Online] aggregated source</li> <li>20 Multimedia dataset (images &amp; videos)</li> <li>[Hackernoon Rare dataset]</li> <li>Analytics vidhya's list of 25 sets</li> </ul> <p>[Wikipedia ML dataset]: https://en.wikipedia.org/wiki/List_of_datasets_for_Machine Learning_research</p> <p>[Hackernoon Rare dataset]: https://hackernoon.com/rare-datasets-for-computer-vision-every-Machine Learning-expert-must-work-with-2ddaf52ad862</p>"},{"location":"blog/2019/12/01/reading-book-list/","title":"Reading book list","text":"<p>This list includes books that a) I have truly enjoyed reading and highly admire or b) Eagerly  looking forward to reading. It has six sections:</p> <ul> <li>Abstract Programming/AI</li> <li>Kubernetes</li> <li>Machine Learning, AI, Deep Learning</li> <li>Statistics</li> <li>Parenting</li> <li>Miscellaneous</li> </ul>"},{"location":"blog/2019/12/01/reading-book-list/#1-abstract-programming","title":"1. Abstract Programming","text":"<p> Real-World Bug Hunting Authored by Peter Yaworski</p> <p> Code: The Hidden Language of Computer Hardware and Software Authored by Charles Petzold</p> <p> The Pragmatic Programmer: your journey to mastery Authored by Andrew Hunt, David Thomas</p> <p> Coders at Work: Reflections on the Craft of Programming Authored by Peter Seibel</p> <p> The Book of Why: The New Science of Cause and Effect Authored by Judea Pearl</p> <p> Clean Code  Authored by Robert C. Martin</p>"},{"location":"blog/2019/12/01/reading-book-list/#2-kubernetes","title":"2. Kubernetes","text":"<p> Kubernetes: Up and Running Authored by Kelsey Hightower, Joe Beda, Brendan Burns</p> <p> *Kubernetes Security Authored by Michael Hausenblas, Liz Rice *</p> <p> *Container Security Authored by Liz Rice *</p> <p> Kubernetes for Developers Authored by Joseph Heck</p>"},{"location":"blog/2019/12/01/reading-book-list/#3-machine-learning-ai-deep-learning","title":"3. Machine Learning, AI, Deep Learning","text":"<p> The Quest for Artificial Intelligence: A History of Ideas and Achievements Authored by Nils J. Nilsson*</p> <p> [Machine Learning: A Probabilistic Perspective] Authored by Kevin P Murphy</p> <p> Neural Networks and Deep Learning  Authored by Michael Nielsen</p> <p> [Deep Learning] Authored by Ian Goodfellow et al.</p> <p> [Machine Learning Yearning] Authored by Andrew Ng</p>"},{"location":"blog/2019/12/01/reading-book-list/#4-statistics","title":"4. Statistics","text":"<p> Linear Algebra Done Right, Authored by Sheldon Axler</p> <p> Mathematical Statistics and Data Analysis, Authored by John A. Rice</p> <p> Elements of Statistical Learning, Authored by Trevor Hastie et al.</p> <p> Introduction to Statistical Learning  Authored by Trevor Hastie et al.</p>"},{"location":"blog/2019/12/01/reading-book-list/#5-parenting","title":"5. Parenting","text":"<p> Becoming Brilliant: What Science Tells Us About Raising Successful Children Authored by Roberta Golinkoff, Kathryn Hirsh-Pasek</p> <p> Thinking Parent, Thinking Child: Turning Everyday Problems into Solutions Authored by Myrna B. Shure</p> <p> The Psychology of Babies: How relationships support development from birth to two Authored by Lynne Murray </p>"},{"location":"blog/2019/12/01/reading-book-list/#6-miscellaneous","title":"6. Miscellaneous","text":"<p> The End of Ice: Bearing Witness and Finding Meaning in the Path of Climate Disruption Authored by Dahr Jamail</p> <p> The Second Kind of Impossible: The Extraordinary Quest for a New Form of Matter Authored by Paul Steinhardt</p> <p>[Machine Learning: A Probabilistic Perspective]: https://www.amazon.com.au/Machine Learning-Probabilistic-Kevin-Murphy/dp/0262018020</p> <p>[Machine Learning Yearning]: https://www.deeplearning.ai/Machine Learning-yearning/</p>"},{"location":"blog/2019/12/20/reproducibility-in-machine-learning-blog-series/","title":"Reproducibility in Machine Learning blog series","text":"<p>This technical blog series titled \"Reproducibility in Machine Learning\" is going to be divided into three parts: 1. Reproducibility in Machine Learning - Research and Industry 2. Realizing reproducible Machine Learning - with Tensorflow  3. End-to-end reproducible Machine Learning pipelines on Kubernetes</p> <p>Some of the content of this blog series has been covered in KubeCon US 2019 - a Kubernetes conference 2019. Details of this talk can be found here with recording available here.  </p>"},{"location":"blog/2019/12/20/reproducibility-in-machine-learning-blog-series/#part-1-reproducibility-in-machine-learning-research-and-industry","title":"Part 1: Reproducibility in Machine Learning - Research and Industry","text":"<p>In Part 1, the objective will be to discuss the importance of reproducibility in machine learning. It will also cover where both research and industry are stand in writing reproducible ML. This blog can be accessed here.</p>"},{"location":"blog/2019/12/20/reproducibility-in-machine-learning-blog-series/#part-2-realizing-reproducible-machine-learning-with-tensorflow","title":"Part 2: Realizing reproducible Machine Learning - with Tensorflow","text":"<p>The focus of Part 2 will be writing reproducible machine learning code. Tensorflow is being used as a machine learning stack for demonstration purposes. This blog can be accessed here. </p>"},{"location":"blog/2019/12/20/reproducibility-in-machine-learning-blog-series/#part-3-end-to-end-reproducible-machine-learning-pipelines-on-kubernetes","title":"Part 3: End-to-end reproducible Machine Learning pipelines on Kubernetes","text":"<p>Part 3 is all about realizing end-to-end machine learning pipelines on kubernetes. This blog can be accessed here.</p>"},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/","title":"Reproducibility in Machine Learning - Research and Industry","text":"<p>This is Part 1 - Reproducibility in Machine Learning - Research and Industry of technical blog series titled [Reproducibility in Machine Learning]. Part 2 &amp; Part 3 can be found here &amp; here respectively.      </p> <p>Machine learning (ML) is an interesting field aimed at solving problems that can not be solved by applying deterministic logic.  In fact, ML solves problems in logits [0, 1] with probabilities! ML is a highly iterative and fiddly field with much of its intelligence derived from data upon application of complex mathematics.  Sometimes, even a slight change such as changing the order of input/data can change the outcome of ML processes drastically. Actually xkcd quite aptly puts it:</p> <p> Figure 1: Machine Learning explained by XKCD</p> <p>This phenomenon is explained as Change Anything Changes Everything a.k.a. CAKE principle coined by Scully et. al  in their NIPS 2015 paper titled [\"Hidden Technical Debt in Machine Learning Systems\"][scully_2015].  CAKE principle highlights that in ML - no input is ever really independent. </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#what-is-reproducibility-in-ml","title":"What is reproducibility in ML","text":"<p>Reproducibility as per the Oxford dictionary is defined as something that can be produced again in the same way.  Figure 2: Reproducible defined</p> <p>In ML context, it relates to getting the same output on the same algorithm, (hyper)parameters, and data on every run. </p> <p>To demonstrate, let's take a simple linear regression example (shown below) on Scikit Diabetes Dataset.  Linear regression is all about fitting a line i.e. <code>Y = a + bX</code> over data-points represented as X, with b being the  slope and a being the intercept.  <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\ndiabetes = datasets.load_diabetes()    \ndiabetes_X = diabetes.data[:, np.newaxis, 9]\nxtrain, xtest, ytrain, ytest = train_test_split(diabetes_X, diabetes.target, test_size=0.33)\nregr = linear_model.LinearRegression()\nregr.fit(xtrain, ytrain)\ndiabetes_y_pred = regr.predict(xtest)\n\n# The coefficients \nprint(f'Coefficients: {regr.coef_[0]}\\n'\n      f'Mean squared error: {mean_squared_error(ytest, diabetes_y_pred):.2f}\\n'\n      f'Variance score: {r2_score(ytest, diabetes_y_pred):.2f}')\n# Plot outputs \nplt.scatter(xtest, ytest,  color='green')\nplt.plot(xtest, diabetes_y_pred, color='red', linewidth=3)\nplt.ylabel('Quantitative measure of diabetes progression')\nplt.xlabel('One of six blood serum measurements of patients')\nplt.show()\n</code></pre> A linear regression example on Scikit Diabetes Dataset</p> <p>Above ML code is NOT reproducible. Every run will give different results: a) The data distribution will vary and  b) Obtained slop and intercept will vary. See Figure 3.</p> <p> Figure 3: Repeated run of above linear regression code produces different results </p> <p>In the above example, we are using the same dataset, same algorithm, same hyper-parameters. So why are we getting different results?  Here the method <code>train_test_split</code> splits the diabetes dataset into training and test but while doing so, it performs a random shuffle of the dataset.  The seed for this random shuffle is not set here. Because of this, every run produces different training dataset distribution.  Due to this, the regression line slope and intercept ends up being different. In this simple example, if we were to set a random state for method <code>train_test_split</code> e.g. <code>random_state=42</code> then we will have a reproducible regression example over the diabetes dataset. The reproducible version of the above regression example is as follows:</p> <p><pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\ndiabetes = datasets.load_diabetes()    \ndiabetes_X = diabetes.data[:, np.newaxis, 9]\nxtrain, xtest, ytrain, ytest = train_test_split(diabetes_X, diabetes.target, test_size=0.33,\n                                                random_state=42)\nregr = linear_model.LinearRegression()\nregr.fit(xtrain, ytrain)\ndiabetes_y_pred = regr.predict(xtest)\n\n# The coefficients \nprint(f'Coefficients: {regr.coef_[0]}\\n'\n      f'Mean squared error: {mean_squared_error(ytest, diabetes_y_pred):.2f}\\n'\n      f'Variance score: {r2_score(ytest, diabetes_y_pred):.2f}')\n# Plot outputs \nplt.scatter(xtest, ytest,  color='green')\nplt.plot(xtest, diabetes_y_pred, color='red', linewidth=3)\nplt.ylabel('Quantitative measure of diabetes progression')\nplt.xlabel('One of six blood serum measurements of patients')\nplt.show()\n</code></pre> A reproducible linear regression example on Scikit Diabetes Dataset</p> <p>Seeding random state is not the only challenge in writing reproducible ML. In fact, there are several reasons why reproducibility in ML is so hard to achieve. But I will go into that a bit later in section <code>Challenges in realizing reproducible ML</code>.  The first question should be  \"why reproducibility matters in ML\"? </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#importance-of-reproducibility-in-ml","title":"Importance of reproducibility in ML","text":"<p>Non-reproducible single occurrences are of no significance to science. <sub>- Popper (The Logic of Scientific Discovery)</sub></p> <p>The importance of reproducibility is increasingly getting recognized since Nature's Survey (2016) reported a <code>reproducibility crisis</code>.  As per this survey report, 70% of researchers have failed to reproduce another scientist's experiments, and  more than 50% have failed to reproduce their own experiments. With more than half of participating scientist agreeing to  the presence of reproducibility crisis is indeed very real. Dr. Joelle Pineau, an Associate Professor at McGill University and lead for  Facebook's Artificial Intelligence Research lab, covered the reproducibility crisis in her talk at  International Conference on Learning Representations (ICLR) 2018 you tube. She is determined to nip this crisis in bud from AI research<sup>src</sup>. It's not just her, several AI research groups are coming up with measures to ensure reproducibility (example below): - Model Card at Google - Reproducibility Checklist at NeurIPS  - ICLR Reproducibility Challenge at ICLR - Show your work at Allen Institute of Artificial Intelligence</p> <p>Aside from being of <code>no use if can't be reproduced</code>, as Popper suggested in the above quote, why does reproducibility matter?</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#1-understanding-explaining-debugging-and-reverse-engineering","title":"1. Understanding, Explaining, Debugging, and Reverse Engineering","text":"<p>Reproducibility helps with understanding, explaining, and debugging. Reproducibility is also a crucial means to reverse engineering.</p> <p>Machine learning is inherently difficult to explain, understand, and also debug. Obtaining different output on the subsequent run just makes this whole understanding, explaining, debugging thing all the more challenging. How do we ever reverse engineer?  As it is, understanding and explaining are hard with machine learning. It's increasingly harder with deep learning.  For over a decade, researches are have been trying to understand what these deep networks learn and yet have not 100% succeeded in doing so.  </p> <p>From visualizing higher layer features of deep networks year 2009 to activation-atlases i.e.  what individual neurons in deep network do year 2017 to understanding how deep networks decides  year 2018 - are all ongoing progressive efforts towards understanding. Meanwhile, explainability  has morphed into a dedicated field 'Explainable Artificial Intelligence XAI. </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#2-correctness","title":"2. Correctness","text":"<p>If anything can go wrong, it will <sub>-Murphy's law</sub></p> <p>Correctness is important as Murphy's law rarely fails us. These are some of the examples of great AI failures of our times. Figure 4: Example of some of the great AI failures of our times</p> <p>Google Photos launched AI capabilities with automatically tagging images. It was found to be tagging people of dark skin as gorillas.  Amazon's recruiting software exhibiting gender bias or even IBM's Watson giving unsafe recommendations for cancer treatment. </p> <p>ML output should be correct in addition to being explainable. Reproducibility helps to achieve correctness through understanding and debugging.   </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#3-credibility","title":"3. Credibility","text":"<p>ML output must be credible. It's not just from a fairness, ethical viewpoint but also because they sometimes impact lives (e.g. mortgage approval). Also, end-users of ML output expect answers to verifiable, reliable, unbiased, and ethical. As Lecun said in his International Solid State Circuit Conference in San Francisco, 2019 keynote:</p> <p>Good results are not enough, Making them easily reproducible also makes them credible. <sub>- Lecun, ISSCC 2019</sub></p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#4-extensibility","title":"4. Extensibility","text":"<p>Reproducibility in preceding layers is needed to build out and extend. Can we build a building outline model if we cant repeatedly generate roof semantics as shown in figure 5? What if we keep getting the different size for the same roof?  Figure 5: Extending ML</p> <p>Extensibility is essential to utilizing ML outputs for consumption. As it is, raw outputs from ML are rarely usable by end-user. Most ML outputs need to be post-processed and augmented to be consumption ready. </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#4-data-harvesting","title":"4. Data harvesting","text":"<p>The world's most valuable resource is no longer oil, but data! <sub>- economist.com</sub></p> <p>To train a successful ML algorithm large dataset is mostly needed - this is especially true for deep-learning.  Obtaining large volumes of training data, however, is not always easy - it can be quite expensive. In some cases  the occurrences of the scenario can be so rare that obtaining a large dataset will either take forever or is simply not possible.  For eg. dataset for Merkel-cell carcinoma, a type of skin cancer that's very rare,  will be very challenging to procure.</p> <p>For this reason, data harvesting a.k.a. synthetic data generation is considered.  Tirthajyoti Sarkar, the author of Data Wrangling with Python: Creating actionable data from raw sources, wrote  an excellent post on data harvesting using scikit that covers this topic in detail.  However, more recently, Generative Adversarial Networks (GAN) by Ian Goodfellow is being heavily used for this purpose. Synthetic Data for Deep Learning is an excellent review article that covers this topic in detail for deep-learning.</p> <p>Give ML models e.g. (GAN) are being used to generate training data now, it's all the more important that reproducibility in such application is ensured. Let's say, we trained a near-perfect golden goose model on data  (including some synthetic). But the storage caught proverbial fire, and we lost this golden goose model along with data. Now, we have to regenerate the synthetic data and obtain the same model but the synthetic data generation process is not quite reproducible. Thus, we lost the golden goose! </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#challenges-in-realizing-reproducible-ml","title":"Challenges in realizing reproducible ML","text":"<p>Reproducible ML does not come in easy. A wise man once said:</p> <p>When you want something, all the universe conspires in helping you to achieve it. <sub>- The Alchemist by Paulo Coelho</sub></p> <p>But when it comes to reproducible ML it's quite the contrary. Every single resource and techniques  (Hardware, Software, Algorithms, Process &amp; Practice, Data) needed to realize ML poses some kind of challenge in meeting  reproducibility (see figure 6).</p> <p> Figure 6: Overview of challenges in reproducible ML</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#1-hardware","title":"1. Hardware","text":"<p>ML algorithms are quite compute hungry. Complex computation needed by ML operation, now a day's runs in order of Giga/Tera floating-point operations (GFLOPS/TFLOPS). Thus needing high parallelism and multiple central processing Units (CPU)  if not, specialized hardware such as (general purpose) graphics processing unit (GPU) or more specifically (GPGPU),  tensor processing unit (TPU) etc. to complete in the reasonable time frame.  </p> <p>But these efficiencies in floating-point computations both at CPU &amp; GPU level comes at a cost of reproducibility. </p> <ul> <li>CPU</li> </ul> <p>Using Intra-ops (within an operation) and inter-ops (amongst multiple operations) parallelism on CPU can sometimes give different results on each run. One such example is using OpenMP for (intra-ops) parallelization. See this excellent talk titled \"Corden's Consistency of Floating Point Results or Why doesn't my application always give\"  Corden 2018 for more in-depth insight into this. Also see wandering precision blog.</p> <ul> <li>GPU</li> </ul> <p>General purpose GPUs can perform vector operations due to stream multiprocessing (SEM) unit. The asynchronous computation performed by this unit may result in different results on different runs. Floating multiple adders (FMAD) or even reductions in floating-point operands are  such examples. Some algorithms e.g. vector normalization, due to reduction operations, can also be non-reproducible. See reproducible summation paper for more info.  </p> <p>Changing GPU architecture may lead to different results too. The differences in SEM, or architecture-specific optimizations  are a couple of reasons why the differences may arise.</p> <p>See Corden's Consistency of Floating-Point Results or Why doesn't my application always give the same answer for more details.</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#2-software","title":"2. Software","text":"<p>It's not just hardware. Some software's offering high-level abstraction or APIs for performing intensive computation do not guarantee reproducibility in their routines. For instance NVIDIA's popular cuda based deep learning library cudnn do not guarantee reproducibility in some of their routines e.g. cudnnConvolutionBackwardFilter&gt;sup&gt;ref. Popular deep learning libraries such as  tensorflow<sup>ref 1,ref 2</sup>, pytorch<sup>ref</sup>  also do not guarantee 100% reproducibility.  </p> <p>There is an excellent talk Duncan Riach, maintainer of tensorflow_determinism on Determinism in deep learning presented at GPU technology conference by NVIDIA 2019</p> <p>Sometimes it's not just a trade-off for efficiency but simple software bugs that lead to non-reproducibility. One such example is this bug  that I ran into resulting in different geo-location upon same computation when a certain library version was upgraded. This is a clear case of software bug but underlines the fact that reproducibility goes beyond just computation, and precision.</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#3-algorithm","title":"3. Algorithm","text":"<p>Several ML algorithms can be non-reproducible due to the expectation of randomness. Few examples of these algorithms are dropout layers, initialization. Some algorithms can be non-deterministic due to underlined computation complexity requiring non-reproducible measures similar to ones discussed in the software section. Some example of these are e.g. vector normalization, backward pass.</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#4-process-practice","title":"4. Process &amp; Practice","text":"<p>ML loves randomness! </p> <p> Figure 7: Randomness defined by xkcd</p> <p>When things don't work with ML - we randomize (pun intended). We have randomness everywhere -  from algorithms to process and practices for instance: - Random initializations  - Random augmentations - Random noise introduction (adversarial robustness) - Data Shuffles</p> <p>To to ensure that randomness is seeded and can be reproduced (much like earlier example of scikit linear regression), with python,  a long list of seed setting ritual needs to be performed: <pre><code>os.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\ntensorflow.random.set_seed(seed)\nnumpy.random.seed(seed)\ntensorflow.keras.layers.Dropout(x, seed=SEED)\ntensorflow.image.random_flip_left_right(x, seed=seed)\ntensorflow.random_normal_initializer(x, y, seed=seed)\n# many such algorithmic layers as aabove \n</code></pre></p> <p>Can we ever win with this seed setting? </p> <p> Figure 8: Seed setting (image credit: google)</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#5-data","title":"5. Data","text":"<p>No input is ever really independent. <sub>[Scully et. al 2015][scully_2015]</sub></p> <p>Data is the main input to ML algorithms and these algorithms are just compute hungry but also data-hungry. So we are  really talking about big data. When data volume is large, we are dealing with all sorts of challenges: - Data management - Data provenance - Data poisoning - Under-represented data (inappropriate  demographic) - Over-represented data (inappropriate  demographic)</p> <p>One of the reasons why ML is so iterative because we need to evolve the ML algorithm with data whilst also continuously evolving data (e.g.  data massaging, feature engineering, data augmentations). That's why data provenance is important but it's also important to maintain a linage with data provenance to ML processes. In short, an end to end provenance is needed with ML processes.      </p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/21/reproducible-ml-research-in-industry/#6-concept-drift","title":"6. Concept drift","text":"<p>A model is rarely deployed twice. <sub>[Talby, 2018][Talby]</sub></p> <p>One of the reason for why a model rarely gets deployed more than once <sup>[ref][Talby]</sup> is <code>Concept drift</code>. Our concept of  things and stuff keeps evolving. Don't believe me? figure 9 shows how we envisaged car 18's to now. Our current evolving impression of the car is solar power self-driving cars!</p> <p> Figure 9: Our evolving concept of <code>car</code></p> <p>So, now we don't just have to manage reproducibility over one model but many! Because our model needs to continually keep learning in a more commonly known term in ML as <code>Continual learning</code> more info. An interesting review paper on this topic is here.</p> <p> Figure 10: Top features - Dresner Advisory Services Data Science and Machine Learning Market Study</p> <p>In fact, Continual learning is so recognized that support for easy iteration &amp; continuous improvement were the top two features industry voted as their main focus with ML as per Dresner Advisory Services'6<sup>th</sup> annual 2019 Data Science and Machine Learning Market Study (see figure 10).</p> <p>The next part of this technical blog series, [Reproducibility in Machine Learning], is Realizing reproducible Machine Learning - with Tensorflow.       </p> <p>[Reproducibility in Machine Learning]: /2019/12/20/Reproducibility-in-Machine Learning.html</p> <p>[scully_2015]: https://papers.nips.cc/paper/5656-hidden-technical-debt-in-Machine Learning-systems.pdf</p> <p>[Talby]: https://www.oreilly.com/radar/lessons-learned-turning-Machine Learning-models-into-real-products-and-services/</p>","tags":["blog","data-science","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/","title":"Realizing reproducible Machine Learning - with Tensorflow","text":"<p>This is Part 2 - Realizing reproducible Machine Learning - with Tensorflow of technical blog series titled [Reproducibility in Machine Learning]. Part 1 &amp; Part 3 can be found here &amp; here respectively.      </p> <p>As discussed in Part 1, writing reproducible machine learning is not easy with challenges arising from every direction e.g. hardware, software, algorithms, process &amp; practice, data. In this post, we will focus on what is needed to ensure  ML code is reproducible.</p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#first-things-first","title":"First things first","text":"<p>There are a few very simple things that are needed to be done before thinking big and focussing on writing reproducible ML code. These are:</p> <ul> <li>Code is version controlled</li> </ul> <p>Same input (data), same process (code) resulting in the same output is the essence of reproducibility. But code keeps evolving, since ML is so iterative. Hence, it's important to version control code (including configuration). This allows obtaining the same  i.e. exact code (commit/version) from the source repository.  </p> <ul> <li>Reproducible runtime \u2013 pinned libraries </li> </ul> <p>So we version-controlled code but what about environment/runtime? Sometimes, non-determinism is introduced not direct by user code  but also dependencies. We talked about this at length in the software section of <code>Challenges in realizing reproducible ML</code> in Part 1. Taking the example of Pyproj - a geospatial transform library, that I once used to compute geo-location-based on some parameters. We changed nothing but just a version of pyproj from V1.9.6 to V2.4.0 and suddenly all our calculations were giving different results. The difference was so much that location calculation for San Diego Convention Centre was coming out to be somewhere in Miramar  off golf course (see figure 1) issue link. Now imagine ordering pizza delivery on the back of my computation snippet  backed with an unpinned version of pyproj?  </p> <p> Figure 1: Example of why pinned libraries are important</p> <p>Challenges like these occur quite often that we would like. That's why it's important to pin/fix dependent runtime either by pinning version of libraries or using versioned containers (like docker).  </p> <ul> <li>Smart randomness</li> </ul> <p>As discussed in Part 1, randomization plays a key role in most ML algorithms. Unseeded randomness is the simplest  way to make code non-reproducible. It is also one of the easiest to manage amongst all things gotchas of non-reproducible ML.  All we need to do is seed all the randomness and manage the seed via configuration (as code or external). </p> <ul> <li>Rounding precision, under-flows &amp; overflow</li> </ul> <p>Floating point arithmetic is ubiquitous in ML. The complexity and intensity of floating-point operations (FLOPS) are increasing every day with current needs easily meeting Giga-Flops order of computations.  To achieve efficiency in terms of speed despite the complexity, mixed precision  floating-point operations have also been proposed. As discussed Part 1, accelerated hardware such as (GPGPU),  tensor processing unit (TPU), etc. due to their architecture and asynchronous computing do not guarantee reproducibility.  Besides, when dealing with floating points, the issues related to overflow and underflow are expected.  This just adds to the complexity.  </p> <ul> <li>Dependent library's behavior aware </li> </ul> <p>As discussed in the software section of <code>Challenges in realizing reproducible ML</code> in Part 1, some routines of ML libraries  do not guarantee reproducibility. For instance,  NVIDIA's CUDA based deep learning library cudnn. Similarly, with Tensorflow, using some methods may result in non-deterministic behavior. One such example is  backward pass of broadcasting on GPU<sup>ref</sup>. Awareness about behaviors of libraries being used and approaches to overcome the non-determinism should be explored. </p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#writing-reproducible-ml","title":"Writing reproducible ML","text":"<p>To demonstrate reproducible ML, I will be using Oxford Pet dataset that has labels for pet images. I will be doing a semantic segmentation of pets images and will be using pixel-level labeling. Each pixel of the pet image in Oxford Pet dataset is labeled as 1) Foreground (Pet area), 2) Background (not pet area) and 3) Unknown (edges).  These labels by definition are mutually exclusive - i.e. a pixel can only be one of the above 3.   </p> <p> Figure 2: Oxford pet dataset</p> <p>I will be using a convolution neural network (ConvNet) for semantic segmentation. The network architecture is based on U-net.  This is similar to standard semantic segmentation example by tensorflow. </p> <p> Fihure 3: U-net architecture</p> <p>The reproducible version of semantic segmentation is available in Github repository. This example demonstrates reproducible ML and also performing end to end ML with provenance across process and data.   </p> <p> Figure 4: Reproducible ML sample - semantic segmentation of oxford pet</p> <p>In this post, however, I will be discussing only the reproducible ML aspect of it and will be referencing snippets of this example.</p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#ml-workflow","title":"ML workflow","text":"<p>In reality, a machine learning workflow is very complex and looks somewhat similar to figure 5. In this post, however,  we will only discuss the data and model training part of it. The remaining workflow i.e. the end-to-end workflow will be discussed in next post.  </p> <p> Figure 5: Machine learning workflow</p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#data","title":"Data","text":"<p>The source dataset is Oxford Pet dataset which contains a multitude of labels e.g. class outcome, pixel-wise label, bounding boxes, etc. The first step is to process this data to generate the trainable dataset. In the example code, this is done by  download_petset.py script. </p> <p><pre><code>python download_petset.py  --output /wks/petset\n</code></pre> The resulting sample is shown in figure 6.</p> <p> Figure 6: Pets data partitioned by Pets ID</p> <p>Post data partition, the entire dataset is divided into 4 sets: a) training, b) validation, c) calibration, and d) test We would want this set partitioning strategy to be reproducible. By doing this, we ensure that if we have to blow away the training dataset, or if accidental data loss occurs then the exact dataset can be created.</p> <p>In this sample, this is achieved by generating the hash of petid and partitioning the hash into 10 folds (script below) to obtain partition index of pet id. </p> <pre><code>partition_idx = int(hashlib.md5((os.path.basename(petset_id)).encode()).hexdigest(), 16) % 10\n</code></pre> <p>With partition_idx 0-6 assigned for training, 7 for validation, 8 for calibration, and 9 for the test,  every generation will result in pets going into their respective partition. </p> <p>Besides, to set partitioning, any random data augmentation performed is seeded with seed controlled as configuration as code. See <code>tf.image.random_flip_left_right</code> used in this tensorflow data pipeline  method. </p> <p>Script for model dataset preparation is located in  dataset_gen.py and used as following <pre><code>python dataset_gen.py --input /wks/petset --output /wks/model_dataset\n</code></pre> with results shown below:</p> <p> Figure 7: Pets data partitioned into training, validation, calibration, and test set</p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#modelling-semantic-segmentation","title":"Modelling semantic segmentation","text":"<p>The model for pet segmentation is based on U-net with backbone of either MobileNet-v2 or VGG-19 (defaults to VGG-19).  As per this model's network architecture, 5 activation layers of pre-trained backbone network are chosen. These layers are: * MobileNet</p> <pre><code>'block_1_expand_relu' \n'block_3_expand_relu'  \n'block_6_expand_relu' \n'block_13_expand_relu'\n'block_16_project'\n</code></pre> <ul> <li>VGG <pre><code>'block1_pool'\n'block2_pool'\n'block3_pool'\n'block4_pool'\n'block5_pool'\n</code></pre> </li> </ul> <p>Each of these layers is then concatenated with a corresponding upsampling layer comprising of Conv2DTranspose layer forming what's known as skip connection. See model code for more info.</p> <p>The training script train.py can be used as following:</p> <pre><code>python train.py --input /wks/model_dataset --output /wks/model --checkpoint_path /wks/model/ckpts --tensorboard_path /wks/model\n</code></pre>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#1-seeding-randomness","title":"1. Seeding randomness","text":"<p>All methods exploiting randomness is used with appropriate seed. - All random initialization is seeded e.g. tf.random_normal_initializer - All dropout layers are seeded e.g. dropout</p> <p>Global seed is set for any hidden methods that may be using randomness by  calling in  <code>set_seed(seed)</code> which sets seed for used libraries:</p> <pre><code>def set_seeds(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n</code></pre>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#2-handing-library-behaviors","title":"2. Handing library behaviors","text":"","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#21-cudnn","title":"2.1 CuDNN","text":"<p>CuDNN does not guarantee reproducibility in some of its routines.  Environment variable <code>TF_DETERMINISTIC_OPS</code> &amp; <code>TF_CUDNN_DETERMINISTIC</code> can be used to control this behavior as per this  snippet (figure 8) from cudnn release page. </p> <p> Figure 8: NVIDIA release page snippet reproducibility</p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#22-cpu-thread-parallelism","title":"2.2 CPU thread parallelism","text":"<p>As discussed in Part 1, using high parallelism with compute intensive workflow may not be reproducible. Configurations for  inter<sup>ref</sup> and  intra<sup>ref</sup>  operation parallelism should be set if 100% parallelism is desired.</p> <p>In this example, I have chosen 1 to avoid any non-determinism arising from inter-operation parallelism. Warning setting  this  will considerably slow down the training. </p> <pre><code>tf.config.threading.set_inter_op_parallelism_threads(1)\ntf.config.threading.set_intra_op_parallelism_threads(1)\n</code></pre>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#23-tensorflow-determinism","title":"2.3 Tensorflow determinism","text":"<p>Following are some of the application of Tensorflow that are not reproducible: - Backward pass of broadcasting on GPU is non-deterministic<sup>link</sup> - Mention that GPU reductions are nondeterministic in docs<sup>link</sup> - Problems Getting TensorFlow to behave Deterministically<sup>link</sup></p> <p>Duncan Riach, along with several other contributors have created tensorflow_determinism package that can be used to overcome non-reproducibility related challenges from TensorFlow. It should be used in addition to the above measures we have discussed so far.</p> <p>If we combine all the approaches discussed above (aside from using seeded randomness), they can be wrapped into a lightweight  method like one below: <pre><code>def set_global_determinism(seed=SEED, fast_n_close=False):\n    \"\"\"\n        Enable 100% reproducibility on operations related to tensor and randomness.\n        Parameters:\n        seed (int): seed value for global randomness\n        fast_n_close (bool): whether to achieve efficient at the cost of determinism/reproducibility\n    \"\"\"\n    set_seeds(seed=seed)\n    if fast_n_close:\n        return\n\n    logging.warning(\"*******************************************************************************\")\n    logging.warning(\"*** set_global_determinism is called,setting full determinism, will be slow ***\")\n    logging.warning(\"*******************************************************************************\")\n\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    # https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads\n    tf.config.threading.set_inter_op_parallelism_threads(1)\n    tf.config.threading.set_intra_op_parallelism_threads(1)\n    from tfdeterminism import patch\n    patch()\n</code></pre> which can then be used on top of the ML algorithm/process code to generate a 100% reproducible code. </p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/22/reproducible-ml-with-tensorflow/#result","title":"Result","text":"<p>What happens if we don't write reproducible ML? What kind of difference we are really talking about? The last two columns of figure 9 show results obtained by a model trained on the exact same dataset, exactly the same code with EXACTLY  one exception. The dropout layer used in the network were unseeded. All other measures discussed above were taken into account.   </p> <p> Figure 9: Effect of just forgetting to set one seed amidst many</p> <p>Looking at the result of the first pet which is a very simple case, we can see the subtle difference in the outcome of these two models. The second pet case is slightly complicated due to shadow and we can see obvious differences in the outcome. But what about the third case, this is a very hard case for pre-trained frozen backbone model we are using but we can see major differences in result between the two models.</p> <p>If we were to use all the measures discussed above then 100% reproducible ML can be obatined. This is shown in the following 2 logs  obtained by running the following: <pre><code>python train.py \\\n  --input /wks/model_dataset \\\n  --hyperparam_fn_path best_hyper_parameters.json \\\n  --output logs \\\n  --checkpoint_path \"logs/ckpts\" \\\n  --tensorboard_path logs\n</code></pre> wherein content of <code>best_hyper_parameters.json</code> are: <pre><code>{\n   \"batch_size\":60,\n   \"epochs\":12,\n   \"iterations\":100,\n   \"learning_rate\":0.0018464290366223407,\n   \"model_arch\":\"MobileNetV2\",\n   \"steps_per_epoch\":84\n}\n</code></pre> Run attempt 1: <pre><code>WARNING:root:******* set_global_determinism is called, setting seeds and determinism *******\nTensorFlow version 2.0.0 has been patched using tfdeterminism version 0.3.0\nInput: tf-data, Model: MobileNetV2, Batch Size: 60, Epochs: 12, Learning Rate: 0.0018464290366223407, Steps Per Epoch: 84\nTrain for 84 steps, validate for 14 steps\nEpoch 1/12\n2019-11-07 12:48:27.576286: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n84/84 [==============================] - 505s 6s/step - loss: 0.8187 - iou_score: 0.4867 - f1_score: 0.6092 - binary_accuracy: 0.8749 - val_loss: 1.0283 - val_iou_score: 0.4910 - val_f1_score: 0.6297 - val_binary_accuracy: 0.8393\nEpoch 2/12\n84/84 [==============================] - 533s 6s/step - loss: 0.6116 - iou_score: 0.6118 - f1_score: 0.7309 - binary_accuracy: 0.9150 - val_loss: 0.6965 - val_iou_score: 0.5817 - val_f1_score: 0.7079 - val_binary_accuracy: 0.8940\nEpoch 3/12\n84/84 [==============================] - 527s 6s/step - loss: 0.5829 - iou_score: 0.6301 - f1_score: 0.7466 - binary_accuracy: 0.9197 - val_loss: 0.6354 - val_iou_score: 0.6107 - val_f1_score: 0.7312 - val_binary_accuracy: 0.9038\nEpoch 4/12\n84/84 [==============================] - 503s 6s/step - loss: 0.5733 - iou_score: 0.6376 - f1_score: 0.7528 - binary_accuracy: 0.9213 - val_loss: 0.6192 - val_iou_score: 0.6227 - val_f1_score: 0.7411 - val_binary_accuracy: 0.9066\nEpoch 5/12\n84/84 [==============================] - 484s 6s/step - loss: 0.5566 - iou_score: 0.6461 - f1_score: 0.7599 - binary_accuracy: 0.9241 - val_loss: 0.5827 - val_iou_score: 0.6381 - val_f1_score: 0.7534 - val_binary_accuracy: 0.9156\nEpoch 6/12\n84/84 [==============================] - 509s 6s/step - loss: 0.5524 - iou_score: 0.6497 - f1_score: 0.7629 - binary_accuracy: 0.9247 - val_loss: 0.5732 - val_iou_score: 0.6477 - val_f1_score: 0.7605 - val_binary_accuracy: 0.9191\nEpoch 7/12\n84/84 [==============================] - 526s 6s/step - loss: 0.5439 - iou_score: 0.6544 - f1_score: 0.7669 - binary_accuracy: 0.9262 - val_loss: 0.5774 - val_iou_score: 0.6456 - val_f1_score: 0.7590 - val_binary_accuracy: 0.9170\nEpoch 8/12\n84/84 [==============================] - 523s 6s/step - loss: 0.5339 - iou_score: 0.6597 - f1_score: 0.7710 - binary_accuracy: 0.9279 - val_loss: 0.5533 - val_iou_score: 0.6554 - val_f1_score: 0.7672 - val_binary_accuracy: 0.9216\nEpoch 9/12\n84/84 [==============================] - 518s 6s/step - loss: 0.5287 - iou_score: 0.6620 - f1_score: 0.7730 - binary_accuracy: 0.9288 - val_loss: 0.5919 - val_iou_score: 0.6444 - val_f1_score: 0.7584 - val_binary_accuracy: 0.9148\nEpoch 10/12\n84/84 [==============================] - 506s 6s/step - loss: 0.5259 - iou_score: 0.6649 - f1_score: 0.7753 - binary_accuracy: 0.9292 - val_loss: 0.5532 - val_iou_score: 0.6554 - val_f1_score: 0.7674 - val_binary_accuracy: 0.9218\nEpoch 11/12\n84/84 [==============================] - 521s 6s/step - loss: 0.5146 - iou_score: 0.6695 - f1_score: 0.7789 - binary_accuracy: 0.9313 - val_loss: 0.5586 - val_iou_score: 0.6581 - val_f1_score: 0.7689 - val_binary_accuracy: 0.9221\nEpoch 12/12\n84/84 [==============================] - 507s 6s/step - loss: 0.5114 - iou_score: 0.6730 - f1_score: 0.7818 - binary_accuracy: 0.9317 - val_loss: 0.5732 - val_iou_score: 0.6501 - val_f1_score: 0.7626 - val_binary_accuracy: 0.9179\n</code></pre></p> <p>Run attempt 2: <pre><code>WARNING:root:******* set_global_determinism is called, setting seeds and determinism *******\nTensorFlow version 2.0.0 has been patched using tfdeterminism version 0.3.0\nInput: tf-data, Model: MobileNetV2, Batch Size: 60, Epochs: 12, Learning Rate: 0.0018464290366223407, Steps Per Epoch: 84\nTrain for 84 steps, validate for 14 steps\n\nEpoch 1/12\n2019-11-07 10:45:51.549715: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n84/84 [==============================] - 549s 7s/step - loss: 0.8187 - iou_score: 0.4867 - f1_score: 0.6092 - binary_accuracy: 0.8749 - val_loss: 1.0283 - val_iou_score: 0.4910 - val_f1_score: 0.6297 - val_binary_accuracy: 0.8393\nEpoch 2/12\n84/84 [==============================] - 515s 6s/step - loss: 0.6116 - iou_score: 0.6118 - f1_score: 0.7309 - binary_accuracy: 0.9150 - val_loss: 0.6965 - val_iou_score: 0.5817 - val_f1_score: 0.7079 - val_binary_accuracy: 0.8940\nEpoch 3/12\n84/84 [==============================] - 492s 6s/step - loss: 0.5829 - iou_score: 0.6301 - f1_score: 0.7466 - binary_accuracy: 0.9197 - val_loss: 0.6354 - val_iou_score: 0.6107 - val_f1_score: 0.7312 - val_binary_accuracy: 0.9038\nEpoch 4/12\n84/84 [==============================] - 515s 6s/step - loss: 0.5733 - iou_score: 0.6376 - f1_score: 0.7528 - binary_accuracy: 0.9213 - val_loss: 0.6192 - val_iou_score: 0.6227 - val_f1_score: 0.7411 - val_binary_accuracy: 0.9066\nEpoch 5/12\n84/84 [==============================] - 534s 6s/step - loss: 0.5566 - iou_score: 0.6461 - f1_score: 0.7599 - binary_accuracy: 0.9241 - val_loss: 0.5827 - val_iou_score: 0.6381 - val_f1_score: 0.7534 - val_binary_accuracy: 0.9156\nEpoch 6/12\n84/84 [==============================] - 494s 6s/step - loss: 0.5524 - iou_score: 0.6497 - f1_score: 0.7629 - binary_accuracy: 0.9247 - val_loss: 0.5732 - val_iou_score: 0.6477 - val_f1_score: 0.7605 - val_binary_accuracy: 0.9191\nEpoch 7/12\n84/84 [==============================] - 506s 6s/step - loss: 0.5439 - iou_score: 0.6544 - f1_score: 0.7669 - binary_accuracy: 0.9262 - val_loss: 0.5774 - val_iou_score: 0.6456 - val_f1_score: 0.7590 - val_binary_accuracy: 0.9170\nEpoch 8/12\n84/84 [==============================] - 514s 6s/step - loss: 0.5339 - iou_score: 0.6597 - f1_score: 0.7710 - binary_accuracy: 0.9279 - val_loss: 0.5533 - val_iou_score: 0.6554 - val_f1_score: 0.7672 - val_binary_accuracy: 0.9216\nEpoch 9/12\n84/84 [==============================] - 518s 6s/step - loss: 0.5287 - iou_score: 0.6620 - f1_score: 0.7730 - binary_accuracy: 0.9288 - val_loss: 0.5919 - val_iou_score: 0.6444 - val_f1_score: 0.7584 - val_binary_accuracy: 0.9148\nEpoch 10/12\n84/84 [==============================] - 531s 6s/step - loss: 0.5259 - iou_score: 0.6649 - f1_score: 0.7753 - binary_accuracy: 0.9292 - val_loss: 0.5532 - val_iou_score: 0.6554 - val_f1_score: 0.7674 - val_binary_accuracy: 0.9218\nEpoch 11/12\n84/84 [==============================] - 495s 6s/step - loss: 0.5146 - iou_score: 0.6695 - f1_score: 0.7789 - binary_accuracy: 0.9313 - val_loss: 0.5586 - val_iou_score: 0.6581 - val_f1_score: 0.7689 - val_binary_accuracy: 0.9221\nEpoch 12/12\n84/84 [==============================] - 483s 6s/step - loss: 0.5114 - iou_score: 0.6730 - f1_score: 0.7818 - binary_accuracy: 0.9317 - val_loss: 0.5732 - val_iou_score: 0.6501 - val_f1_score: 0.7626 - val_binary_accuracy: 0.9179\n</code></pre></p> <p>So we have 100% reproducible ML code now but saying training is snail-ish is an understatement. Training time has increased  (CPU based measures) from 28 minutes vs 1 hr 45 minutes as we give away with inter-thread parallelism and also asynchronous computation optimization. This is not practical in reality. This is also why reproducibility in ML is more focussed around  having a road map to reach the same conclusions<sub>- Dodge</sub>. This is realized by maintaining a system capable of capturing full provenance over everything involved in the ML process including data, code, processes, and infrastructure/environment.  This will be the focus of part 3 of this blog series. </p> <p>The next part of the technical blog series, [Reproducibility in Machine Learning], is End-to-end reproducible Machine Learning pipelines on Kubernetes.       </p> <p>[Reproducibility in Machine Learning]: /2019/12/20/Reproducibility-in-Machine Learning.html</p>","tags":["blog","data-science","machine-learning","tensorflow","reproducibility","intermediate"]},{"location":"blog/2019/12/23/end-to-end-reproducible-machine-learning-pipelines-on-kubernetes/","title":"End-to-end reproducible Machine Learning pipelines on Kubernetes","text":"<p>This is Part 3 - End-to-end reproducible Machine Learning pipelines on Kubernetes of technical blog series titled [Reproducibility in Machine Learning]. Part 1 &amp; Part 2 can be found here &amp; here respectively.</p> <p>Change Anything Changes Everything (CAKE) principle <sub>-[Scully et al][scully_2015]</sub> is  real in ML. Also, 100% reproducible ML code comes at a cost of speed - a non-negotiable aspect in today's time.  If  we cannot be 100% and change is evident, then the only way to maintaining explainability, understanding, trust  &amp;  confidence is through version control everything. </p> <p> Figure 1: Version control explained by XKCD</p> <p>In this post, we will be looking at building an end to end fully automated ML pipeline that can maintain full provenance across the entire ML system. In my view, a standard machine learning workflow looks like the one below: </p> <p> Figure 2: Machine Learning end to end system</p> <p>So we will be working towards building this system with full provenance over it. For this, we will be extending our sample  semantic segmentation example based on Oxford Pet dataset </p> <p>To build this ML workflow, we will be using Kubernetes - a container orchestration platform.  On top of Kubernetes, we will be running Pachyderm  software that will do the heavy lifting of maintaining provenance across data, artifacts, and ml processes.</p>","tags":["blog","kubernetes","k8s","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/23/end-to-end-reproducible-machine-learning-pipelines-on-kubernetes/#what-to-version-control","title":"What to version control","text":"<p>In part 1 of this blog series, we discussed above the challenges, shown in figure 3, in realizing reproducible ML.</p> <p> Figure 3: Overview of challenges in reproducible ML</p> <p>The presence of these challenges in the system-wide view of ML is shown in figure 4.</p> <p> Figure 4: What to version control?</p> <p>But first, let's talk about creating the environment, infrastructure, and versioning it.   </p>","tags":["blog","kubernetes","k8s","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/23/end-to-end-reproducible-machine-learning-pipelines-on-kubernetes/#1-versioning-environment","title":"1. Versioning environment","text":"<p>Using gitops environment and any changes associated with it can be version controlled. In this sample, we will be using ArgoCD to implement GitOps workflow (figure 5) which will see our environment config moved to be alongside the code repository (figure 6).   </p> <p> Figure 5: Gitops</p> <p>This is achieved by defining argo apps which can be applied on BYO Kubernetes cluster (version 1.14.7) that has ArgoCD installed:</p> <pre><code>kubectl apply \u2013f https://raw.githubusercontent.com/suneeta-mall/e2e-ml-on-k8s/master/cluster-conf/e2e-ml-argocd-app.yaml\n</code></pre> <p> Figure 6: Gitops on environment config</p> <p>Once the Argo apps are created, the following software will be installed on the cluster: - Kubernetes: 1.14.7 (tested on this version, in theory, should work with other versions too!) - ArgoCD: 1.2.3 - Kubeflow: 0.6.2</p> <p>Kubeflow is an ML toolkit designed to bring a variety of ML related Kubernetes based software together. - Seldon 0.4.1 (upgraded from packaged version on kubeflow 0.6.2) Seldon is a model serving software - Pachyderm: 1.9.7 Pachyderm offers a git like a repository that can hold data even big data. It also offers automated repository capability that <code>act</code> on input and generate data thus holding a versioned copy of this generated data. Together with these  constructs, it can be used to create pipeline DAG like processes with provenance across graph input, transformation spec, output</p> <p>Any change on this configuration repository will then trigger a cluster update keeping environment in synced with versioned config. </p>","tags":["blog","kubernetes","k8s","machine-learning","reproducibility","intermediate"]},{"location":"blog/2019/12/23/end-to-end-reproducible-machine-learning-pipelines-on-kubernetes/#2-versioning-data-process-and-artifacts","title":"2. Versioning data, process, and artifacts","text":"<p> Figure 7: Artifact view of Machine Learning end to end system (shown in figure 2)</p> <p>Pachyderm pipeline specification for an end to end ML workflow capability shown in figure 2 is available here. The generated artifacts/data as a result of this ML workflow is shown in figure 7 above. These artifacts and their association with other processes are also highlighted in figure 7. </p> <pre><code>---\npipeline:\n  name: stream\ntransform:\n  image: suneetamall/pykubectl:1.14.7\n  cmd:\n  - \"/bin/bash\"\n  stdin:\n  - \"wget -O images.tar.gz https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz &amp;&amp; \\\n     wget -O annotations.tar.gz https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz &amp;&amp; \\\n     tar -cvf data.tar.gz *.tar.gz &amp;&amp; \\\n     cat data.tar.gz &gt; /pfs/out &amp;&amp; \\\n     while :; do sleep 2073600; done\"\nspout:\n  overwrite: true\n---\ninput:\n  pfs:\n    glob: /\n    repo: stream\npipeline:\n  name: warehouse\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python download_petset.py --input /pfs/stream/ --output /pfs/out\"\ndatum_tries: 2\n#standby: true\n---\ninput:\n  pfs:\n    glob: \"/\"\n    repo: warehouse\npipeline:\n  name: transform\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python dataset_gen.py --input /pfs/warehouse --output /pfs/out\"\ndatum_tries: 2\n#standby: true\n---\ninput:\n  pfs:\n    glob: \"/\"\n    repo: transform\npipeline:\n  name: train\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python train.py --input /pfs/transform --output /pfs/out --checkpoint_path /pfs/out/ckpts --tensorboard_path /pfs/out\"\nresource_requests:\n  memory: 2G\n#  gpu:\n#    type: nvidia.com/gpu\n#    number: 1\ndatum_tries: 2\n#standby: true\n---\ninput:\n  pfs:\n    glob: \"/\"\n    repo: transform\npipeline:\n  name: tune\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python tune.py --input /pfs/transform --output /pfs/out\"\nresource_requests:\n  memory: 4G\n  cpu: 1\n#  gpu:\n#    type: nvidia.com/gpu\n#    number: 1\ndatum_tries: 2\n#standby: true\n---\ninput:\n  cross:\n    - pfs:\n       glob: \"/\"\n       repo: transform\n    - pfs:\n        glob: \"/optimal_hp.json\"\n        repo: tune\npipeline:\n  name: model\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python train.py --input /pfs/transform --hyperparam_fn_path /pfs/tune/optimal_hp.json\n     --output /pfs/out --checkpoint_path /pfs/out/ckpts --tensorboard_path /pfs/out\"\n  - \"ln -s /pfs/tune/optimal_hp.json /pfs/out/optimal_hp.json\"\nresource_requests:\n  memory: 2G\n#  gpu:\n#    type: nvidia.com/gpu\n#    number: 1\ndatum_tries: 2\n#standby: true\n---\ninput:\n  cross:\n    - pfs:\n       glob: \"/calibration\"\n       repo: transform\n    - pfs:\n        glob: \"/model.h5\"\n        repo: model\npipeline:\n  name: calibrate\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python calibrate.py --input /pfs/transform --model_weight /pfs/model/model.h5 --output /pfs/out\"\n  - \"ln -s /pfs/model/model.h5 /pfs/out/model.h5\"\ndatum_tries: 2\n#standby: true\n---\ninput:\n  cross:\n    - pfs:\n       glob: \"/test\"\n       repo: transform\n    - pfs:\n        glob: \"/\"\n        repo: calibrate\npipeline:\n  name: evaluate\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"papermill evaluate.ipynb /pfs/out/Report.ipynb \\\n      -p model_weights /pfs/calibrate/model.h5 \\\n      -p calibration_weights /pfs/calibrate/calibration.weights \\\n      -p input_data_dir /pfs/transform \\\n      -p out_dir /pfs/out \\\n      -p hyperparameters /pfs/calibrate/optimal_hp.json\"\n  - \"ln -s /pfs/calibrate/model.h5 /pfs/out/model.h5\"\n  - \"ln -s /pfs/calibrate/calibration.weights /pfs/out/calibration.weights\"\nresource_requests:\n  memory: 1G\ndatum_tries: 2\n#standby: true\n---\ninput:\n  pfs:\n    glob: \"/\"\n    repo: evaluate\npipeline:\n  name: release\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  image: suneetamall/e2e-ml-on-k8s:1\n  stdin:\n  - \"python release.py --model_db evaluate --input /pfs/evaluate/evaluation_result.csv --version ${evaluate_COMMIT}\"\npod_spec: '{\"serviceAccount\": \"ml-user\", \"serviceAccountName\": \"ml-user\"}'\ndatum_tries: 2\n#standby: true\n---\n## Service https://docs.pachyderm.io/en/1/concepts/pipeline-concepts/pipeline/service.html\ninput:\n  pfs:\n    glob: \"/\"\n    repo: model\npipeline:\n  name: tensorboard\nservice:\n  external_port: 30888\n  internal_port: 6006\ntransform:\n  cmd:\n  - \"/bin/bash\"\n  stdin:\n  - tensorboard --logdir=/pfs/model/\n  image: suneetamall/e2e-ml-on-k8s:1\n---\n</code></pre> <p>This pipeline creates ML workflow, with artifact dependency shown in above figure 7, wherein full provenance across  data, processes, and outcomes are maintained along with respective lineage.   </p> <p>This is the last post of the technical blog series, [Reproducibility in Machine Learning].       </p> <p>[Reproducibility in Machine Learning]: /2019/12/20/Reproducibility-in-Machine Learning.html</p> <p>[scully_2015]: https://papers.nips.cc/paper/5656-hidden-technical-debt-in-Machine Learning-systems.pdf</p>","tags":["blog","kubernetes","k8s","machine-learning","reproducibility","intermediate"]},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/","title":"WTH! Who killed my pod - Whodunit?","text":"<p>A few days ago, I deployed a brand new application onto a self-managed Kubernetes cluster (hereafter referred to as Kube).  Suffice to say, all hell broke loose. The pods were getting <code>OOMKilled</code> with error code 137 left and right! </p> <p>Now, I know a thing or two about Kubernetes<sup>1,2</sup>. I am not a total Kube noob! But, I could not figure out what the fudge was going on actually!  Besides, this app has been thoroughly tested and profiled and ran fine on bare metal and virtual environments.</p> <p>So this was me, a few days ago!.</p> <p></p> <p>This sparked a massive hunt for the culprit, and some interesting insights were discovered. Worth noting, similar investigating has also been done on by Line Corp in their excellent blog however, I have a different story to tell!</p> <p>In this writeup,  I am going to talk about this particular incident and the insights I have uncovered about both Kube and Linux kernels.</p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#context-of-the-app","title":"Context of the app","text":"<p>The app runs some intensive numpy and Tensorflow computations to produce some artifacts and associative metadata. The workloads are more memory-intensive as they operate on rich multi-media content.  Other gory details besides resource requirements of the app is irrelevant for this discussion. </p> <p>The average resource requirement, for this app, is very fluctuating yet predictable (in a given range).  At least so we thought looking at our metrics:</p> <p> Figure 2: Average resource requirements of the app when run on VMs or bare metal</p> <p>I hear you, the resource utilization is not following a zero gradient line (fig 2)!  It would be awesome to have constant non-flapping resource requirement needs - so clearly some work needs to happen on the app here. Having said that, it's an absolutely acceptable and supported workload. </p> <p>Ok, so the app was deployed and now, we will look at the line of investigation:</p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#apps-on-kube-day-1","title":"App's on Kube: day 1","text":"<p>The provisioned app pods started to get killed as frequently as every 20 mins or more with error code 137 and reason <code>OOMKilled</code>. </p> <p> Figure 3: The killer is on the loose! - Whodunit?</p> <p>Let me explain a few things about the failure first: 1. <code>Error code 137</code> indicates that the container process received the SIGKILL and thus was killed by the OS kernel.      SIGKILL on Kube can only be produced using one of the following means:</p> <pre><code>1.1. Manually (human): Triggering CTRL+C or using other means of manually sending SIGKILL or even manually killing process.\n\n1.2. Container Runtime/Interface: `Kubelet` the process running on the host machine that manages running Kube workload is `the power that be` for containers. \nIt communicates through container runtime to manage the container lifecycle. It can kill and almost always kills badly behaving pods!\n\n![](../../resources/oom/CRI.png)\n*Figure 4: Container runtime interface. Image Credit: [Ian Lewis]! Borrowed from his 4 part container runtime series [container runtime] that I highly recommend reading*\n\n1.3. OS kernel: The OS kernel is responsible for the life cycle of processes running on the host. \nIt is `the mighty power that be` for all the processes on the host including the container process and its children.\nIt can also kill and almost always kills badly behaving processes!\n</code></pre> <ol> <li><code>OOMKilled</code> represent a kill event (SIGKILL) triggered to a process because someone in-charge suspected of the process to be the culprit of a memory surge that may lead to an out of memory event. This is a safeguard mechanism to avoid  system-level failure and to nip mischieve in the bud.  </li> </ol> <p><code>Takeaway 1</code>: Either Container Runtime/Interface or OS Kernel killed my process because supposedly it was misbehaving and causing the out-of-memory issue!  Essentially, I am ruling out the manual kill because that was simply not the case!</p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#deep-dive-into-factors-at-play-here","title":"Deep-dive into factors at play here","text":"<ol> <li> <p>Container runtime (in fig 4) is responsible for two things: </p> <p>a) Running containers: Comes from open container initiative (OCI) (about 2013) open sourced by Docker called \"runc\". It provides ability to run containers.</p> <p>b) Image management: How images are packed, unpacked, pushed, pulled etc comes under this umbrella. A good example for this is \"containerd\".          </p> <p> Figure 5: Docker stack! Image credit: internet</p> <p>There are several other implementation for runtime than runc+containerd like rkt but for me, its <code>runc+containerd</code> in play.</p> </li> <li> <p>control groups are a Linux kernel feature that allows processes to be organized into hierarchical groups whose usage of various types of ../resources (memory, CPU, and so on) can then be limited and monitored. The cgroups interface is provided through a pseudo-filesystem called cgroupfs. You may have heard about <code>/sys/fs/cgroup/</code>! </p> <p>Liz Rice did an excellent demonstration of what it means to run a container and how they work that I highly recommend going through. Don't forget playing with the demo code. It gives a foundational understanding of cgroups's role in all things containers.</p> <p> Figure 6: CGroup in picture! Image credit: zines by Julia Evans</p> </li> <li> <p><code>Kubelet</code> (see fig 4) not only interfaces container runtime but also has <code>cAdvisor</code>(for Container Advisor) integrated within.  Note <code>kubelet</code> is a service running on the host and it operates at the host level, not the pod.  With <code>cAdvisor</code> it captures resource utilization, statistics about control group of all container processes on the host.</p> </li> <li> <p>Kubernetes manages the resource for containers using <code>cgroups</code> that guarantees resource isolation and restrictions.  Kube can allocate X amount of ../resources to a container and allow the ../resources to grow until a pre-existing limit is reached or no more is left on the host to use. Kube provides these requests and limits semantic on containers which are used to enforce the said limit on process hierarchy for each container via cgroups. Now, the `limit is not always a hard cut-off. As documented in google's blog of best practices resource requests and limits, there are two types of ../resources:</p> <ol> <li>Compressible ../resources: When resource limit is reached, Kube will throttle the container i.e. start to restrict the usage but won't actually terminate the container.      CPU is considered as a compressible resource.</li> <li>Incompressible ../resources: When a limit for this type of resource is reached, the highest usage process within the cgroups hierarchy will be killed.     Memory is an incompressible resource. </li> </ol> <p><code>Takeaway 2</code>: It's not the CPU limit, but the memory limit that we need to focus on.</p> </li> <li> <p>Kubernetes classifies pod into three categories based on the quality of service (QoS) they provide:</p> <p>4.1 Guaranteed pods are those who's resource request and limit are just the same. These are the best kind of workload from Kube's viewpoint as they are easier to allocate and plan for resource-wise. These pods are guaranteed to not be killed until they exceed their limits.  Figure 7: Guaranteed QoS pod example</p> <p>4.2 Best-Effort pods are those where no resource requirements are specified. These are the lowest priority pods and the first to get killed if the system runs out of memory.   Figure 8: Best-Effort QoS pod example</p> <p>4.3 Burstable pods are those whose resource request and limit are defined in a range (fig 9), with limit treated as max if undefined.  These are the kind of workloads that are more likely to be killed when the host system is under load and they exceed their requests and no Best-Effort pods exist.   Figure 9: Burstable QoS pod example</p> <pre><code>So can Kube over-commit? \nIf yes, would it always be on the compressible ../resources? \n</code></pre> <p>Yes, Kube can overcommit. The pod limits are allowed to be higher than requests. It's possible that the sum of all limits exceeds the total node capacity. It's possible to overcommit both compressible and incompressible ../resources. This is pictorially explained here. In fact, with Kube, it's also possible to not only vertically overcommit but also horizontally (at cluster level) overcommit.  Horizontal overcommits are nicer as they can trigger auto-scaling events to scale out.   </p> </li> </ol>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#so-why-the-pods-are-getting-killed","title":"So why the pods are getting killed?","text":"<p>The app was initially deployed with <code>Burstable</code> QoS with Memory requirements set at request: 4Gi, limit: 7Gi, and  CPU set at 2 for both requests, limits (see fig 2). The nodes were AWS <code>r5.2xlarge</code> type with 8 CPU, 64GB RAM, running Debian/Linux. Other than Kube system components and the app, nothing else was deployed on these nodes. </p> <p>So, Kube could have only deployed 3 app pods per <code>r5.2xlarge</code> nodes (due to CPU request). This means, 43GB (=64-7*3) of RAM  was lying around singing hakuna matata! What a waste! Sure but let's not digress! So why the OOMKill? <code>\u00af\\_(\u30c4)_/\u00af</code></p> <p>Noteworthy observation:     - Node monitoring tells us that is running healthy and has plenty of ../resources at its disposal.      - the pod is still OOMKilled but not all app pods on the node, just one is killed.</p> <p>I am still clueless. So, caving in, I decided to use up this extra memory floating around and beef up the nodes a bit more  and buy more time to do a proper investigation.  Now, the apps are redeployed again with RAM request 4Gi, limit: 31Gi (leaving 4GB for other misc system components).</p> <p>Did that ameliorate the problem - no! Of course, I am being silly about this, I should be making it guaranteed to have better  chance of avoiding OOMKill. </p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#apps-on-kube-day-2","title":"App's on Kube: day 2","text":"<p>So, my apps are running with guaranteed QoS with 31GB of RAM as required/limit. Node still seems healthy and shows no sign of duress.  </p> <p>Hows the app doing with the new revised configuration: <code>still getting OOMKilled with 137 error code left and right!</code> </p> <p></p> <p>Meanwhile, we uncovered random memory surges in some pods (see figure 10). These surges occurred very rarely and did not match to the duration of out-of-memory kill events. In fact, the frequency of OOM was much higher than these memory surges. </p> <p> Figure 10: The notorious spike of memory use on pod</p> <p>While these surges are worth investigating, they are still within the request/limit range (28.x Gi suurge on 31Gi request). So they still don't justify the OOM event.</p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#whats-log-telling-us","title":"Whats log telling us","text":"<p>Based on Takeaway 1 &amp; 2, we look at who is firing the kill signal. #Whodunit</p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#kube-events-for-pod-and-other-higher-level-abstractions","title":"Kube events for pod and other higher-level abstractions","text":"<p>Investigating, on Kube <code>Events</code> there is no record or any OOMKill or any event signaling anything malicious. <pre><code>kubectl describe pod &lt;my pod&gt;\nkubectl describe deploy &lt;my pod&gt;\n</code></pre> In fact, according to my Kube event stream <code>kubectl get events</code>, Kube is all healthy and there is nothing to see, nothing to worry about there! It shows that containers are clearly being restart but it seems to be not capturing any adverse event and bringing it back up to keep to desired declared state on attached replicaset.  <pre><code>26m         Normal   Created   pod/myapp   Created container planck\n26m         Normal   Started   pod/myapp   Started container planck\n26m         Normal   Pulled    pod/myapp   Container image \"app\" already present on machine\n</code></pre></p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#what-are-the-cri-and-kubelet-doing","title":"What are the CRI and kubelet doing?","text":"<p>Looking at the system journal, there is nothing noteworthy recorded for OOM.  1. Nothing is logged for <code>Out of memory</code> (command reference <code>journalctl -u kubelet | grep -i \"Out of memory\"</code>) 2. Only log I see for shorter term <code>oom</code> (cmd reference <code>journalctl -u kubelet | grep -i \"oom\"</code> is info level log of kubelet startup record. <pre><code>kubelet[2130]: I0309 04:52:13.990735    2130 flags.go:33] FLAG: --oom-score-adj=\"-999\"\nkubelet[2130]: I0309 04:52:15.416807    2130 docker_service.go:258] Docker Info: &amp;{ID:XF74:2JFW:UOE4:QI7X:TXQU:RJLG:E7FC:K4K3:IUTM:MGFW:W2GM:Z6AC Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:0 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog]} MemoryLimit:true SwapLimit:false KernelMemory:true KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:false IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:23 OomKillDisable:true NGoroutines:44 SystemTime:2021-03-09T04:52:15.411198727Z LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:4.9.0-14-amd64 OperatingSystem:Debian GNU/Linux 9 (stretch) OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc00062c0e0 NCPU:16 MemTotal:133666107392 Generic../resources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ip-172-30-36-152 Labels:[] ExperimentalBuild:false ServerVersion:18.06.3-ce ClusterStore: ClusterAdvertise: Runtimes:map[runc:{Path:docker-runc Args:[]}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:&lt;nil&gt; Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:468a545b9edcd5932818eb9de8e72413e616e86e Expected:468a545b9edcd5932818eb9de8e72413e616e86e} RuncCommit:{ID:a592beb5bc4c4092b1b1bac971afed27687340c5 Expected:a592beb5bc4c4092b1b1bac971afed27687340c5} InitCommit:{ID:fec3683 Expected:fec3683} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[]}\nkubelet[2130]: I0309 04:52:15.437879    2130 manager.go:1159] Started watching for new ooms in manager\n</code></pre></p> <p>Normally, in the event of OOM triggered by Kube, we should see kubelet recording some signal for oom e.g. <code>An OOM event was triggered</code></p> <p><code>Takeaway 3</code>: As far as Kube is concerned, the pod is well behaved and it's all hakuna matata! </p> <p>So, #Whodunit? Enter day 3 - new day new investigation </p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#apps-on-kube-day-3","title":"App's on Kube: day 3","text":"<p>Based on the previous 3 takeaways, the only potential suspect we have is OS kernel. The pods are still crashing and metrics, events, and Kube level logs do not justify the observation. </p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#reading-kernel-logs","title":"Reading kernel logs","text":"<ol> <li> <p>System level log scan <code>grep -i -r 'out of memory' /var/log/</code> takes us somewhere.      <pre><code>/var/log/kern.log:Mar  9 13:17:05 ip-172-xxx-xx-xxx kernel: [30320.358563] Memory cgroup out of memory: Kill process 11190 (app) score 9 or sacrifice child\n</code></pre> <code>Takeaway 4</code>: We do in fact have kernel thinking memory cgroups is in danger and starting to kill!</p> </li> <li> <p>Kernel logs (<code>/var/log/kern.log</code>) seem to have much more insightful info than the above one-liner <code>out of memory: Kill process</code>. </p> </li> </ol> <p>But before we look into this, let's do a bit of a deep dive into related concepts: </p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#deep-dive-into-os-kernel","title":"Deep-dive into OS Kernel","text":"<ol> <li>Swap space and Kube</li> </ol> <p>Docker supports setting swappiness however it's discouraged as it's slow and less performant.     Also, providing a limit on the swap is unsupported at the docker level which can lead to resource management and overcommitment chaos.     These are some of the reasons why kops and in general Kube prefer no swap on hosts. </p> <ol> <li>OOMKill disable on Kubernetes</li> </ol> <p>OS Kernels allow disabling OOM Kill for cgroups level (<code>/sys/fs/cgroup/memory/memory.oom_control</code>) even docker     supports it using <code>--oom-kill-disable</code> flag. These are highly discouraged due to the nature of problem band-aid fixer <code>OOM Killer</code>    solves. It also does not sit with Kube's declarative approach orchestration and also with cattle workload philosophy.    It's also why by default oom kill is enabled on Kubernetes.</p> <p>Its possible however to configure it to disable OOMKill by starting kubelet service with <code>--cgroup-driver=cgroupfs</code> argument and then setting <code>oom_kill_disable</code> under <code>/sys/fs/cgroup/memory/memory.oom_control</code>  as 1.</p> <p><code>Takeaway 5</code>: It's not something I want to enable either, but for the completeness of the discussion, it's worth mentioning :).    </p> <ol> <li> <p>Kernel memory management</p> <p>The kernel uses virtual addressing (using paging and segmentation) to provide isolation amongst various processes running on host.  It is also virtual addressing that allows for use of more memory than what's available currently in physical memory (RAM) by making use of other sources like a disk (a.k.a. swap).  Virtual addressing is divided into user &amp; kernel space.  Userspace is the sort of virtual address space that's reserved for user/application programs whereas kernel space is reserved for kernel-related operations. </p> <p>Now, the os kernel is designed to be greedy - greedy to be able to run as many processes as possible. This is also the reason why we need mechanisms like `out of memory'.</p> </li> <li> <p>System vs memory controller (memch) OOM</p> </li> </ol> <p>cgroups comprises of two components: <code>core</code> and <code>controller</code>. Core corresponds to managing the hierarchy and core capabilities whereas controllers     are focused on the type of resource cgroup is controlling eg cpu, io, memory controller ('memcg').  </p> <pre><code>Now, the user-space out-of-memory handling can address OOM conditions for both cgroups using the memory controller ('memcg') and for the system as a whole.\n`Takeaway 6`: We know, based on our takeaways, that our OOM is not stemming from system draining or system as whole. Also, log `Memory cgroup out of memory` indicating that its `memcg`\nthat's triggering the OOM Kill. Here, the app process hierarchy memory usage is aggregated together into its memcgs so the memory usage at group level can be accounted for. \nWhat our first log here is telling us is `memcg usage reached its limits and memory cannot be reclaimed i.e. the memcg is out of memory`&lt;sup&gt;[1][lwn]&lt;/sup&gt;.\n</code></pre> <ol> <li> <p>OOM kill score</p> <p>How does kernel come to decide which process to kill, is based on a score. The score has two parts: main (<code>oom_score</code>) and adjustment factor (<code>oom_score_adj</code>). These scores are store against process id in process space and can be located on disk as : <pre><code>/proc/&lt;pid&gt;/oom_score\n/proc/&lt;pid&gt;/oom_score_adj\n</code></pre></p> <p>The <code>oom_score</code> is given by kernel and is proportional to the amount of memory used by the process i.e. = 10 x percentage of memory used by the process.  This means, the maximum <code>oom_score</code> is 100% x 10 = 1000!. Now, the higher the oom_score higher the change of the process being killed. However, user can provide an adjustment factor <code>oom_score_adj (a.k.a. oom_adj in older kernel versions)</code>.  If provided, it is used to adjust the final score. The valid value for <code>oom_score_adj</code> is in the range of  (-1000, +1000), where -ve score decreases and +ve increases the chances of oomkill. More details on this can be found in this very interesting article by Jonathan Corbet another OOMKill rewrite, with precursory article found here.</p> </li> <li> <p>OOM trigger workflow</p> </li> </ol> <p><code>kmsg</code> is the kernel message interface that directs kernel messages to <code>/proc/kmsg</code> &amp; <code>/dev/kmsg</code>. Now, <code>/dev/kmsg</code> is more useful for us mere mortals as it's designed to be persistent.    <code>/proc/kmsg</code> is designed to be read once and treated more as event queue if you will. Messages from here also trickle through to kernel logs @ <code>/var/log/kern.log</code>.</p> <pre><code>_On Kube_\n\nKebelet watches for `kmsg` and handles messages that will translate to OOMEvent/OOMKillEvent in Kube event stream which is then handled appropriately to trigger OOMKill. More interesting details of how this happens can be found [here][line-eng-qos] (also shown in borrowed fig 11).\n\n![](../../resources/oom/workflow-4-1024x816.png)\n*Figure 11: OOM handling workflow on Kubernetes. Image credit: [Line Corp][line-eng-qos]*\n\nAs mentioned in `takeway 3 &amp; 4`, this workflow however was not triggered in our case, we are did not record any Kube related OOM events or even kubelet receiving\nany related messages.\n\n_At Kernel Level_\nWhen system or memory controller related OOM is suspected, based on `oom_score` (with adjustment `oom_score_adj`), `oom-killer` is invoked on the highest\nscore process and its children.\n</code></pre>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#so-why-the-pods-are-getting-killed_1","title":"So why the pods are getting killed?","text":"<p>In my case, memory cgroup ran out of memory and my stack trace confirms this (see fig 12). It tells me that the application container was  killed because it was consuming 1.5MB shy of memory set as limit (31457280 KB).</p> <p> Figure 12: Kernel log part 1</p> <p>OK! this explains the OOMKill but why:</p> <p>a. My monitoring only shows 29GB as max memory surge!</p> <p>b. I never noticed beyond 9GB usage in local/testing/profiling and all the jazz!</p> <p></p> <p>This simply does not add up! Let's hold on to this thought for a bit and look at the rest of the logs and what it says:</p> <p>Before we go into part 2 of the log, I should explain a few things:</p> <ol> <li> <p>The pause container is the parent container of each pod, responsible for creating and managing the environment for the group of containers that would be provisioned within the pod. For more info, I will direct you to an excellent article by Ian Lewis, the almighty pause container.  I need to explain this because it will be shown in the following log.</p> </li> <li> <p>Definition of memory cgroups stats metrics as per kernel.org is listed below. </p> </li> </ol> <p>Note that, <code>anonymous memory</code> (abbreviated often as <code>anon</code>) is a memory mapping with no file or device backing it.     Anon memory is used by programs to allocate memory for the stacks and heaps.    Also, the standard page size on the Linux kernel is 4KB which can be really inefficient to store mapping for a large block of memory virtual memory.     <code>Hugepages</code> are designed to solve this inefficiency and can hold a bigger chunk than 4KB. More details on this is available here. </p> <pre><code>| Metrics of memory cgroups stats |                                                                                                        Definition                                                                                                        |\n| ------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n| rss                             | rss stands for resident set size. It is the portion of memory occupied by a process that is held in RAM. This metric represents the number of bytes of anonymous and swap cache memory (includes transparent hugepages). |\n| rss_huge                        |                                                                                   number of bytes of anonymous transparent hugepages.                                                                                    |\n| cache                           |                                                                                          number of bytes of page cache memory.                                                                                           |\n| mapped_file                     |                                                                                number of bytes of the mapped file (includes tmpfs/shmem)                                                                                 |\n| swap                            |                                                                                              number of bytes of swap usage                                                                                               |\n| dirty                           |                                                                            number of bytes that are waiting to get written back to the disk.                                                                             |\n| writeback                       |                                                                         number of bytes of file/anon cache that are queued for syncing to disk.                                                                          |\n| inactive_anon                   |                                                                         number of bytes of anonymous and swap cache memory on inactive LRU list.                                                                         |\n| active_anon                     |                                                                          number of bytes of anonymous and swap cache memory on active LRU list.                                                                          |\n| inactive_file                   |                                                                               number of bytes of file-backed memory on inactive LRU list.                                                                                |\n| active_file                     |                                                                                number of bytes of file-backed memory on active LRU list.                                                                                 |\n| unevictable                     |                                                                            number of bytes of memory that cannot be reclaimed (mlocked etc).                                                                             |\n</code></pre> <p>Now, as discussed previously, the swap is not being used in this system. See the second part of the logs in fig 13.  You will note, there are two containers recorded and their memory stats is a capture - a) the pause container and b) the app container.  We can ignore the pause, it's tiny and looking very healthy. But look at the stats for app pod in fig 13 (below)! At the time my app was killed, it held about 29GB in hugepages and only 1.3GB extra in RSS.  That's huge and remember monitoring it not picking it for some reason! It captured 29GB but not 31GB! Perhaps its picking only <code>rss_huge</code> and presenting it as <code>rss</code> erroneously! <code>\u00af\\_(\u30c4)_/\u00af</code>! Yes, we have a problem but this monitoring issue is for another day!</p> <p> Figure 13: Kernel log part 2</p> <p>Notice the blue arrow in fig 13, its capturing page info by both the pause container process and app container process. These are page info and not and need to be multiplied by 4KB to get actual memory stats. These are translated two lines below the blue line! </p> <p>My app has freaking 62GB in total virtual memory! What's going on! </p> <p>Ok, so \"total-vm\" is the part of virtual memory the process uses. A part of this \"total-vm\" that's mapped to RAM is <code>rss</code>. Part of <code>rss</code> that's allocated on to real memory, blocks is your <code>anon-rss</code> (anonymous memory), and the other part of rss is mapped to devices and files and termed <code>file-rss</code>. If my app goes crazy and allocates a large chunk of space (say using malloc()) but never really use it then <code>total-vm</code> can be high but it won't all be used in real memory.  This is made possible due to overcommit. A good sign of this happening, given swap off, is when <code>total-vm</code> is high but <code>rss</code> is actually low! This is exactly what's happening here! We have about 30GB difference between <code>total-vm</code> and <code>rss</code>.</p> <p><code>Takeaway 7</code>: We have two problems here: a) Supporting over-commitment and b) Allocation of what we suspect un-needed memory!   </p> <p>Let's look at solving the over-commit first and see what level of fixes it provides:</p>"},{"location":"blog/2021/03/14/wth-who-killed-my-pod---whodunit/#controlling-over-commits","title":"Controlling over-commits","text":"<p>So far, we have concluded over-commitment is a problem. Well, as discussed previously, it's a feature (of both kernel &amp; kube) apparently!</p> <p></p> <p>Kernel uses the \"extendability\" of virtual addressing to over-commit. The kernel settings <code>vm.overcommit_memory</code> and  <code>vm.overcommit_ratio</code> is specially designed to controlling this capability. For more info, see here.</p> <p>1.1 <code>vm.overcommit_memory = 0</code>: Make best guess and overcommit where possible. This is the default.</p> <p>1.2 <code>vm.overcommit_memory = 1</code>: Always overcommit </p> <p>1.3 <code>vm.overcommit_memory = 2</code>: Never overcommit, and only allocate as much memory as defined in overcommit_ratio.</p> <p><code>vm.overcommit_ratio</code> is only used when overcommit_memory=2. It defines what percent of the physical RAM plus swap space should be allocated. This is default to 50. We want this config to be 100. </p> <p>But the use of <code>sysctl</code> to set these(using the following) is not enough as the config won't persist on horizontal scaling (new node spinning due to spot instances or less important but restart): <pre><code>sysctl -w vm.overcommit_memory=2\nsysctl -w vm.overcommit_ratio=100\n</code></pre> The effect of these configs is immediate and no start is needed. Talking about the restart, <code>systcl</code> cli config update do not persist,  system config needs to be updated in <code>/etc/sysctl.conf</code> to persist the setting across restarts. </p> <p>On <code>Kube</code>, kops provisioned clusters, these settings need to be supplied through sysctlparameters config but these are only supported from kube 1.17 and higher! Safe sysctl parameters can be set at pod level however our setting is not (obviously) supported at the pod level. One can't use additionaluserdata for this either, as these settings are overridden when kops provision node as Kube node!</p> <p>And, to make it a helluva fun, this cluster is currently at 1.12! Heya, Mr. Murphy!</p> <p></p> <p>So, I say our my prayers, and turn to bash: <pre><code>for memip in $(aws ec2 describe-instances --region us-east-1 --instance-ids \\\n$(aws autoscaling describe-auto-scaling-instances --region us-east-1 --output text \\\n--query \"AutoScalingInstances[?AutoScalingGroupName=='myasg'].InstanceId\") \\\n--query \"Reservations[].Instances[].PrivateIpAddress\")\ndo     \n    ssh -o StrictHostKeyChecking=no  ${memip} 'bash -s' &lt; set_mem.sh   \ndone \n</code></pre> where <code>set_mem.sh</code> is: <pre><code>#!/usr/bin/env bash\nsudo sysctl -w vm.overcommit_memory=2\nsudo sysctl -w vm.overcommit_ratio=100 \n</code></pre></p> <p>I see a massive improvement in OOMKills. Pods that were killed every 20mins and odd, are chugging along with 24hr processing and no crash still.   Figure 14: Getting somewhere! OOMKills sort of under control!</p> <p>So, perhaps we can upgrade Kube and make this configuration systematic!  </p> <p>But, I am not done yet! No no no no no no no .....</p> <p>Remember, part <code>b</code> of our problem in <code>takeaway 7</code> i.e. <code>b) Allocation of what we suspect un-needed memory!</code>.</p> <p>Why was it happening in the first place, and why it's controlled with overcommit disabled. I won't lie, it still happens but far less infrequent!  </p> <p>it's not fixed yet!</p> <p>Oh! the fun never ends! All the places we go!  I will cover this later, ahem ahem, when I know the answer! Pretty sure it's some nasty behavior of Tensorflow 2, and the investigation is underway!</p> <p></p> <p>Thanks for reading. Hopefully, it was a fun insightful read!</p>"},{"location":"blog/2021/12/31/data-in-deep-learning/","title":"Review of recent advances in dealing with data size challenges in Deep Learning","text":"<p>The energy and excitement in machine learning and deep learning communities are infectious these days. So many groundbreaking advances are happening in this area but I have often found myself wondering why the only thing that makes it all shine - yes I am talking about the dark horse of deep learning the data is so underappreciated. The last few years of DL research have given me much joy and excitement and I carry hope now that going forward we can see some exciting progress in this space that explore advances in deep learning in conjunction with data! In this article, I summarise some of the recent developments in the deep learning space that I have been blown away by. </p> <p>Table of content of this article: - Review of recent advances in dealing with data size challenges in Deep Learning - The dark horse of deep learning: data - Labelled data: the types of labels - Commonly used DL techniques centered around data   - Data Augmentation   - Transfer Learning   - Dimensionality reduction   - Active learning - Challenges in scaling dataset for deep-learning - Recent advances in data-related techniques   - 1. Regularization     - 1.1 Mixup     - 1.2 Label Smoothing   - 2. Compression     - 2.1. X-shot learning: How many are enough?     - 2.2. Pruning       - 2.2.1 Coresets       - 2.2.2 Example forgetting       - 2.2.3 Using Gradient norms     - 2.3. Distillation   - 3. So what if you have noisy data - Conclusion - References</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#the-dark-horse-of-deep-learning-data","title":"The dark horse of deep learning: data","text":"<p>Deep learning (DL) algorithms learn to perform a task by building a (domain) knowledge representation by looking at the training data. An early study of image models (classification and segmentation, year 2017) noted that the performance of the model increases logarithmically as the training dataset increases 1. The belief that increasing training dataset size will continue to increase model performance has been long-held. This has also been supported by another empirical study that validated this belief across machine translation, language modeling, image classification, and speech recognition 2 (see figure 1). </p> <p> *Figure 1: Shows relationship between generalization error and dataset size (log scale) 2 *</p> <p>So, the bigger dataset is better right? Almost! A theoretical foundation has been laid out in the form of power-law i.e $ \\begin{equation} \\label{power_law} \u03b5(m) \\approx \u03b1m^{\u03b2_g} \\end{equation} $ wherein \u03b5 is generalization error, m is the number of samples in the training set, \u03b1 is a constant property of the problem/DL task, and \u03b2<sub>g</sub> is the scaling exponent that defines the steepness of the learning curve. Here, \u03b2<sub>g</sub>, the steepness of the curve depicts how well a model can learn from adding more data to the training set 2 .(see figure 2) Empirically,  \u03b2<sub>g</sub> was found to be between \u22120.07 and \u22120.35 despite theory suggesting \u03b2<sub>g</sub> to be 0.5 or 1. Nonetheless, the logarithmic relationship holds. As shown in figure 2, the gain eventually tapers in irreducible error. </p> <p> *Figure 2: Power Law curve showing model trained with a small dataset only as good as random guesses to rapidly getting better as dataset size increases to eventually settling into irreducible error region explained by a combination of factors including imperfect data that cause imperfect generalization 2 *</p> <p>This can be attributed to several factors including imperfection in data. The importance of data quality and continually iterating over is touched on in some of the previous talks 1, 2, 3. Data quality matters, and so does the data distribution. The better the distribution of the training dataset is, the more generalized the model can be!</p> <p>Data is certainly the new oil! 3</p> <p>So, can we scale the data size without many grievances? Keep in mind, 61% of AI practicing organizations already find data and data-related challenges as their top challenge 4. If the challenges around procurement, storage, data quality, and distribution/demographic of the dataset has not subsumed you yet, this post focuses on yet another series of questioning. How can we train efficiently when data volume grows and the computation cost and turnaround time increase linearly with data growth? Then we begin asking how much of the data is superfluous, which examples are more impactful, and how do we find them? These are very important questions to ask given a recent survey 4 noted that about 40% of the organizations practicing AI already spend at least $1M per annum on GPUs and AI-related compute infrastructures. This should concern us all.  Not every organization beyond the FAANG (and also, the one's assumed in FAANG but missed out on acronym!) and ones with big fat balance sheet will be able to leverage the gain by simply scaling the dataset. Besides, this should concern us all for environmental reasons and carbon emissions implications more details. </p> <p>The carbon footprint of training a single AI is as much as 284 tonnes of carbon dioxide equivalent \u2014 five times the lifetime emissions of an average car source.</p> <p>The utopian state of simply scaling training datasets and counting your blessings simply does not exist. The question then is, what are we doing about it? Unfortunately not a whole lot especially if you look at the excitement in the ML research community in utilizing gazillion GPU years to gain a minuscule increase in model performance attributed to algorithmic or architectural changes. But the good news is this area is gaining much more traction now. Few pieces of research since 2020 are very promising albeit in their infancy. I have been following the literature around the use of data in AI (a.k.a data-centric AI) topic very closely as this is one of my active areas of interest. I am excited about some of the recent developments in this area. In this post, I will cover some of my learnings and excitement around this topic.</p> <p>Before, covering them in detail, let's review foundational understanding and priors first:</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#labelled-data-the-types-of-labels","title":"Labelled data: the types of labels","text":"<p>This post focuses heavily on supervised learning scenarios focussing mainly on computer vision. In this space, there are two types of labels: - Hard labels - Soft labels</p> <p>Traditional labels are hard labels where the value of ground truth is a discrete value e.g. 0 and 1, 0 for no, and 1 for yes. These discrete values can be anything depending on how the dataset was curated. It's important to note that these values are absolute and unambiguously indicate their meaning.</p> <p>There is an emerging form of labels known as soft labels where ground through represents the likelihood. By nature these labels are continuous. An example, a pixel is 40% cat 60% dog. It will make a whole lot of sense in the following sections.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#commonly-used-dl-techniques-centered-around-data","title":"Commonly used DL techniques centered around data","text":"<p>Data augmentation and transfer learning are two commonly used techniques in deep learning these days that focus on applying data efficiently. Both these techniques are heavily democratized now and commonly applied unless explicitly omitted. </p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#data-augmentation","title":"Data Augmentation","text":"<p>Data augmentation encompasses a variety of techniques to transform a datapoint such that it adds variety to the dataset. The technique aims to keep the data distribution about the same but add richness to the dataset by adding variety. Predominantly, the transformation via this technique has been intra-sample. Affine transformations, contrast adjustment, jittering, or color balancing are some such examples of data augmentation techniques. Imgaug and kornia are very good libraries for such operation even though all ML frameworks offer a limited set of data augmentation routines. </p> <p>Data augmentation technique was initially proposed to increase robustness and achieve better generalization in the model but they are also used as a technique to synthetically increase data size as well. This is especially true in cases where data procurement is really challenging. These days, data augmentation techniques have become a lot more complex and richer including scenarios where-in model-driven augmentations may also be applied. One example of this is GAN-based techniques to augment and synthesize samples. In fact, data augmentation is also one of the techniques to build robustness against adversarial attacks.</p> <p> * Example of augmentation src *</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#transfer-learning","title":"Transfer Learning","text":"<p>Transfer learning is a very well democratized technique as well that stems from reusing the learned representations into a new task if the problem domain of two tasks is related. Transfer learning relaxes the assumption that the training data must be independent and identically distributed (i.i.d.) with the test data 5, allowing one to solve the problem of insufficient training data by bootstrapping model weights from another learned model trained with another dataset.</p> <p> *Figure 3: Training with and without transfer learning 6 *</p> <p>With transfer learning, faster convergence can be achieved if there is an overlap between the tasks of the source and target model.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#dimensionality-reduction","title":"Dimensionality reduction","text":"<p>Dimension reduction techniques are also applied to large datasets:</p> <p>These techniques are categorized into two: 1. Ones that seek to preserve the pairwise distance amongst all the samples in the dataset. Principal component analysis (PCA) is a good example of this. 2. Ones that preserve the local distances over global distance. The techniques like uniform manifold approximation and projection (UMAP) 23 and t-distributed stochastic neighbor embedding (t-SNE) 24 fit in this category. UMAP arguably preserves more of the global structure and is algorithmically faster than t-sne. Both T-SNE and UMAP use gradient descent for arriving at the optimal embeddings.</p> <p>These techniques in DL space however are mostly used to understand the data and also for visualization purposes. UMAP and T-SNE do better at preserving global structure than other embedding algorithms but are limited. This blog covers the topic more in detail.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#active-learning","title":"Active learning","text":"<p>Active learning is a methodology wherein the training process proactively asks for labels on specific data. It is used more commonly in classical ML techniques, but it has not been very successful in deep learning due to back-propagation. Offline or pool-based active learning has been investigated heavily for use in deep learning but without much groundbreaking success. The use of active learning is not very straightforward either due to the negative impact of outliers on training 25. Pool-based active learning will be covered in the following section in more detail (pruning).</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#challenges-in-scaling-dataset-for-deep-learning","title":"Challenges in scaling dataset for deep-learning","text":"<p>Besides the techniques discussed in previous section, not a lot of investment has been done in the area focussing on data-centric AI. The momentum around data-centric AI is forming a bit recently with Andrew Ng driving data-centric AI efforts through his new startup Landing.AI. </p> <p>In my view, the following are some of the broad categories of questions that fall under the purview of data-centric AI:</p> <ol> <li>How to efficiently train with the rapid increase in the dataset? Yann LeCun called out in his interview with Soumith Chintala during PyTorch developer day 2021 that training time of more than 1 week should not be acceptable. This is a very good baseline for practical reasons but if one does not have an enormous GPU fleet at their disposal then this is goalpost is very hard to achieve given current DL practices. So, what else can be done to train efficiently with increased dataset size?</li> <li>Are all samples equally important? How important a sample in the dataset is? Can we leverage the \"importance factor\" for good?</li> <li>What role does a sample play towards better generalization? Some samples carry redundant features, so how to deduplicate the dataset when features as in DL are not explicit?</li> <li>Data size matters but can we be strategic about what goes in the dataset?<ol> <li>Cleverly doing this has to do with efficient sampling and data mining techniques. These are the easily solved problem if and only if we know what our targets are. Challenge in DL, as I see it, is what to look for to mine for the best sample? This is not well understood. </li> </ol> </li> <li>How can we leverage more innate DL techniques like objective functions, backpropagation, and gradient descent to build a slick and effective dataset that provides the highest return on investment.</li> <li>Noises in datasets are seen as evil. But are they always evil? How much noise can one live with? How to quantify this?</li> <li>How much of a crime it is if data bleeds across traditional train/validate/calibrate/test splits.<ol> <li>What are the recommendations on the data split for cascade training scenarios?</li> </ol> </li> <li>How fancy can one get with data augmentation before returns start to diminish?</li> <li>How to optimize the use of data if continual learning is observed? </li> </ol>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#recent-advances-in-data-related-techniques","title":"Recent advances in data-related techniques","text":"<p>If we look at humans are learning machines, they have infinite data at their disposal to learn from. Our system had evolved into efficient strategies to parse through infinite data streams to select the samples we are interested in. How our vision system performs foveal fixation utilizing saccadic eye movements to conduct efficient subsampling of interesting and useful datapoint should be a good motivation. Sure we fail sometimes, we fail to see the pen on the table even though it's right in front of us due to various reasons but we hit it right most of the time. Some concepts of Gestalt theory, a principle used to explain how people perceive visual components (as organized patterns, instead of many disparate parts) are already applicable for better selection of data even if machine models are stochastic parrots. According to this theory, eight main factors, listed below, determine how the visual system automatically groups elements into patterns. </p> <ol> <li>Proximity: Tendency to perceive objects or shapes that are close to one another as forming a group. </li> <li>Similarity: Tendency to group objects if physical resemblance e.g. shape, pattern, color, etc. is present. </li> <li>Closure: Tendency to see complete figures/forms even if what is present in the image is incomplete. </li> <li>Symmetry: Tendency to 'see' objects as symmetrical and forming around a center point. 50 </li> <li>Common fate: Tendency to associate similar movement as part of a common motion. </li> <li>Continuity: Tendency to perceive each object as a single uninterrupted i.e. continuous object </li> <li>Good Gestalt: Tendency to group together if a regular, simple, and orderly pattern can be formed </li> <li>Past experience: Tendency to categorize objects according to past experience. </li> </ol> <p>Of these, I argue, proximity, similarity, common fate, and past experience are relevant. I even argue on the possibility of applying closure. A recent work by FAIR 22, shows that machine models can fill in the gaps and infer missing pieces correctly by applying minor changes commonly used technique autoencoders. Why I bring this up with so much excitement than GAN-based techniques of hallucination is how easy it is to build and train as compared to GAN.</p> <p> Masked-Autoencoders showing model inferring missing patches 22</p> <p>Its been interesting to note that the recent advances towards dealing with the challenges of scaled data are largely inspired by already known deep-learning techniques except they are now applied through the lens of data. Examples like pruning, compression, sampling strategies, and leveraging from phenomena such as catastrophic forgetting, knowledge distillation.</p> Technique How it's presently utilized in model building Proposed data-centric view Prunning A specialized class of model compression technique where low magnitude weights are eliminated to reduce the size and computational overhead. Samples that don't contribute much to generalization are omitted from the training regime. Compression A broad range of model compression techniques to reduce the size and computational overhead includes techniques like quantization wherein some amount of information loss is expected. A broad range of data filtering and compression techniques to reduce size without compromising much on generalization. Distillation To extract learned representation from a more complex model to a potentially smaller model. To extract knowledge present in the larger dataset into a smaller synthesized set. Loss function Also termed as the objective function is the one of core concepts of DL that defines the problem statement. As shown in 22, and also more broadly can be leveraged to fill in missing information in the data. Regularisation One of the theoretical principles of DL is applied through various techniques like BatchNorm, Dropouts to avoid overfitting. Variety of techniques to ensure overfitting applied with data in mind, e.g. Label Smoothing 7,10 <p>*Table 1: Summary of techniques that are crossbreed from core DL techniques to also into data-centric DL *</p> <p>Let's dive into the details of how these classes of techniques are applied through the lens of data:</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#1-regularization","title":"1. Regularization","text":"","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#11-mixup","title":"1.1 Mixup","text":"<p>Mixup is a special form of data augmentation technique that looks beyond intra-sample modification and explores inter-sample modification. The idea with mixup is to linearly combine (through convex geometry) a pair of samples to result into one.</p> <p>$ \\begin{equation} x\\prime=\u03bbx_i + (1\u2212\u03bb)x_j , \\ \\text{where,} \u03bb \u2208 [0,1] \\ \\text{ drawn from beta distribution, and xi, xj are input/source vector} \\end{equation} $</p> <p>$ \\begin{equation} y\\prime = \u03bby_i + (1 \u2212 \u03bb)y_j , \\ \\text{where y_i , yj are one-hot label encodings} \\end{equation} $</p> <p> *Figure 4: Sample produced by applying mixup 7 on Oxford Pets dataset *</p> <p>Mixup 7 in fact seeks to regularize the neural network to favor simple linear behavior in-between training examples. As shown in fig 5, mixup results in better models with fewer missed. Its been shown that mixup increases the generalization, reduces the memorization of corrupt labels, increases the robustness towards adversarial examples 7,8.</p> <p> Figure 5: Shows that using mixup 7, lower prediction error and smaller gradient norms are observed.</p> <p>I see mixup as not only an augmentation, and regularisation technique but also a data compression technique. Depending on how frequently (say \u03b1) the mixup is applied, the dataset compression ratio (C<sub>r</sub>)  will :</p> <p>$ \\begin{equation} C_r = 1 - \u03b1/2 \\end{equation} $</p> <p>If you have not noticed already, applying mixup convert labels to soft labels. The linear combination of discreet values will result in a continuous label value that can explain the example previously discussed wherein the pixel is 40% cat 60% dog (see fig 5).</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#12-label-smoothing","title":"1.2 Label Smoothing","text":"<p>Label smoothing 10 is a form of regularisation technique that smoothes out ground truth by a very small value epsilon <code>\u025b</code>. One motivation for this is of course better generalization and avoiding overfitting. While the other motivation is to discourage the model from becoming overconfident. Both 8,10 have shown that label smoothing leads to better models.</p> <p>$ \\begin{equation} Q_{i} =   \\begin{cases} \\displaystyle     1 - \u025b &amp;  \\text{if i == k,} \\           \u025b/K &amp; \\text{Otherwise, where K is number of classes} \\       \\end{cases}      \\end{equation} $</p> <p>Label smoothing as indicated by the equation above does not lead to any visible differences in label data as <code>\u025b</code> is really small. However, applying mixup change visibly changes both source (x) and the label (y).</p> <p> Applying label-smoothing has no noticeable difference</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#2-compression","title":"2. Compression","text":"<p>Compression refers to a broad range of data filtering and compression techniques to reduce size without compromising much on generalization. Following are some of the recent exciting development on this front:</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#21-x-shot-learning-how-many-are-enough","title":"2.1. X-shot learning: How many are enough?","text":"<p>The troubles of high computational cost and long training times due to an increase in the dataset have led to the development of training by a few shot strategies. The intuition behind this approach is to take a model and guide it to learn to perform a new task only by looking at a few samples 11. The concept of transfer learning is implicitly applied in this approach. This line of investigation started with training new tasks by using only a few (handful) samples and explored an extreme case of one-shot training i.e. learning new tasks from only one sample 12,13.</p> <p>Recently an interesting mega-extreme approach of shot-based learning has emerged - <code>'Less Than One'-Shot Learning</code> a.k.a LO Shot learning 11. This approach utilizes soft label concepts and seeks to merge hard label N class samples into M samples where M &lt; N and thus the name less than one! LO Shot-based techniques are a form of data compression technique and may feel very similar to the MixUp technique discussed earlier. However, LO Shot contrary to a convex combination of samples as in Mixup, exploits distance weighted k-Nearest Neighbours technique to infer the soft labels. Their algorithm termed <code>distance-weighted soft-label prototype k-Nearest Neighbours (SLaPkNN)</code> essentially takes the sum of the label vectors of the k-nearest prototypes to target point x, with each prototype weighted inversely proportional to its distance from x. The following figure shows 4 class datasets are merged into 2 samples using SLaPkNN.</p> <p> Figure LO-Shot: LO Shot splitting 4 class space into 2 points 11.</p> <p>In my understanding that is the main theoretical difference between the two techniques, with the other difference being mixup only merges two samples into one using a probability drawn from beta distribution combined using <code>\u03bb</code> and <code>1-\u03bb</code> whereas LO is more versatile and can compress greatly.  I am not saying mixup cant be extended to be more multivariate but that empirical analysis of such approach is unknown; whereas with 11 its been shown SLaPkNN can compress 3M \u2212 2 classes into M samples at least. </p> <p>The technical explanation for this along with code is available here.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#22-pruning","title":"2.2. Pruning","text":"<p>Pruning is a subclass of compression techniques wherein samples that are not really helpful or effective are dropped out whereas selected samples are kept as is without any loss in content. Following are some of the known techniques of dataset pruning:</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#221-coresets","title":"2.2.1 Coresets","text":"<p>Coreset selection technique pertains to subsampling from a large dataset to a smaller set that almost approximates the given large set. This is not a new technique and has heavily been explored using hand-engineered features and simpler models like Markov models to approximate the smaller set. This is not a DL-specific technique either and has its place in classical ML as well. An example could be using na\u00efve Bayes to select coresets for more computationally expensive counterparts like decision trees. </p> <p>In deep learning, using a similar concept, a lighter-weight DL model can be used as a proxy to select the approximate dataset 15. This is easier achieved when continual learning is practiced otherwise it can be a very expensive technique in itself given proxy model needs to be trained with a full dataset first. This becomes especially tricky given the proxy and target models are different and also when the information in the dataset is not concentrated in a few samples but uniformly distributed over all of them. These are some of the reasons why this approach is not very successful.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#222-example-forgetting","title":"2.2.2 Example forgetting","text":"<p>An investigation 14 reported that some samples once learned are never forgotten and exhibit the same behavior across various training parameters and hyperparameters. There are other classes of samples that are forgotten. The forgetting event was defined as when the model prediction regresses in the subsequent epoch. Both qualitative and qualitative (see fig 6 and 7) analysis into such forgotten samples indicated noisy labels, images with \"uncommon\" visually complicated features were the main reasons for example forgetting.</p> <p> Figure 6: Algorithm to track forgotten samples 14.</p> <p> Figure 7: Indicating how increasing fraction of noisy samples led to increased forgetting events 14.</p> <p>An interesting observation from this study was that losing a large fraction of unforgotten samples still results in extremely competitive performance on the test set. The hypothesis formed was unforgotten samples are not very informative whereas forgotten samples are more informative and useful for training. In their case, the forgetting score stabilized after 75 epochs (using RESNET &amp; CIFAR but the value will vary as per model and data).</p> <p>Perhaps a few samples are enough to tell that a cat has 4 legs, a small face, and pointy ears, and it's more about how different varieties of cats look especially if they look different from the norm e.g. Sphynx cats.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#223-using-gradient-norms","title":"2.2.3 Using Gradient norms","text":"<p>Loss functions are an excellent measure to find interesting samples in your dataset whether these may be poorly labeled or really outlier samples. This was highlighted by Andrej Karpathy as well:</p> <p>When you sort your dataset descending by loss you are guaranteed to find something unexpected, strange, and helpful.</p> <p>Personally, I have found loss a very good measure to find poorly labeled samples. So, the natural question would be \"should we explore how we can use the loss as a measure to prune the dataset?\". It's not until NeurIPS 2021, 21 that this was properly investigated. This Standford study looked into the initial loss gradient norm of individual training examples, averaged over several weight initializations, to prune the dataset for better generalization. This work is closely related to example forgetting except that instead of performance measure the focus more is on using local information early in training to prune the dataset. </p> <p>This work proposes GraNd score of a training sample (x, y) at time t given by L2 norm of the gradient of loss computed on that sample and also expected loss L2 norm termed EL2N (equation below). The reasoning here is that samples with a small GraNd score have abounded influence on learning how to classify the rest of the training data at a given training time. Empirically, this paper found that averaging the norms over multiple weight initializations resulted in scores that correlate with forgetting scores 14 and leads to pruning a significant fraction of samples early in training. They were able to prune 50% of the sample from CIFAR-10 without affecting accuracy, while on the more challenging CIFAR-100 dataset, they pruned 25% of examples with only a 1% drop in accuracy.  $ \\begin{equation} \u03c7_t(x, y) = E_{w_t} || g_t(x, y)||_2  \\ \\tag*{GraNd eq} \\  \\end{equation} $</p> <p>$ \\begin{equation} \u03c7_t(x, y) = E || p(w_t, x) - y)||_2  \\ \\tag*{EL2N eq} \\  \\end{equation} $</p> <p>This is a particularly interesting approach and is a big departure from other pruning strategies to date which treated samples in the dataset independently. Dropping samples based on independent statistics provides a weaker theoretical guarantee of success as DL is a non-convex problem 21.  I am very curious to find out how mixup impacts the GraNd scores given it shown (see figure 5b) using mixup leads to smaller gradient norm (l1 albeit).</p> <p> Results of prunning with GradNd and EL2N 21.</p> <p>The results from this study are shown in the fig above. Noticeably high pruning is not fruititious even with this approach despite how well it's doing on CIFAR-10 and 100 datasets. Are we retaining the data distribution when we drop large samples? Mostly not and that is only reasoning that makes sense. And we circle back to how much pruning is enough? Is that network dependent or more a property of data and its distribution? This study 21 claims that GradND and EL2N scores, when averaged over multiple initializations or training trajectories remove dependence on specific weights/networks, presenting a more compressed dataset. If this assertion holds in reality, in my view, this is a very promising finding easing the data-related challenges of DL.</p> <p>What's more fascinating about this work is that it sheds light on how the underlying data distribution shapes the training dynamics. This has been amiss until now. Of particular interest is identifying subspaces of the model's data representation that are relatively stable over the training.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#23-distillation","title":"2.3. Distillation","text":"<p>Distillation technique refers to the methodologies of distilling the knowledge of a complex or larger set into a smaller set. Knowledge or model distillation is a popular technique that compresses the learned representation of a larger model into a much smaller model without any significant drop in performance. Using student-teacher training regime have been explored extensively even in the case of transformer networks that are even more data-hungry than more conventional network say Convolution network DeiT. Despite being called data-efficient, this paper employs a teacher-student strategy to transform networks, and data itself is merely treated as a commodity. </p> <p>Recently, this concept is investigated for use in deep learning for dataset distillation with aim of synthesizing an optimal smaller dataset from a large dataset 17,16. The distilled dataset are learned and synthesized but in theory, they approximate the larger dataset. Note that the synthesized data may not follow the same data distribution.</p> <p>Some dataset distillation techniques refer to their approach as compression as well. I disagree with this in principle as compression albeit lossy in this context, refers to compressing the dataset whereas with distillation the data representation is deduced/synthesized - potentially leading to entirely different samples together. Perhaps it's the compressibility factor a.k.a compression ratio that applies to both techniques. For example, see figure 13 shows the extent to which distilled images can change.</p> <p>A dataset distillation 17 paper quotes:</p> <p>We present a new optimization algorithm for synthesizing a small number of synthetic data samples not only capturing much of the original training data but also tailored explicitly for fast model training in only a few gradient steps 17.</p> <p>Their problem formulation was very interesting! they derive the network weights as a differentiable function of the synthetic training data and set the training objective to optimize the pixel values of the distilled images The result from this study showed that one can go as low as one synthetic image per category while not regressing too much on the performance. More concretely, they distilled 60K training images of the MNIST digit dataset into only 10 synthetic images (one per class) yields a test-time MNIST recognition performance of 94%, compared to 99% for the original dataset). </p> <p> Figure 8: Dataset distillation results from FAIR study 17.</p> <p>Here are some of the distilled samples for the classes labeled at the top (fig 9). It's amazing how well the MNIST trained on these sets does but CIFAR one misses the mark only being about as good as random (54%) compared to 80% on the full dataset(fig 8 &amp; 9).</p> <p> Figure 9: Dataset distillation results from FAIR study 17.</p> <p>Following this work, another distillation technique was proposed utilizing kernel methods - more specifically kernel ridge regression to obtain \u03b5-approximate of original datasets 18. This technique is termed Kernel Inducing Points (KIP) and follows the same principle for keeping the objective function to maximize the approximation and backpropagate the gradients to learn synthesized distilled data. The difference between 18 and 17 is one 17 uses the same DL network while the other 18 uses kernel techniques. With KIP, another advantage is that not just source samples but optionally labels can be synthesized too. In 17, the objective was purely to learn pixel values and thus the source (X). This paper 18 also proposes another technique Label Solve (LS) in while X is kept constant and only label (Y) is learned.</p> <p> Figure 10: Examples of distilled samples a) with KIP and b) With LS 18.</p> <p>The CIFAR 10 result from 17 (fig 9) was about 36.79% for 10 samples, with KIP there is a slight gain in performance there given the extreme compression. This raises the question of what is a good compression ratio that can guarantee good information retention. For complex tasks like CIFAR (compared to MNIST), 10 (one per sample) may not be enough given how complex this dataset is comparatively. </p> <p> Figure 11: CIFAR10 result from KIP and LS 18.</p> <p>Actually, LO shot technique 11, discussed previously, is also a specialized form of X-shot technique that does dataset distillation. Aside from that, gradient-based techniques for dataset distillation have been actively investigated in the last few years (ref 16,17,18,19,20). Another approach explored siamese augmentation method termed  <code>Differentiable Siamese Augmentation (DSA)</code>  that uses matching loss and synthesizes dataset through backpropagation techniques 16</p> <p> Figure 12: Differentiable Siamese Augmentation 16.</p> <p>Bayesian and gradient-descent trained neural networks converge to Gaussian processes (GP) as the number of hidden units in intermediary layers approaches infinity 20 (fig 13). This is true for convolutional networks as well as they converge to a particular gaussian processes channel limits are stretched to infinity. These networks can thus be described as kernels known as Neural Tangent Kernel (NTK). Neural Tangents library based on JAX an auto differentiation toolkit has been used in applying these kernels in defining some of the recent distillation methods. References 18,20,21 are one such examples.  </p> <p> Figure 13: Infinite width Convolution networks converging to infinity 20.</p> <p>The authors of KIP and LS techniques 18 explore how to scale and accelerate the distillation process to apply these techniques to infinitely wide convolutional networks 20. Their results are very promising (see fig 14).</p> <p> Figure 14: KIP ConvNet results 20.</p> <p>A visual inspection into the distilled dataset from the infinite width CNN-based KIP technique is shown in fig 15. The distillation results are curious, to say the least. In the example, the distilled apple image seems to represent a pile of apples whereas the bottle distilled results into visibly different bottles while still showing artifacts of the original two bottles. While other classes show high order features (with some noise). </p> <p> Figure 15: KIP ConvNet example of distilled CIFAR set 20.</p> <p>Figure 16 shows MNIST results, they are not only very interesting but also look very much like mixup (where x and y both are mixed).</p> <p> Figure 16: KIP ConvNet example of distilled MNIST set 20.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#3-so-what-if-you-have-noisy-data","title":"3. So what if you have noisy data","text":"<p>Noises in the dataset are considered a nuisance. Because models hold the compressed form of knowledge represented by the dataset, dataset curation techniques carefully look to avoid noises in datasets. </p> <p>Noises can be an incredibly powerful technique to fill in the missing information in source/images. For instance, if only part of an image is known then instead of padding the image with default (0 or 1-pixel value), filling in using random noise can be an effective technique avoiding confusion on actual real values that relate to the black or white region. This has held true in my own experience. It was very amusing to note that the forgetting event study 14 in fact looked into adding label noise on the distribution of forgetting events. They added noise in pixel values and observed that adding an increasing amount of noise decreases the number of unforgettable samples (see also figure 7 for their results when noise was used). </p> <p>Noise coming from randomness is handled very well by DL networks as well. I find the result from 22, shown in figure 17 quite fascinating actually. Looking at how well the model is doing when missing patches are random and how poor it is doing when missing patches are systematic is indicative of how powerful and lame (both at the same time) machines are! </p> <p> Figure 17: Noisy patches in Masked-AutoEncoder 22.</p> <p>GradND study 21, looked into the effect of noise on the source itself and performed a series of experiments to conclude that when there is enough data, keeping the high score examples, which are often noisy or difficult, does not hurt performance and can only help.</p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#conclusion","title":"Conclusion","text":"<p>In summary, the last four years have been incredibly exciting for data in DL space and the year 2021 even more! There is a lot of mileage we can get out of simpler techniques like MixUp but more exciting developments are dissecting the training dynamics and exploring the importance of samples in solving a particular task using DL techniques. Distillation methods are still in the early stages where they work well for simpler datasets but honestly how many real-world problems have simple datasets? Nevertheless, some really exciting development in this space. These techniques can be groundbreaking if the compression methods hold across a wide range of architectures as indicated by 21. </p>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2021/12/31/data-in-deep-learning/#references","title":"References","text":"<ol> <li>[1707.02968] Revisiting Unreasonable Effectiveness of Data in Deep Learning Era.\u201d Accessed January 3, 2022. https://arxiv.org/abs/1707.02968.</li> <li>Hestness, Joel, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou. \u201cDeep Learning Scaling Is Predictable, Empirically,\u201d December 2017. https://arxiv.org/abs/1712.00409.</li> <li>https://www.wired.com/story/no-data-is-not-the-new-oil/</li> <li>https://pages.run.ai/hubfs/PDFs/2021-State-of-AI-Infrastructure-Survey.pdf</li> <li>[1808.01974] A Survey on Deep Transfer Learning. Accessed January 5, 2022. https://arxiv.org/abs/1808.01974.</li> <li>Transfer Learning. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.1515&amp;rep=rep1&amp;type=pdf</li> <li>Zhang, Hongyi, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. \u201cMixup: Beyond Empirical Risk Minimization,\u201d October 2017. https://arxiv.org/abs/1710.09412.</li> <li>[1812.01187] Bag of Tricks for Image Classification with Convolutional Neural Networks. Accessed December 30, 2021. https://arxiv.org/abs/1812.01187.</li> <li>[2009.08449] 'Less Than One'-Shot Learning: Learning N Classes From M &lt; N Samples. Accessed January 5, 2022. https://arxiv.org/abs/2009.08449.</li> <li>[1512.00567] Rethinking the Inception Architecture for Computer Vision. Accessed January 5, 2022. https://arxiv.org/abs/1512.00567.</li> <li>[1904.05046] Generalizing from a Few Examples: A Survey on Few-Shot Learning. Accessed January 5, 2022. https://arxiv.org/abs/1904.05046.</li> <li>Li Fei-Fei, R. Fergus and P. Perona, \"One-shot learning of object categories,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 4, pp. 594\u2013611, April 2006, doi: 10.1109/TPAMI.2006.79. https://ieeexplore.ieee.org/document/1597116</li> <li>[1606.04080] Matching Networks for One Shot Learning. Accessed January 5, 2022. https://arxiv.org/abs/1606.04080.</li> <li>[1812.05159] An Empirical Study of Example Forgetting during Deep Neural Network Learning. Accessed December 29, 2021. https://arxiv.org/abs/1812.05159.</li> <li>[1906.11829] Selection via Proxy: Efficient Data Selection for Deep Learning. Accessed December 29, 2021. https://arxiv.org/abs/1906.11829.</li> <li>[2102.08259] Dataset Condensation with Differentiable Siamese Augmentation. Accessed January 5, 2022. https://arxiv.org/abs/2102.08259.</li> <li>[1811.10959] Dataset Distillation. Accessed January 5, 2022. https://arxiv.org/abs/1811.10959.</li> <li>[2011.00050] Dataset Meta-Learning from Kernel Ridge-Regression. Accessed January 5, 2022. https://arxiv.org/abs/2011.00050.</li> <li>[2006.05929] Dataset Condensation with Gradient Matching. Accessed January 5, 2022. https://arxiv.org/abs/2006.05929.</li> <li>[2107.13034] Dataset Distillation with Infinitely Wide Convolutional Networks. Accessed January 5, 2022. https://arxiv.org/abs/2107.13034.</li> <li>[2107.07075] Deep Learning on a Data Diet: Finding Important Examples Early in Training. Accessed December 10, 2021. https://arxiv.org/abs/2107.07075.</li> <li>[2111.06377] Masked Autoencoders Are Scalable Vision Learners. Accessed January 5, 2022. https://arxiv.org/abs/2111.06377.</li> <li>[1802.03426] UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. Accessed January 5, 2022. 23. https://arxiv.org/abs/1802.03426.</li> <li>Maaten, Laurens van der and Geoffrey E. Hinton. \"Visualizing Data using t-SNE.\" Journal of Machine Learning Research 9 (2008): 2579\u20132605. https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf</li> <li>[2107.02331] Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering.\u201d Accessed January 8, 2022. https://arxiv.org/abs/2107.02331</li> </ol>","tags":["blog","deep-learning","machine-learning","data-science","advanced"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/","title":"Pydra - Pydantic and Hydra for configuration management of model training experiments","text":"<p>How do you manage the configurations of your model training experiments? Having good configuration management in place improves the user experience and simplifies experiment management. Some of the indirect advantages of having a good config solution are clean, reliable, and simple application code. This is true for any software application however some applications demand higher investment on the config piece than others. One key differentiator perhaps here is how many config fields one has and how each of these relates to the other. This can get real messy real quick with deep learning experiments where the list of config and hyperparameters can rapidly grow out of hand as soon as one breaks out of adhoc experimentations.</p> <ul> <li>Pydra - Pydantic and Hydra for configuration management of model training experiments</li> <li>Context</li> <li>Hydra<ul> <li>A simple non-structured config example</li> <li>An extension using structured config</li> <li>Some other interesting features of hydra</li> <li>Interpolation</li> <li>Hydra Directives</li> <li>Where Hydra falls short?</li> </ul> </li> <li>Pydantic<ul> <li>An few interesting notes</li> <li>Can Pydantic bridge the gaps in hydra</li> </ul> </li> <li>How well does this integrate with other ecosystem tools</li> <li>Version config</li> <li>Conclusion</li> </ul>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#context","title":"Context","text":"<p>By definition model training configurations are hierarchial. For example, an experiment configuration can be broken down into data and model specifications. While these are loosely coupled specifications, they may enforce some degree of restrictions on each other e.g. model's output specification needs to be in line with data specification. A classifier network needs to output a 10 length vector if the data source is MNIST and 20 if it's PASCAL VOC. </p> <p>Overall, configuration solution for training experiments has following requirements:</p> <ol> <li>Ability to easily templatize configurations of various components of your training experiments.</li> <li>Ability to organize the configuration of training in a hierarchical fashion acknowledging the dependency and hierarchy of participating components.</li> <li>Without duplication, reuse configurations across modules wherever needed by means such as interpolation, expressions.</li> <li>Ability to compose config using templates and applying customization through overrides, environments etc.</li> <li>Being able to store and reuse the final assembled/compiled config and reproduce the experiments reliably.</li> <li>Support structured config consisting of potentially complex, canonical python types with strong validation support beyond type hint. This perhaps is optional if one is not interested in dynamic domain-specific validations - something that can not be achieved in serialized formats like yaml/json.</li> <li>Ability to version config and enforce a schema on the config specification for reliability and robustness.</li> <li>Ability to integrate easily into complex distributed launcher frameworks for both local and remote launch.</li> <li>A configuration management that nicely integrates into your echo-system of tools and is not very dictative.</li> </ol> <p>With that in mind, I evaluated a bunch of tools combination of Hydra and Pydantic stood out as a good choice. In this post, I will go over my learnings of both the tools and also talk about gaps I still see present. Lastly, put forth a tentative solution for this gap. The structure of this post is as follows:</p> <ol> <li>Hydra - its strengths and also, what I think are its weakness.</li> <li>Pydantic - how it can be used to fill in the void of Hydra</li> <li>The missing bits of config management from Pydra i.e. both Hydra &amp; Pydantic</li> <li>The solution to bridging the gap</li> <li>Conclusion</li> </ol> <p>Note: The samples and code shared in this post are available here.</p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#hydra","title":"Hydra","text":"<p>Hydra is a dynamic hierarchical config management tool with the ability to override parts of the config and also to compose the config through various sources (eg command line args, environment variables). It offers a nice solution to templated configurations that can be repurposed dynamically based on your objectives. Beyond rewriting rules, compositions, and interpolations to re-config templates, it also provides a mechanism to represent the config in plain old python object style and can take care of serialization and deserialization itself. On some noteworthy features side - with hydra you can fire multi-process workload on multiple instances of configurations derived from the same template source. This can be a really handy feature for many use cases including side-by-side comparisons. </p> <p>It is also extensible in a way that one can write their plugins to launch local or remote workload. Some other nice noteworthy features are runner config and callbacks. All in all, powered by OmegaConf this is a great tool for config management. </p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#a-simple-non-structured-config-example","title":"A simple non-structured config example","text":"<p>Let's look at a simple use of hydra for yaml based config without involving python object model for config.  This example is borrowed and extended from a hydra sample. . this example demonstrates 3 config modules i.e. db, schema and ui assembled togather via high level config.yaml. </p> <p> Example hierarchical hydra config.</p> <p><pre><code>import logging\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\nimport hydra\nfrom hydra.core.config_store import ConfigStore\nfrom hydra.core.hydra_config import HydraConfig\nfrom omegaconf import MISSING, DictConfig, OmegaConf\n\nlog = logging.getLogger(__name__)\n\n\n@hydra.main(config_path=\"conf\", config_name=\"config\")\ndef my_app(cfg: DictConfig) -&gt; None:\n    log.info(\"Type of cfg is: %s\", type(cfg))\n    cfg_dict = OmegaConf.to_container(cfg, throw_on_missing=False, resolve=True)\n\n    log.info(\"Merged Yaml:\\n%s\", OmegaConf.to_yaml(cfg))\n\n    log.info(cfg.db)\n    log.info(cfg.db.driver)\n\n    log.info(HydraConfig.get().job.name)\n\n\nif __name__ == \"__main__\":\n    my_app()\n</code></pre> Sample code can be found here</p> <p>A few things happening in this script: 1. How is config loaded:    The above script tells hydra to look for hierarchical config under <code>conf</code> as a base location for config directory, and <code>config.yaml</code> as top-level config specification. This setting is defaulted by python decorator <code>@hydra.main(config_path=\"conf\", config_name=\"config\")</code>.    A user can override these settings and point the config location to another place by using <code>--config-dir</code> for the base directory and <code>--config-name</code> for top-level config.yaml as follows: <pre><code>python my_app_non_structured.py --config-dir conf_custom_hydra\npython my_app_non_structured.py --config-name config_hydra\n</code></pre> 2. What format can I access config:     Once hydra has loaded the config, it will be loaded as dict/dictionary and surfaced as <code>DictConfig</code> from OmegaConf. The benefit <code>DictConfig</code> is you can access the fields as variable accessors e.g. <code>cfg.db.driver</code> as shown in code above instead of dict str key access pattern. 3. Where is composition coming from:     What's defined in <code>conf</code> directory is template config. Some values may be missing - which can be represented in yaml as <code>???</code>. It's also possible to override some values from the template config at runtime. An example of this is:     <code>python my_app_non_structured.py db.user=suneeta</code>     Here, the final used configuration that the application will see is: <pre><code>db:\n  driver: mysql\n  user: suneeta\n  pwd: secret\nui:\n  create_db: true\n  view: true\nschema:\n  database: school\n  tables:\n  - name: students\n  - name: exams\n</code></pre> 4. What is the final config used in my run:   Hydra saves the specifics of the config used in the run in its output location. By default the output location is    <code>outputs/YYYY-MM-DD/HH-MM-SS/.hydra/config.yaml</code> which can be used to rerun the same run for reproducibility.  <pre><code>python my_app_non_structured.py --config-dir=outputs/2022-03-16/13-45-29/.hydra\n</code></pre>   Hydra also allows you to configure job and run settings, an example of such configuration is located here.   Alternatively, one can also override these settings in the main config.yaml file:</p> <p><pre><code>defaults:\n  - _self_  # Note: to source default of hydra config \n  - db: mysql\n  - ui: full\n  - schema: school\n\nhydra:\n  job:\n    env_set: \n      HDF5_USE_FILE_LOCKING: \"false\"\n      ## Useful for distributed train setup\n      # RANK: ${hydra.job.num}\n    env_copy: ## Local environment copy\n      - API_KEY  \n\n  job_logging:\n    version: 1\n    formatters:\n      simple:\n        format: \"[%(levelname)s] - %(message)s\"\n    handlers:\n      console:\n        class: logging.StreamHandler\n        formatter: simple\n        stream: ext://sys.stdout\n    root:\n      handlers: [console]\n\n    disable_existing_loggers: false\n\n  run:\n    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}\n</code></pre> 5. Multi-run and templates: Multi-run allows users to run the multi-process workload on the same template of config but dynamically changing some values of it. Effectively, the user will be running multiple processes of the same code under different configurations. Parameter sweeps are a really good use case for when this may come in handy. In the following run, <code>multirun</code> is doing the trick triggering 3 different processes each for schema of school, support, and warehouse.  <pre><code>python my_app_non_structured.py db.user=suneeta schema=school,support,warehouse  --config-dir conf_custom_hydra --multirun\n</code></pre></p> <p>Each process gets an int id assigned which the application can recognize. The index starts from 0, as shown in fig below. </p> <p> Example Of multi-runs.</p> <p>This is especially useful in distributed training runs where things like RANK of process needs to be known. This can be easily configured using hydra as following: <pre><code>hydra:\n  job:\n    env_set: \n      RANK: ${hydra.job.num}\n</code></pre></p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#an-extension-using-structured-config","title":"An extension using structured config","text":"<p>If your application configs are slightly more complex and you might want object representation of your config then Hydra provided structured config option with <code>ConfigStore</code>. An example of this is here.</p> <p>In this case, you define your config object model as follows: <pre><code>@dataclass\nclass DBConfig:\n    user: str = MISSING\n    pwd: str = MISSING\n    driver: str = MISSING\n    timeout: int = 100\n\n\n@dataclass\nclass MySQLConfig(DBConfig):\n    driver: str = \"mysql\"\n\n\n@dataclass\nclass PostGreSQLConfig(DBConfig):\n    driver: str = \"postgresql\"\n\n\n@dataclass\nclass View:\n    create_db: bool = False\n    view: bool = MISSING\n\n\n@dataclass\nclass Table:\n    name: str = MISSING\n\n\n@dataclass\nclass Schema:\n    database: str = \"school\"\n    tables: List[Table] = MISSING\n\n\n@dataclass\nclass Config:\n    # We can now annotate db as DBConfig which\n    # improves both static and dynamic type safety.\n    db: DBConfig\n    ui: View\n    schema: Schema\n</code></pre> A few things noteworthy to call out here: 1. <code>MISSING</code> is the replacement of yaml equivalent of missing denoted as <code>???</code>.  2. Hydra can only work with plain old python objects and at best with dataclasses or drop-in replacements of <code>dataclasses</code>. 3. Structured config can not work with python primitives and cant serde (serialize and deserialize) canonical or complex python objects. Not even things like python pathlib <code>Path</code>. </p> <p>Once, the config object model is done, one should define <code>ConfigStore</code> and register config objects: <pre><code>cs = ConfigStore.instance()\ncs.store(name=\"config\", node=Config)\ncs.store(group=\"db\", name=\"mysql\", node=MySQLConfig)\ncs.store(group=\"db\", name=\"postgresql\", node=PostGreSQLConfig)\ncs.store(name=\"ui\", node=View)\ncs.store(name=\"schema\", node=Schema)\n</code></pre></p> <p>Here, <code>group</code> key in config registry indicates mutually exclusive groups. More about these can be found here.</p> <p>How does hydra injection change then to support config store?  Not by a lot, as shown in this example, changing <code>DictConfig</code> to your high-level config object <code>Config</code> in this case does the trick. Then, <code>OmegaConf.to_object(cfg)</code> unpacks dict config in your python object model.  <pre><code>@hydra.main(config_path=\"conf\", config_name=\"config\")\ndef my_app(cfg: Config) -&gt; None:    \n    log.info(\"Type of cfg is: %s\", type(cfg))\n    cfg_dict = OmegaConf.to_container(cfg, throw_on_missing=False, resolve=True)\n\n    cfg_obj = OmegaConf.to_object(cfg)\n</code></pre></p> <p>This is all the application needs to do to move to structured config and features discussed earlier can be explored using the following commands: <pre><code>python my_app.py\npython my_app.py db.user=suneeta    \npython my_app.py db.user=suneeta --config-dir conf_custom_hydra\n# python my_app.py db.user=suneeta --config-name config_hydra\n# Multi-run\npython my_app.py db.user=suneeta schema=school,support,warehouse  --config-dir conf_custom_hydra --multirun\n</code></pre> Code located here</p> <p>There is another approach Hydra offers to instantiate objects through the config. This approach requires the user to know which config is object-able beforehand as unpacking them into objects requires explicit calls to <code>instantiate</code> API.  An example of such use is as follows, notice fully qualified class name in <code>__target__</code> field in config:</p> <p> Example Of instantiate objects.</p> <p>This feature, in my view, should be used sparingly as it tightly couples the config to application-specific objects. This kind of mixed-breed config handling approach is very hard to maintain and understand.</p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#some-other-interesting-features-of-hydra","title":"Some other interesting features of hydra","text":"","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#interpolation","title":"Interpolation","text":"<p>Interpolation offers a means to refer to an existing config instead of duplicating it. It also allows users to use derive values obtained through string interpolation in config. An example of interpolation is shown below:</p> <p> Example Of instantiate objects.</p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#hydra-directives","title":"Hydra Directives","text":"<p>Hydra allows overriding package configuration employing directives; documentation for these is here. In short, they offer means to rewrite and relocate config dynamically.  I think this is evil and facilitates yaml engineering. It can also be a debugging nightmare if your intended use of config is beyond standard interfaces. </p> <p> Example Of directives to rewrite config specifications.</p> <p>Talking about directives, <code>__global__</code> are quite handy in managing configuration overrides. One example is shown here on hydra samples itself</p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#where-hydra-falls-short","title":"Where Hydra falls short?","text":"<p>Overall, OmegaConf and Hydra are two powerful tools for config management, however, I personally find the following shortcoming in these tools:</p> <ol> <li> <p>No support to serde (serialize and deserialize) canonical or complex python objects can be really annoying and causes more overhead for applications. Only primitive supports are a good start. </p> <p>1.1. OmegaConf and Hydra does not support <code>Union</code> type in the config either.</p> </li> <li> <p>Support for structured config type is limited to plain old Python objects or dataclasses (and drop-in replacement thereof).</p> </li> <li> <p>Validation framework is a must-have in any config management framework. Anything users provide must be validated in the application for various things like type-checking, application-specific validation, constraint limits, etc. This is currently offloaded largely to application. The choice application is left with is using structured config as simple objects and performing all validation explicitly including obvious things like type checking. This is limiting in my view.</p> </li> <li> <p>Interpolation is great to have feature. Extension to this is being able to run expression-based interpolations eg list of items to the total item in the list. However, this support is lacking in Hydra with issues being raised.</p> </li> </ol>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#pydantic","title":"Pydantic","text":"<p>Pydantic offers a runtime type enforcement and validation and is itself a data validation and settings management tool. It works with pure canonical python data models and provides two approaches for this: 1. Drop in replacement of dataclass 2. BaseModel abstraction</p> <p>Through its validation framework and type checking pydantic offers schema enforcement and can serialize and deserialize objects from various formats including but not limited to yaml/json, xml, ORM, etc. Its field type support especially constrained types are very rich and vastly simplifies application config validations. Eg can the image size be less than 0? What's the best approach to validate this? limit at config level or sprinkle that in the application where config is used?</p> <p>Overall, pydantic is a well-documented library, an example of its dataclass use is as shown below: <pre><code>import logging\nimport sys\nfrom pathlib import Path\nfrom typing import Optional, Union\n\nfrom pydantic import BaseModel, conint, validator\nfrom pydantic.dataclasses import dataclass\n\n\nlog = logging.getLogger(__name__)\n\n\n@dataclass\nclass Dataset:\n    name: str\n    path: str\n\n    @validator(\"path\")\n    def validate_path(cls, path: str) -&gt; Path:\n        if Path(path).exists():\n            print(\"exist\")\n        return Path(path)\n\n\n@dataclass\nclass Model:\n    type: str\n    num_layers: conint(ge=3)\n    width: Optional[conint(ge=0)]\n\n    @validator(\"type\")\n    def validate_supported_type(cls, type: str) -&gt; str:\n        if type not in [\"alex\", \"le\"]:\n            raise ValueError(f\"'type' canonly be [alex, le] got: {type}\")\n        return type\n\n\n@dataclass\nclass Config:\n    dataset: Dataset\n    model: Model\n</code></pre> Notice the use of the validator decorator here. This is an approach to validate for application-specific logics.</p> <p>BaseModel comes with more bells and whistles as it provides syntactic sugar of <code>Config</code> inner class that can be used to configure the behavior of a concrete implementation of BaseModels. Details of this can be found here. Some of the settings like <code>anystr_lower</code> and <code>use_enum_values</code> are so handy. Who does not want to work with case insensitive configurations but keep the application clear of case conversions? Like BCE and bce means any different than binary cross entropy? BaseModel implementation looks like this:</p> <p><pre><code>class Dataset(BaseModel):\n    name: str\n    path: str\n\n    @validator(\"path\")\n    def validate_path(cls, path: str) -&gt; Path:\n        if Path(path).exists():\n            print(\"exist\")\n        return Path(path)\n\n    class Config:\n        title = \"Dataset\"\n        max_anystr_length = 10\n        allow_mutation = False\n        validate_assignment = True\n        anystr_lower = True\n        validate_all = True\n        use_enum_values = True \n</code></pre> Full example code is located here</p> <p>BaseSettings is also another great feature that seeks to abstract away settings/config that is sourced from other sources like an environment variable, init files, etc. <pre><code>class Secrets(BaseSettings):\n    api_key: str = Field(\"\", env=\"api_key\")\n    token: str\n\n    class Config:\n        # case_sensitive = True\n        env_nested_delimiter = \"_\"\n\n        @classmethod\n        def customise_sources(\n            cls,\n            init_settings: SettingsSourceCallable,\n            env_settings: SettingsSourceCallable,\n            file_secret_settings: SettingsSourceCallable,\n        ) -&gt; Tuple[SettingsSourceCallable, ...]:\n            return env_settings, init_settings, file_secret_settings\n</code></pre></p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#an-few-interesting-notes","title":"An few interesting notes","text":"<ol> <li>It's interesting to note that the validator of pydantic can be repurposed to implement derived fields. An example of this is captured here: The use-case being, a list of classes is already provided in config in another module say data. You want to \"infer\" the total number of classes from this in the model config. In this case, you can interpolate and copy over a list of classes from the data module to model but your requirement of actually only caring about total classes is unfulfilled as you cant do expression-based interpolation just yet.  In this case, <code>total_classes</code> can be defined as either list of int and then the total is deduced upon validation, leaving your in config object always representing total int value and logic-based deduction happening upon validation. Example of this is as follows:</li> </ol> <p><pre><code>from typing import List, Union\nfrom pydantic import BaseModel, conint, validator\n\nclass Model(BaseModel):\n    total_classes: Union[conint(ge=0), List[conint(ge=0)]]\n\n    @validator(\"total_classes\")\n    def validate_classes(cls, total_classes: Union[conint(ge=0), List[conint(ge=0)]]) -&gt; conint(ge=0):\n        if isinstance(total_classes, List):\n            return len(total_classes)\n        return total_classes\n</code></pre> I have not seen any issue in the use of validator like this but unsure if this is the intended use of validator support. Also, unsure why the validator returns in the said interface. </p> <ol> <li>Hydra's benchmarking is pretty favorable (see image below). However, they dont benchmark against OmegaConf and some other related tools, see details here. </li> </ol> <p> Hydra's benchmarks.</p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#can-pydantic-bridge-the-gaps-in-hydra","title":"Can Pydantic bridge the gaps in hydra","text":"<p>Pydantic offers a strong validation framework something that's been missing in hydra. While drop-in replacement of pydantic dataclass works with hydra one can still miss out on the syntactical sugars of Model Config and still be limited to primitives and non Union types and more interesting constrained types of pydantic. </p> <p>It's fair to say that direct integration of hydra with pydantic is absent. The follow-up question should be, can we make it work? Sure we can :). </p> <p>An example demonstrating how Hydra and Pydantic can be used in conjunction is shown here. The secret sauce of integration lies in the following:</p> <ol> <li>Giving up on the use of <code>ConfigStore</code> of hydra</li> <li>Reading the config as <code>DictConfig</code> and unpacking to Pydantic BaseModel object via dict</li> </ol> <p>In short, this is two-liner: <pre><code>    OmegaConf.resolve(cfg)\n    r_model = Config(**cfg)\n</code></pre> where <code>Config</code> is a concrete implementation of Pydantic's BaseModel. The decision we make it here is configs are specified in yaml format and we leave Hydra to manage template, composition, and all the good things of non-structured config management. Upon resolution and merge of config, we deserialize with Pydantic and get all the goodies of Pydantic validation, check, etc.</p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#how-well-does-this-integrate-with-other-ecosystem-tools","title":"How well does this integrate with other ecosystem tools","text":"<p>Given hydra can provide a final configuration in dict format, the configuration side can easily integrate with echo-system tools that care about configs. Given most experiment management and tracking tools support managing config as dict, this is less of a challenge. A post from Weights and biases goes in detail about integration. </p> <p>It's interesting to note that other features of Hydra like multirun and sweeps given they employ multi-processing may interfere with other tools employing MP techniques too. </p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#version-config","title":"Version config","text":"<p>Versioning is very important practice to follow if one works with large, actively evolving code base. For the same reasons as REST APIs should be versioned, docker images are versioned, library releases are versioned, and so on, application config specifications should be versioned as well. If not for incremental updates then at least for breaking changes. Kubernetes actually does this really well, where users can bring their resource specification of supported version and it can work with that version creating ../resources for you. There is lot more complexity in config management that Kubernetes immplements but whats transferable here in my view is:</p> <ol> <li>When creating a run, always use latest version of config.</li> <li>Have a support in place where you can migrate your old configs to latest version of config so you can reproduce [not repeat] your experiments with newer features should you need to.</li> </ol> <p>This prototype is a toy example to explore how to handle versioning in the config and provide a migration path for when old version config is provided. The assumption made here is, your training code only ever works with the latest version of config so the application code is simple and is always progressive. Whenever a breaking change is introduced, a new float version of config is created while the preceding version of config implements a migration path to the following version.</p> <p>Code shown below, represents Model config which has 3 versions <code>v</code> i.e. 1.0, 2.0, 3.0. Each version makes a breaking change to the previous but each concrete implementation implements a method <code>def to_next(self) -&gt; Optional[BaseModel]</code> that cracks at migrating the config to a new specification.  <pre><code>class VersionModel(BaseModel, abc.ABC):\n    v: Literal[\"inf\"] = Field(float(\"inf\"), const=True)\n\n    class Config:\n        title = \"Model\"\n        allow_mutation = False\n        max_anystr_length = 10\n        validate_assignment = True\n        anystr_lower = True\n        validate_all = True\n        use_enum_values = True\n\n    def version(self) -&gt; float:\n        return self.v\n\n    def _next_version_model(self) -&gt; float:\n        versions = list(fake_registry.keys())\n        versions.sort()\n        idx = versions.index(self.v) + 1\n        if idx == len(versions):\n            return None\n        return versions[idx]\n\n    def next_version(self) -&gt; BaseModel:\n        next_class = fake_registry.get(self._next_version_model())\n        return next_class\n\n    @abc.abstractmethod\n    def to_next(self) -&gt; BaseModel:\n        pass\n\n\nclass Model1(VersionModel):\n    # https://pydantic-docs.helpmanual.io/usage/types/#arguments-to-constr\n    type: str  # constr(to_lower=True)\n    num_layers: conint(ge=3)\n    width: Optional[conint(ge=0)]\n    # v: float = Field(1.0, const=True)\n    zoom: conint(gt=18) = 19\n    v: Literal[1.0] = Field(1.0, const=True)\n\n    # @classmethod\n    # def to_next(cls, instance: Type[VBT]) -&gt; BaseModel:\n    def to_next(self) -&gt; Optional[BaseModel]:\n        next_class = self.next_version()\n        if next_class != Model2:\n            raise Exception(\"WTH\")\n\n        logging.warning(\"================================================\")\n        logging.warning(\"==============Migrating from 1-&gt;2 ==============\")\n        logging.warning(\"================================================\")\n\n        d = self.dict()\n        d.pop(\"v\")\n        return Model2(**d)\n\n\nclass Model2(Model1):\n    width: conint(ge=5)\n    context: conint(ge=256) = 256\n    # v: float = Field(2.0, const=True)\n    v: Literal[2.0] = Field(2.0, const=True)\n\n    def to_next(self) -&gt; Optional[BaseModel]:\n        next_class = self.next_version()\n        if next_class != Model3:\n            raise Exception(\"WTH\")\n\n        logging.warning(\"================================================\")\n        logging.warning(\"==============Migrating from 2-&gt;3 ==============\")\n        logging.warning(\"================================================\")\n\n        return Model3(\n            new_context=self.context,\n            num_layers=self.num_layers,\n            type=self.type,\n            width=self.width,\n            zoom=self.zoom,\n        )\n\nclass Model3(Model1):\n    new_context: conint(ge=512, le=1300) = 512\n    v: Literal[3.0] = Field(3.0, const=True)\n\n    def to_next(self) -&gt; Optional[BaseModel]:\n        logging.warning(\"================================================\")\n        logging.warning(\"============== Latest no migration =============\")\n        logging.warning(\"================================================\")\n\n        return None\n</code></pre> Config templates, as shown here are versioned as well. </p> <p>Let's run through various scenarios: 1. A user wants to run a training and uses the latest config, they run <code>python example.py model=resnet_v3</code> 2. A user wants to run a training and uses the latest config but overrides some values, they run <code>python example.py model=resnet_v3 +model.zoom=25</code> 3. A user wants to re-run a training from an old config, they run <code>python example.py</code>. They use the v2 version of config and migration fails because field <code>context</code> require value is greater than or equal to 512 in v3 but used config in v2 template is 256. The user received feedback on what needs to change in config to make it work. 4. the Same user in #3 wants to re-run a training from the old config, they run <code>python example.py model.context=512</code>. They can run and the application performs the migration and the application actually only Model3 version of object config. 5. I want to expose the schema of Model config, how can I do this: <pre><code>        _Models = Annotated[Union[Model1, Model2, Model3], Field(discriminator=\"v\")]\n        _schema = schema_json_of(_Models, title=\"Model Schema\", indent=2)\n</code></pre> This produces the following schema for model config: <pre><code>{\n  \"title\": \"Model Schema\",\n  \"discriminator\": {\n    \"propertyName\": \"v\",\n    \"mapping\": {\n      \"1.0\": \"#/definitions/Model1\",\n      \"2.0\": \"#/definitions/Model2\",\n      \"3.0\": \"#/definitions/Model3\"\n    }\n  },\n  \"anyOf\": [\n    {\n      \"$ref\": \"#/definitions/Model1\"\n    },\n    {\n      \"$ref\": \"#/definitions/Model2\"\n    },\n    {\n      \"$ref\": \"#/definitions/Model3\"\n    }\n  ],\n  \"definitions\": {\n    \"Model1\": {\n      \"title\": \"Model\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"v\": {\n          \"title\": \"V\",\n          \"const\": 1.0,\n          \"enum\": [\n            1.0\n          ],\n          \"type\": \"number\"\n        },\n        \"type\": {\n          \"title\": \"Type\",\n          \"type\": \"string\"\n        },\n        \"num_layers\": {\n          \"title\": \"Num Layers\",\n          \"minimum\": 3,\n          \"type\": \"integer\"\n        },\n        \"width\": {\n          \"title\": \"Width\",\n          \"minimum\": 0,\n          \"type\": \"integer\"\n        },\n        \"zoom\": {\n          \"title\": \"Zoom\",\n          \"default\": 19,\n          \"exclusiveMinimum\": 18,\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"type\",\n        \"num_layers\"\n      ]\n    },\n    \"Model2\": {\n      \"title\": \"Model\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"v\": {\n          \"title\": \"V\",\n          \"const\": 2.0,\n          \"enum\": [\n            2.0\n          ],\n          \"type\": \"number\"\n        },\n        \"type\": {\n          \"title\": \"Type\",\n          \"type\": \"string\"\n        },\n        \"num_layers\": {\n          \"title\": \"Num Layers\",\n          \"minimum\": 3,\n          \"type\": \"integer\"\n        },\n        \"width\": {\n          \"title\": \"Width\",\n          \"minimum\": 5,\n          \"type\": \"integer\"\n        },\n        \"zoom\": {\n          \"title\": \"Zoom\",\n          \"default\": 19,\n          \"exclusiveMinimum\": 18,\n          \"type\": \"integer\"\n        },\n        \"context\": {\n          \"title\": \"Context\",\n          \"default\": 256,\n          \"minimum\": 256,\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"type\",\n        \"num_layers\",\n        \"width\"\n      ]\n    },\n    \"Model3\": {\n      \"title\": \"Model\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"v\": {\n          \"title\": \"V\",\n          \"const\": 3.0,\n          \"enum\": [\n            3.0\n          ],\n          \"type\": \"number\"\n        },\n        \"type\": {\n          \"title\": \"Type\",\n          \"type\": \"string\"\n        },\n        \"num_layers\": {\n          \"title\": \"Num Layers\",\n          \"minimum\": 3,\n          \"type\": \"integer\"\n        },\n        \"width\": {\n          \"title\": \"Width\",\n          \"minimum\": 0,\n          \"type\": \"integer\"\n        },\n        \"zoom\": {\n          \"title\": \"Zoom\",\n          \"default\": 19,\n          \"exclusiveMinimum\": 18,\n          \"type\": \"integer\"\n        },\n        \"new_context\": {\n          \"title\": \"New Context\",\n          \"default\": 512,\n          \"minimum\": 512,\n          \"maximum\": 1300,\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"type\",\n        \"num_layers\"\n      ]\n    }\n  }\n}\n</code></pre></p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2023/11/12/hydra-pydantic-config-management/#conclusion","title":"Conclusion","text":"<p>It's great to have tools like Hydra and Pydantic to simplify config management and deal with validations efficiently. It would be even great if Hydra integrates nicely with Pydantic as well but at least there is a path to using these two tools together. </p>","tags":["blog","python","hydra","pydantic","machine-learning","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/","title":"Confident Learning: Label errors are imperative! So what can you do?","text":"<p>What makes deep-learning so great, despite what you may have heard, is data! There is an old saying, that sums it up pretty well:</p> <p>The model is only as good as the data! </p> <p>Which brings us to the real question, exactly how good is your data? Collecting ground truth/training datasets is incredibly expensive, laborious, and time-consuming. The process of labeling involves searching for the object of interest and applying prior knowledge and heuristics to come to a final decision. A decision to represent if the object (of interest) is present and if so, annotate it to provide extra information like bounding box, and segmentation mask. </p> <p>There are several factors at play in this process that leads to error in the dataset. The question is what can we do about it? In this post, I will touch on some of the reasons why labeling error occurs, why the errors in labels are imperative, and what are the tools and techniques one can use to manage errors in the label datasets. Then, I will dive into the\u00a0detail of confident learning. I will also demonstrate the use of cleanlab, a confident learning implementation [1], to easily find noise in\u00a0the data.</p> <p>Disclaimer: Before diving into the details, I would like to acknowledge that, at the time of writing this post, I am not affiliated with or sponsored by cleanlab in any capacity.</p> <p>This post is broken down into the following sections:</p> <ul> <li>Confident Learning: Label errors are imperative! So what can you do?</li> <li>Reasons for labeling errors</li> <li>Labeling efficiency tricks that increase the risk of labeling errors</li> <li>Errors in labels are imperative</li> <li>Exactly, what is Confident learning?<ul> <li>Fundamentals</li> <li>Limitations of CL</li> </ul> </li> <li>Hands on of label noise analysis using cleanlab for multi-label classification<ul> <li>Model info</li> <li>Exploration in noise using cleanlab</li> </ul> </li> <li>Conclusion</li> <li>References</li> </ul>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#reasons-for-labeling-errors","title":"Reasons for labeling errors","text":"<p>Let's first look at some of the reasons why errors in the labels may be present. One broad class for such errors is tooling/software bugs. These can be controlled and managed using good software best practices like tests covering both software and the data. The other class of errors is the one where the mistakes are coming from the labelers themselves. These are incredibly harder issues to track. Because labelers are the oracle in this process of deep learning after all! If we don't trust them, then who do we trust?</p> <p>There is a very interesting work by Rebecca Crowley where she provides a detailed chart of a range of reasons why an object (of interest) may be missed while searching in a scene or also why a wrong final decision may be made by them [4]. Some directly impacting labeling in my view are:</p> <ol> <li>Search Satisficing: The tendency to call off a search once something has been found, leading to premature stopping, thus increasing the chance of missing annotations[4]. This more applies to scenarios where more than one annotation is needed. For example, multi-label or segmentation annotation (dog and pen are in the image but the labeler only annotates for the dog and does not spend enough time to spot the pen and capture in labels).</li> <li>Overconfidence &amp; Under-confidence: This type of labeling error relates to one's feeling-of-knowing [4] that is over or underestimated.</li> <li>Availability: There is an implicit bias in annotating it wrongly if something is frequently occurring or rarely occurring  [4]. It is particularly true for challenging labeling tasks. For instance, if the cancer prevalence rate in a location is 0.01%, then the labeler, when labeling a not-so-straightforward case, is more likely to mark a non-cancer than cancer.</li> <li>Anchoring/Confirmation bias: When a labeler makes a pre-emptive decision [4] about a labeling task outcome and then looks for information to support that decision. For example, believing they are looking at a cancerous case, they start to search for abnormality in the image to support the finding that this case is cancer. In this unfair search/decision process, they are more likely to make mistakes.</li> <li>Gambler's Fallacy: When they are encountered with a repeated pattern of similar cases, then they are likely to deviate and favor an outcome that breaks that pattern [4].</li> <li>Amongst all these, Cognitive Overload is also a valid and fair reason for errors in labels.</li> </ol>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#labeling-efficiency-tricks-that-increase-the-risk-of-labeling-errors","title":"Labeling efficiency tricks that increase the risk of labeling errors","text":"<p>Given the process to procure a labeling dataset is expensive, some clever tricks and techniques are occasionally applied to optimize the labeling funnel. While some focus on optimization through labeling experience such as Fast Interactive Object Annotation<sup>[5]</sup>, other techniques focus on using auto-labeling techniques to reduce the labeling burden a bit to aid the labelers. Tesla has a very powerful mechanism to realize auto-labeling at scale as talked about in the 2021 CVPR by Karpathy. They sure have the advantage of having feedback (not just the event that's worth labeling but also what did the driver do or if that led to a mishap). It's an advantage that not all deep-learning practicing organizations have! Impressive nonetheless!  Then we also have the weakly supervised class of training regimes that I won't go into detail about (perhaps a topic for another day)!</p> <p>The thing is, the cleverer tricks you employ to optimize this process, the higher the chances of error in your dataset. For instance, using the model in the loop for labeling is being increasingly used to optimize the labeling process (as detailed in this presentation), as an auto-labeling/pre-label trick, wherein predicted labels are shown to the labelers and the labeler only fine-tunes the annotation instead of annotating from the get-go. This process has two main challenges:</p> <p>a) It may introduce a whole gamut of bias in labels as discussed above in (Reasons for labeling errors.</p> <p>b) If the model is not on par with human labelers, the labor, and boredom of correcting a garbage prior label increase the risk of errors in the dataset. This is a classic case of cognitive overload.</p> <p>If this example was not enough, let's take a case of auto labeling using ontology/knowledge graph. Here, the risk of error propagation is too high if the knowledge encoded in the ontology/knowledge graph is biased. For example, if it's an ocean water body it cants be a swimming pool. Because well, contrary to common knowledge ocean pools do exist. Or if it's a house it's not a waterbody - because you know lake houses do exist!</p> <p> Ocean Pool/Rock Pool @Mona Vale NSW AU (Image is taken from the internet! @credit: unknown)</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#errors-in-labels-are-imperative","title":"Errors in labels are imperative","text":"<p>Given the challenges discussed so far, It is fair to say that errors are imperative. The oracle in this process are labelers and they are only just human!</p> <p>I am not perfect; I am only human</p> <p>Evidently, there is an estimated average of at least 3.3% errors across the 10 popular datasets, where for example label errors comprise at least 6% of the ImageNet validation set <sup>2</sup>.</p> <p>Assuming, human labelers will produce a perfectly clean dataset is, well, overreaching to say the least. If one cares, one can employ multiple labelers to reduce the error by removing the noise through consensus. This is a great technique to produce a high-quality dataset but it's also many times more expensive and slow thus impractical as standard modus-operandi. Besides being expensive, this does not guarantee a clean dataset either. This is evident from Northcutt's NeurIPS 2021<sup>[2]</sup> work on analyzing errors in the test set of popular datasets that reported order of hundred samples across popular datasets where an agreement could not be reached on true ground truth despite looking at collating outcomes from labelers (see table 2 in the paper for reference).</p> <p>For the last few years, I have been using model-in-loop to find samples where there are disagreements in the dataset with the models. Some of the other techniques that I have found useful are leveraging loss functions, as called out by Andrej Karpathy! More recently, I have seen a huge benefit of deploying ontology-based violations to find samples that are either a) labeling errors or b) extreme edge cases that we were not aware of (aka out of distribution [OOD] samples). </p> <p>When you sort your dataset descending by loss you are guaranteed to find something unexpected, strange and helpful.</p>\u2014 Andrej Karpathy (@karpathy) October 2, 2020 <p></p> <p>However, I realized I have been living in oblivion when I came across project cleanlab from Northcutt's group and started digging in a bunch of literature around this exact space! I was excited to uncover all the literature that proposed the tricks and tips I have been using to date without being aware of them. Well no more!! In the following sections, I will cover what I have learned reading through this literature.</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#exactly-what-is-confident-learning","title":"Exactly, what is Confident learning?","text":"<p>All models are wrong, but some are useful!</p> <p>Confident learning<sup>[1]</sup> (CL) is all about using all the useful information we have at hand to find noise in the dataset and improve the quality of the dataset. It's about using one oracle (the labelers) and testing it using another oracle in the build i.e. the model!  At a very high level, this is exactly what we have been more generally calling model-in-the-loop!</p> <p>Learning exists in the context of data, yet notions of confidence typically focus on model predictions, not label quality!<sup>1</sup></p> <p>Confident learning (CL) is a class of learning where the focus is to learn well despite some noise in the dataset. This is achieved by accurately and directly characterizing the uncertainty of label noise in the data. The foundation CL depends on is that <code>Label noise is class-conditional, depending only on the latent true class, not the data</code> <sup>1</sup>. For instance, a <code>leopard</code> is likely to be mistakenly labeled as a <code>jaguar</code>.  This is a very strong argument and in practice untrue. I can argue that the scene (ie the data) has implications for the labeler's decisions. For instance, a dingy sailing in water is less likely to be labeled as a car if it's in water. In other words, would not a dingy being transported in a lorry is more likely to be labeled as a car than when it was sailing on the water? so data and context do matters!  This assumption is a classic case of, <code>in statistics any assumption is fair if you can solve for x!</code>. Now that we have taken a dig at this, it's fair to say that this assumption is somewhat true even if not entirely. </p> <p>Another assumption CL makes is that rate of error in the dataset is &lt; \u00bd. This is a fair assumption and is coming from Angluin &amp; Laird's<sup>[3]</sup> proposed method for the class conditional noise process which is used in CL to calculate the joint distribution of noisy and true labels.</p> <p>In Confident learning, a reasonably well performant model is used to estimate the errors in the dataset. First, the model's prediction is obtained then, using a class-specific threshold setting confident joint distribution matrix is obtained; which is then normalized to obtain an estimation of the error matrix. This estimated error matrix then builds the foundation for dataset pruning, counting, and ranking samples in the dataset.</p> <p>Estimating the joint distribution is challenging as it requires disambiguation of epistemic uncertainty (model-predicted probabilities) from aleatoric uncertainty (noisy labels) but useful because its marginals yield important statistics used in the literature, including latent noise transition rates latent prior of uncorrupted labels, and inverse noise rates. <sup>1</sup>.</p> <p> Confident learning  in pictures<sup>1</sup>.</p> <p>The role of a class-specific threshold is useful to handle variations in model performance for each class. This technique is also helpful to handle collisions in predicted labels. </p> <p>What's great about Confident learning and cleanlab (its python implementation of it) is that while it does not propose any groundbreaking algorithm, it has done something that is rarely done. Bring together antecedent works into a very good technical framework that is so powerful that it rightfully questions major datasets that shape the evolution of deep learning. Their work on the analysis of 10 popular datasets including MNIST is well appreciated. This is also a reminder that we are massively overfitting the entire deep learning landscape to datasets like MNIST, and ImageNet, as they are pretty much, must use the dataset to benchmark and qualify bigger and better algorithms and that, they have at least 3.3% errors if not 20% (as estimated by Northcutt's group)!</p> <p>This approach was used in side by side comparison where samples were pruned either randomly (shown in orange in below fig) or more strategically via CL to remove noisy samples only (shown in blue below fig). The accuracy results as shown below. CL is doing better than random prune!</p> <p> Borrowed from Confident learning<sup>1</sup></p> <p>Following are an example of some of the samples that CL flags as noisy/erroneous, also including the edge cases where a) neither were true and b) Its either the CL suggestion or provided label but unclear which of the two are correct (non-agreement):</p> <p> Examples of samples corrected using Confident learning<sup>2</sup>.</p> <p>CL is not 100% accurate. At the best, it is an effort to estimate noise using an epistemic uncertainty predictor [the model]. Having said that these examples it fails on are quite challenging as well. </p> <p> Examples of samples Confident learning struggled with!<sup>2</sup></p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#fundamentals","title":"Fundamentals","text":"<p>Let's look at the fundamentals CL builds on and dig in a bit on the antecedent and related works that formulate the foundation upon which Confident learning(cleanlab) is built!</p> <ol> <li> <p>As discussed above already, is class conditional noise proposed by Angluin &amp; Laird is the main concept utilized by CL. </p> </li> <li> <p>The use of weighted loss functions to estimate the probability of misclassification, as used in <sup>7</sup>, is quite relevant to the field of CL, although it's not directly used in the CL technique as proposed by the Confident learning framework paper. </p> </li> <li> <p>Use of iterative noise cross-validation [INCV] techniques, as proposed in Chen et. al<sup>[8]</sup>, that utilize a model-in-the-loop approach to finding noisy samples. This algorithm is shown below:</p> <p> Chen's INCV algorithm</p> </li> <li> <p>CL does not directly use MentorNet<sup>[6]</sup>. However, it is very relatable work that builds on a data-driven training approach. In simplistic terms, there is a teacher network that builds a curriculum of easy to hard samples (derived using loss measures) and the student is trained off this curriculum.</p> <p> MentorNet architecture</p> </li> <li> <p>There are other variations to data-driven teaching, one noticeable example is Co-teaching<sup>[9]</sup> which looks to be teaching each other in pairs and passing the non-noisy samples (calculated based on loss measures) to each other during learning. The main issue Co-teaching tries to solve is the memorization effects that are present in MentorNet<sup>[6]</sup>. (aka M-Net] but not in Co-teaching<sup>[9]</sup> due to data share.</p> <p> Co-teaching approach in contrast with MentorNet aka M-Net</p> </li> <li> <p>The understanding that small losses are a good indicator of useful samples and highly likely correct samples whereas jumpy, high loss producing samples are, well, interesting! They can be extreme edge cases or out-of-distribution samples or also can indicate wrongness. This only holds for reasonably performant models with abilities at least better than random chance if not more!</p> </li> </ol>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#limitations-of-cl","title":"Limitations of CL","text":"<p>One thing that CL entirely ignores about label errors is when one or more true label is entirely missed. This is more likely to happen in multi-label settings and even more complex labeling setting like segmentation or detection than in multi-class classifications. For example, if there is a TV and water bottle in an image and the only annotation present is for the TV, and the water bottle is missed entirely! This is currently not modeled in CL as relies on building a pairwise class-conditional distribution between the given label and the true label. If the given label was a cat but the actual label was the dog for example. The framework itself does not allow it to model for the missing label when a true label is present. </p> <p>Pairwise class-conditional distribution as proposed in CL also limits its use in multi-label settings. Explicitly when multiple labels can co-exist on the same data. For example, both the roof and swimming pool can be present in the image and they are not necessarily exclusive. This limitation comes from pairwise (single class gives vs single class predicted) modeling. This is different from say Stanford Car Dataset where make and model are predicted as multiple labels but they are exclusive ie a vehicle can be ute or hatchback but that is exclusive to it being made by Toyota or Volvo. Exclusivity in this case allows for modeling Pairwise class-conditional distribution. These are more multi-label multi-class modeled using multi-headed networks. True multi-label datasets can't be modeled like these pairwise joint distributions. They can perhaps be modeled using more complex joint distribution formulations but that would not scale very well. Confident learning<sup>[1]</sup> as it stands currently is a computationally expensive algorithm with an order of complexity being O(m2 + nm). </p> <p>Having said these, it is probably something that is not explained in the literature as it seems that cleanlab itself supports multi-label classification. Conceptually I am unclear how multi-label works given the said theory. The support for multi-label is developing as issues are being addressed on this tool 1,2.</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#hands-on-of-label-noise-analysis-using-cleanlab-for-multi-label-classification","title":"Hands on of label noise analysis using cleanlab for multi-label classification","text":"<p>Now that we have covered the background and theoretical foundations, let's try the confident learning out in detecting label noise using its implementation cleanlab. Specifically, I will use multi-label classification given the uncertainty around it (as discussed above)!. For this hands-on, I will use MLRSNet dataset. This spike is built using ResNet as a multi-label image classifier predicting 6 classes that can co-exist at the same time. These classes are <code>['airplane', 'airport', 'buildings', 'cars', 'runway', 'trees']</code> and derived off MLRSNet subset - i.e. only using <code>airplane</code> and <code>airport</code>.</p> <p>The source code and this notebook for this project is label-noise Github repository. The notebook checks how well cleanlab performs in detecting label noise and identifies out-of-distribution samples, weird samples, and also errors!</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#model-info","title":"Model info","text":"<p>Train and validation loss from the model trained using label-noise for 19 epochs. Note, for this spike, I opted out of n-fold cross-validation (CV). Using CV can lead to better results but its a not quick.</p> <p></p> <p>Training logs for the model used in this exercise (Image provided by author)</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#exploration-in-noise-using-cleanlab","title":"Exploration in noise using cleanlab","text":"<p>As shown in this notebook, the filter approach provided a list of samples that were deemed noisy. This flagged 38% of out-of-samples as noisy/erroneous. </p> <p>Ranking provided an order in the samples on a 0-1 scale for label quality, the higher the number, the better quality the sample. I looked in <code>get_self_confidence_for_each_label</code> approach for out-of-distribution (OOD) samples and also entropy-based ordering. The distribution for each is as follows:</p> <p></p> <p>Confidance order of entropy-based ordering</p> <p></p> <p>Confidance order of self_confidence ordering</p> <p>The samples picked as lowest quality or confidence is indeed rightfully chosen. There is an airplane that was missed in the image (shown in the highlighted overlay) and also another sample is OOD! </p> <p>What's more interesting is all three methods of filtering, ranked by self-confidence and entropy all flagged these two samples! So we increase the threshold, and while there are false positives (for noise) there is some good example of errors.</p> False Positive True Positive <p>I am not sure if I am following how to interpret the pair-wise count for multi-label, so that's left for another day!</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#conclusion","title":"Conclusion","text":"<p>As discussed in this post, there are several reasons why label errors are unavoidable. While no small-efforts are required to minimize the errors in the dataset, management of the errors in the dataset is also warranted. The management to find noisy data, out of distribution data, or data that represents a systematic flaw (software/tooling issues or issues in the understanding of a concept that defines the target class). Approaches like model-in-loop, or additional information like ontology to find such noises or errors in the dataset are effective techniques. Confident learning provides a solid foundation for analyzing a dataset of noisy or OOD samples \u2014 a technique that's quite effective for multi-class approaches, with the evolving support for multi-label classification. Now, on to cleaning the dataset! Happy cleaning!</p>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/05/16/confident-learning-and-clean-data/#references","title":"References","text":"<ol> <li>C. G. Northcutt, L. Jiang, and I. Chuang. Confident learning: Estimating uncertainty in dataset labels. Journal of Artificial Intelligence Research, 70:1373\u20131411, 2021. 1911.00068</li> <li>Northcutt, C. G., Athalye, A., and Mueller, J. (2021). Pervasive label errors in test sets destabilize machine learning benchmarks. In International Conference on Learning Representations Workshop Track (ICLR). 2103.14749</li> <li>D. Angluin and P. Laird. Learning from noisy examples. Machine Learning, 2(4):343\u2013370, 1988. link</li> <li>Crowley RS, Legowski E, Medvedeva O, Reitmeyer K, Tseytlin E, Castine M, Jukic D, Mello-Thoms C. Automated detection of heuristics and biases among pathologists in a computer-based system. Adv Health Sci Educ Theory Pract. 2013 Aug;18(3):343-63. doi: 10.1007/s10459-012-9374-z. Epub 2012 May 23. PMID: 22618855; PMCID: PMC3728442. link</li> <li>Huan Ling and Jun Gao and Amlan Kar and Wenzheng Chen and Sanja Fidler, Fast Interactive Object Annotation with Curve-GCN. CVPR, 2019 link</li> <li>Jiang, L., Zhou, Z., Leung, T., Li, L.-J., and Fei-Fei, L. (2018). Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In International Conference on Machine Learning (ICML).1712.05055.</li> <li>N. Natarajan, I. S. Dhillon, P. K. Ravikumar, and A. Tewari. Learning with noisy labels. In Conference on Neural Information Processing Systems (NeurIPS), pages 1196\u20131204, 2013. NurIPS 2013</li> <li>P. Chen, B. B. Liao, G. Chen, and S. Zhang. Understanding and utilizing deep neural networks trained with noisy labels. In International Conference on Machine Learning (ICML), 2019.1905.05040</li> <li>Han, B., Yao, Q., Yu, X., Niu, G., Xu, M., Hu, W., Tsang, I., and Sugiyama, M. (2018). Co-teaching: Robust training of deep neural networks with extremely noisy labels. In Conference on Neural Information Processing Systems (NeurIPS). 1804.06872</li> </ol>","tags":["blog","data-science","machine-learning","clean-lab","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/","title":"Review and comparison of two manifold learning algorithms: t-SNE and UMAP","text":"<p>What are manifold learning algorithms? What is t-SNE and UMAP? What are the differences between t-SNE and UMAP? How can I explore the features of a dataset using t-SNE and UMAP? These are my notes from my recent exploration into t-SNE and UMAP and trying to apply them to a multi-label dataset to understand the abilities and limits of these algorithms. </p> <p>This post is broken down into the following sections:</p> <ul> <li>Review and comparison of two manifold learning algorithms: t-SNE and UMAP</li> <li>Manifold learning algorithms (MLA)</li> <li>Neighbour graphs</li> <li>t-Distributed Stochastic Neighbor Embedding (t-SNE)</li> <li>Uniform Manifold Approximation and Projection UMAP</li> <li>Comparison table: t-SNE vs UMAP</li> <li>Exploring dataset with t-SNE \\&amp; UMAP</li> <li>Simple feature dataset like MNIST</li> <li>More complex datasets like CIFAR</li> <li>What to do when there is noise in features?</li> <li>how to do this for multi-label</li> <li>Can we apply this to understand what neural networks are doing?</li> <li>Conclusion</li> </ul>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#manifold-learning-algorithms-mla","title":"Manifold learning algorithms (MLA)","text":"<p>For us humans, high-dimensional data are very difficult to visualize and reason with. That's why we use dimensionality reduction techniques to reduce data dimensions so that the data is easy to work with and reason about. Manifold learning algorithms (MLA) are dimensionality reduction techniques that are sensitive to non-linear structures in data. The non-linearity is what sets manifold learning apart from other popular linear dimensionality reduction techniques like Principal Component Analysis (PCA) or Independent Component Analysis (ICA). Non-linearity allows MLAs to retain complex and interesting properties of data that would otherwise be lost in linear reduction/projection. Because of this property, MLA is a very handy algorithm to analyze data - to reduce data dimensions to 2D or 3D, and visualize and explore them to find patterns in datasets.</p> <p>t-SNE (t-Distributed Stochastic Neighbor Embedding) and Uniform Manifold Approximation and Projection UMAP are the two examples of MLA, that I will cover in this post. I will compare and contrast them and provide a good intuition of how they work and how to choose one over the other.</p> <p>Note that, MLAs are tweaks and generalizations of existing linear dimensionality reduction frameworks themselves. Similar to linear dimensionality reduction techniques, MLAs are predominantly unsupervised even though supervised variants exist. The scope of this post is unsupervised techniques, however.</p> <p>So what does non-linearity buys us? The following shows the difference in reduction using PCA vs t-SNE, as shown in McInnes excellent talk:</p> <p> Comparison of t-SNE and UMAP on MNIST dataset. (Image from McInnes talk)</p> <p>As we can see, PCA retains some structure. However, it is very well pronounced in t-SNE, and clusters are more clearly separated. </p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#neighbour-graphs","title":"Neighbour graphs","text":"<p>t-SNE and UMAP are neighbor graph technique that models data points as nodes, with weighted edges representing the distance between the nodes. Through various optimizations and iterations, this graph and layout are tuned to best represent the data as the distance is derived from the \"closeness\" of the features of the data itself. This graph is then projected on reduced dimensional space a.k.a. embedded space. This is a very different technique than matrix factorization as employed by PCA, ICA for example.</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#t-distributed-stochastic-neighbor-embedding-t-sne","title":"t-Distributed Stochastic Neighbor Embedding (t-SNE)","text":"<p>t-SNE uses Gaussian joint probability measures to estimate the pairwise distances between the data points in the original dimension. Similarly, the student's t-distribution is used to estimate the pairwise distances between the data points in the embedded space (i.e. lower dimension or target dimension). t-SNE then uses the gradient descent technique to minimize the divergence between the two distributions in original and embedded space using the Kullback-Leibler (KL) divergence technique.</p> <p><code>Perplexity</code> in t-SNE is effectively the number of nearest neighbors considered in producing the conditional probability measure. A larger perplexity may obscure small structures in the dataset while small perplexity will result in very localized output ignoring global information. Perplexity must be less than the size of data (number of data points) then; otherwise, we are looking at getting a blobby mass. The recommended range for perplexity lies between 5-50, with a more general rule that the larger the data, the larger the perplexity.</p> <p>Because of the use of KL divergence, t-SNE preserves the local structure in the original space, however, global structure preservation is not guaranteed. Having said that, when initialization with PCA is applied, the global structure is somewhat preserved. </p> <p>Talking more about structures, the scale of distances between points in the embedded space is not uniform in t-SNE as t-SNE uses varying distance scales. That's why it is recommended to explore data under different configurations to tease out patterns in the dataset. Learning rate and number of iterations are two additional parameters that help with refining the descent to reveal structures in the dataset in the embedded space. As highlighted in this great distill article on t-SNE, more than one plot may be needed to understand the structures of the dataset.</p> <p> Different patterns are revealed under different t-SNE configurations, as shown by distill article. (Image from distill).</p> <p>t-SNE is known to be very slow with the order of complexity given by O(dN^2) where d is the number of output dimensions and  N is the number of samples. Barnes-Hut variation of t-SNE improves the performance [O(dN log N)] however Barnes-Hut can only work with dense datasets and provide at most 3d embedding space. The efficiency gain in Barnes-Hut is coming from changes in gradient calculation which are done with <code>O(n log n)</code> complexity, that uses approximation techniques which leads to about 3% error in nearest neighbor calculation.</p> <p>Because of these performance implications, a common recommendation is to use PCA to reduce the dimension before applying t-SNE. This should be considered very carefully especially if the point of using t-SNE was to explore into non-linearity of the dataset. Pre-processing with linear techniques like PCA will destroy non-linear structures if present.</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#uniform-manifold-approximation-and-projection-umap","title":"Uniform Manifold Approximation and Projection UMAP","text":"<p>UMAP is based on pure combinatorial mathematics that is well covered in the paper and is also well explained by author McInnes in his talk and library documentation is pretty well written too. Similar to t-SNE, UMAP is also a topological neighbor graph modeling technique. There are several differences b/w t-SNE and UMAP with the main one being that UMAP retains not only local but global structure in the data.</p> <p>There is a great post that goes into detail about how UMAP works. High level, UMAP uses combinatorial topological modeling with the help of simplices to capture the data and applies Riemannian metrics to enforce the uniformity in the distribution. Fuzzy logic is also applied to the graph to adjust the probability distance if the radius grows. Once the graphs are built then optimization techniques are applied to make the embedded space graph very similar to the original space one. UMAP uses binary cross-entropy as a cost function and stochastic gradient descent to iterate on the graph for embedded space. Both t-SNE and UMAP use the same framework to achieve manifold projections however implementation details vary. Oskolkov's post covers in great detail the nuances of both the techniques and is an excellent read.</p> <p>UMAP is faster for several reasons, mainly, it uses random projection trees and nearest neighbor descent to find approximate neighbors quickly. As shown in the figure below, similar to t-SNE, UMAP also varies the distance density in the embedded space.</p> <p> Manifold reprojection used by UMAP, as presented by McInnes in his talk.  (Image from McInnes talk)</p> <p>Here's an example of UMAP retaining both local and global structure in embedded space:</p> <p> Example of UMAP reprojecting a point-cloud mammoth structure on 2-D space. (Image provided by the author, produced using tool 1)</p> <p>Here's a side-by-side comparison of t-SNE and UMAP on reducing the dimensionality of a mammoth. As shown, UMAP retains the global structure but it's not that well retained by t-SNE. </p> <p> Side by side comparison of t-SNE and UMAP projections of the mammoth data used in the previous figure. (Image provided by the author, produced using tool 1) </p> <p>The explanation for this difference lies in the loss function. As shown in the following figure, UMAP uses binary cross-entropy that penalizes both local (clumps) and global (gaps) structures. In t-SNE however, due to KL Divergence as the choice of the cost function, the focus remains on getting the clumps i.e. local structure right.</p> <p> Cots function used in UMAP as discussed in McInnes talk. (Image from McInnes talk)</p> <p>The first part of the equation is the same in both t-SNE (coming from KL divergence) and UMAP. UMAP only has the second part that contributes to getting the gaps right i.e. getting the global structure right.</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#comparison-table-t-sne-vs-umap","title":"Comparison table: t-SNE vs UMAP","text":"Characteristics t-SNE UMAP Computational complexity O(dN^2) (Barnes-Hut with O(dN log N) ) O(d*n^1.14) (emprical-estimates O(dN log N)) Local structure preservation Y Y Global structure preservation N (somewhat when <code>init=PCA</code>) Y Cost Function KL Divergence Cross Entropy Initialization Random  (PCA as alternate) Graph Laplacian Optimization algorithm Gradient Descent (GD) Stochastic Gradient Descent (SGD) Distribution for modelling distance probabilities Student's t-distribution family of curves (1+a*y<sup>(2b))</sup>-1 Nearest neighbors  hyperparameter 2^Shannon entropy nearest neighbor k","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#exploring-dataset-with-t-sne-umap","title":"Exploring dataset with t-SNE &amp; UMAP","text":"<p>Now that we have covered theoretical differences, let's apply these techniques to a few datasets and do a few side-by-side comparisons between t-SNE and UMAP.</p> <p>Source code and other content used in this exercise are available in this git repository - feature_analysis. The notebook for MNIST analysis is available here. Likewise, the notebook for CIFAR analysis is available here.</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#simple-feature-dataset-like-mnist","title":"Simple feature dataset like MNIST","text":"<p>The following figure reprojects MNIST image features on the 2D embedded space under different perplexity settings. As shown, increasing the perplexity, makes the local clusters very packed together. In this case, PCA based initialization technique was chosen because I want to retain the global structure as much as possible. </p> <p> Reprojection of MNIST image features on the 2D embedded space using t-SNE under different perplexity settings. (Image provided by author)</p> <p>It's quite interesting to see that the digits that are packed close together are: 1. 7,9,4 2. 3,5,8 3. 6 &amp; 0  4. 1 &amp; 2 5. That 6 is more close to 5 than 1  6. Likewise 7 is closer to 1 than 0.</p> <p>At a high level this co-relation makes sense, the features of the digits that are quite similar are more closely packed than digitals that are very different. Its also, interesting to note that 8 and 9 have anomalies that map closely to 0 in rare cases in embedded space. So what's going on? Following image overlays randomly selected images on the clusters produced by t-SNE @ perplexity of 50.</p> <p> Reprojection of MNIST image features on the 2D embedded space using t-SNE @ perplexity=50 with randomly selected image overlay. (Image provided by author)</p> <p>As we pan around this image, we can see a distinct shift in the characteristics of the digits. For example, the 2 digits at the top are very cursive and have a round little circle at the joint of the two whereas as we travel to the lower part of the cluster of 2s, we can see how sharply written the bottom 2s are. The bottom 2s features are sharp angular joints.  Likewise, the top part of the cluster of 1s is quite slanty whereas the bottom 1s are upright. </p> <p>It's quite interesting to see that the 8's occasionally clustered together with 0's are quite round in the middle and do not have the sharp joint in the middle. </p> <p>So, what does MNIST data look like with UMAP? UMAP's embedded space also reflects the same grouping as discussed above. In fact, UMAP and t-SNE clustering in terms of digits grouping are very much alike. It appears to me that UMAP and t-SNE are mirror reflections when it comes to how digits are grouped. </p> <p> Reprojection of MNIST image features on the 2D embedded space using UMAP. (Image provided by author)</p> <p>It's also very interesting to note how similar-looking 1s are that are reprojected to the same coordinates in the embedded space.</p> <p> One example of samples that get reprojected to the same coordinates in the embedded space using UMAP. (Image provided by author)</p> <p>Not all the data points that collide in embedded space will look exactly similar, the similarity is more in the reduced dimensional space. One such example is shown below. Here 1 and 0 are reprojected to the same coordinates. As we can see the strokes on the left side of 0 are very similar to strokes of 1. The circle of zero is not quite complete either. </p> <p> One example of two different digits getting reprojected to the same coordinates in the embedded space using UMAP. (Image provided by author)</p> <p>Here's also an example of samples falling into the same neighborhood in the embedded space that look quite distinct despite sharing some commonality (the strokes around the mouth of 4 and incomplete 8s)! </p> <p> Example of 4 and 8s reprojected to the nearby coordinates in the embedded space using UMAP. (Image provided by author)</p> <p>Its unpredictable what tangible features have been leveraged to calculate the similarities amongst data points in the embedded space. This is because the main focus of MLAs has been distance measures and the embedded space is derived based on best effort using unsupervised techniques with evident data loss (due to dimensionality reduction).  </p> <p>This was MNIST, where digits are captured with empty backgrounds. These are very easy cases because all the signals in the feature vectors are true signals that correspond to the digit as its drawn. When we start talking about visualizing data where there are noises in the signals then that case poses certain challenges. For example, taking the case of cifar dataset, the images of things are captured with a varying background as they are all-natural images unlike MNIST with a black background. In the following section, let's have a look at what happens when we apply t-SNE and UMA to the CIFAR dataset.</p> <p> High-level differences between cifar and MNIST dataset. (Image provided by author)</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#more-complex-datasets-like-cifar","title":"More complex datasets like CIFAR","text":"<p>The following figure shows the resultant embedding of CIFAR images after applying UMAP. As shown below results are less than impressive to delineate amongst CIFAR classes or perform any sort of features analysis. </p> <p> Results of CIFAR image feature visualization using t-SNE under different perplexity settings. (Image provided by author)</p> <p>So, what's going on? Let's overlay the images and see if we can find some patterns and make sense of the one big lump we are seeing. The following figure overlays the image. It's really hard to find a consistent similarity between neighboring points. Often we see cars and vehicles nearby but not consistently. They are intermixed with flowers and other classes. It's simply too much noise in the feature vector to do any meaningful convergence. </p> <p> Results of CIFAR image feature visualization using t-SNE. Shows images in an overlay on randomly selected points. (Image provided by author)</p> <p>In the above two figures, we looked at analyzing CIFAR with t-SNE. The following plot is produced by using UMAP. As we can see it's not convincing either. Much like t-SNE, UMAP is also providing one big lump and no meaningful insights. </p> <p> Results of CIFAR image feature visualization using UMAP. (Image provided by author)</p> <p>Following show images of 2 cats that are projected to the same location in embedded space. There is some similarity between the two images like nose, and sharp ears obviously but also the two images have varying distinct features.</p> <p> Results of CIFAR image feature visualization using UMAP showing samples of cats that are reprojected into the same located in the embedded space. (Image provided by author)</p> <p>Likewise, if we look at the following figure where deer and frog are co-located in embedded space, we can see the image texture is very similar. This texture however is the result of normalization and grayscale conversion. As we can see, a lot goes on in nature scenes and without a clear understanding of which features to focus on, one's features can be other's noise. </p> <p> Results of CIFAR image feature visualization using UMAP. Shows images in an overlay on randomly selected points. (Image provided by author)</p> <p>t-SNE and UMAP are feature visualization techniques and perform best when the data vector represents the feature sans noise. </p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#what-to-do-when-there-is-noise-in-features","title":"What to do when there is noise in features?","text":"<p>So, what can we do if there are noises in our feature vectors? We can apply techniques that reduce noises from feature vectors before applying manifold learning algorithms. Given the emphasis on nonlinearity in both t-SNE and UMAP (to preserve nonlinear features), it is better to choose a noise reduction technique that is nonlinear. </p> <p>Autoencoder is a class of unsupervised deep learning techniques that learns the latent representation of the input dataset eliminating noises. Autoencoder can be non-linear depending on the choices of layers in the network. For example, using a convolution layer will allow for non-linearity. If noises are present in the feature vector then an autoencoder can be applied to learn latent features of a dataset and to transform samples to noise-free samples before applying manifold algorithms. UMAP has native integration with Tensorflow for similar use cases that is surfaced as parametric UMAP. Why parametric because autoencoders/neural networks are parametric! i.e. increasing data size will not increase parameters - the parameters may be large but will be fixed and limited. This approach of transforming input feature vectors to the latest representation not only helps with noise reduction but also with complex and very high dimensional feature vectors. </p> <p>The following figure shows the results of applying autoencoder before performing manifold algorithm t-SNE and UMAP for feature visualization. As we can see in the result, the clumps are much more compact and the gaps are wider. The proximity of MNIST classes remains unchanged, however - which is very nice to see.</p> <p> Results of applying autoencoder on MNIST before applying manifold algorithm t-SNE and UMAP. (Image provided by author)</p> <p>So how does it affects the features that contribute to proximities/neighborhood of data? The manifold algorithm is still the same however it's now applying on latent feature vector as produced by autoencoders and not raw features. So effectively, the proximity factor is now calculated on latent representation and not directly on perceptible features. Given the digit clusters are still holding global structure and it's just more packed together within the classes, we can get the sense that it's doing the right things if intra-class clumps can be explained. Let's look at some examples. The following shows a reprojection in the embedded space where 4,9 and 1 are clustered together into larger clusters of 1s. If we look closely the backbone of all these numbers is slanting at about 45 degrees and perhaps that has been the main driving factor. The protruding belly of 4 and 9 are largely ignored but also they are not very prominent. </p> <p> Example of co-located 1s, 4 &amp; 9 in embedded space obtained by applying Paramertic UMAP on MNIST. (Image provided by author)</p> <p>More importantly, looking at the dataset (in the following figure), there are not as many 9s or 4s that have a backbone at that steep slant of 45 degrees. This is more easily shown in the full-scale overlay in the following figure (sparsely chosen images to show to make it more comprehensible). We can see all samples are upright 4s and 9s where there is a slant the protrusion is more prominent. Anyhow, we don't need to get overboard with this as manifold algorithms are not feature detection algorithms and certainly can't be compared to the likes of more powerful feature extraction techniques like convolution. The goal with manifold is to find global and local structures in the dataset. These algorithms work best if signals in datasets are noise-free where noise includes features/characteristics we want ignored in the analysis. A rich natural background is a very good case of noise as shown already in the CIFAR case.</p> <p> Images overlaid on t-SNE of auto-encoded features derived from MNIST dataset. (Image provided by author)</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#how-to-do-this-for-multi-label","title":"how to do this for multi-label","text":"<p>In the early day of learning about this, I found myself wondering how would we do the feature analysis on a multi-label dataset? Multi-class is certainly the easy case - each sample only needs to be color-coded for one class so is easy to visualize. We are also expecting class-specific data to be clumped together mostly (perhaps not always and depends on intent but may be more commonly).</p> <p>If multi-label data consists of exclusive classes similar to Satnford Cars Dataset where options within the make and the models of cars are mutually exclusive, then splitting the visualization to the group of exclusive cases could be very helpful. </p> <p>However, if the multi-label dataset is more alike MLRSNet where classes are independent then it's best to first analyze the data class agnostic and explore if there are any patterns in features and proceed based on this.</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#can-we-apply-this-to-understand-what-neural-networks-are-doing","title":"Can we apply this to understand what neural networks are doing?","text":"<p>A lot of work has been done in the area of explainability and feature understanding that is very well documented in distill blogs. The underlined idea is that we can take the activation of the layers of the neural network and explore what features it is that that particular layer is paying attention to. The activations are essentially the signal that is fired for a given input to the layer. These signals then formulate the feature vector for further analysis to understand where and what the layer is paying more attention to. T-SNE and UMAP are heavily used in these analyses. </p> <p>The distill blogs are very well documented and highly recommended for reading if this is something that is of interest to you.</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2022/06/09/feature-analysis---t-sne-vs-umap/#conclusion","title":"Conclusion","text":"<p>This post was focused on the fundamentals of manifold learning algorithms, and diving into the details of t-SNE and UMAP. This post also compared and contrasted t-SNE and UMAP and presented some analysis of MNIST and CIFAR datasets. We also covered what to do if we have a very high dimensional dataset and also if we have noises in the dataset. Lastly, we touched on what to do if your dataset is multi-label. </p> <p>In the follow-up, I will cover how we can utilize t-SNE and UMAP to better understand what neural networks are doing and apply it in conjunction with convolutions as feature extractors. </p> <p>[umap_doco] https://umap-learn.readthedocs.io/en/latest/how_umap_works.html</p>","tags":["blog","feature-analysis","data-science","tsne","umap","intermediate"]},{"location":"blog/2023/11/12/launch-of-curious-cassies-beach-ride-quest/","title":"Launch of Curious Cassie's Beach Ride Quest","text":"<p>We are thrilled to announce the launch of Curious Cassie's Beach Ride Quest - an exciting concept book from the beloved Curious Cassie series!</p>","tags":["blog","children-book","children-literature","beginner"]},{"location":"blog/2023/11/12/launch-of-curious-cassies-beach-ride-quest/#curious-cassies-beach-ride-quest","title":"Curious Cassie's Beach Ride Quest","text":"<p>Join Cassie, Caleb, and their mom on an extraordinary adventure to the beach. Along the way, they will encounter fascinating situations that explore the wonders of motion and gravity, leaving them inspired by the genius of Sir Isaac Newton.</p> <p>Title: Curious Cassie's Beach Ride Quest: A Celebration of Isaac Newton's Discoveries</p> <p>Genre: Children's Fiction (picture books, junior fiction)</p> <p>Publication Date: 2023-11-12</p> <p></p> <p>You might also enjoy reading ChatGPT vs Me: As a Children's Author</p> <p>Get your copy now:</p> <p>Curious Cassie's Beach Ride Quest is available through Ingram. You can find it at your favorite book retailer. Here are direct links to Amazon:</p> <p> - Amazon |  - Amazon AU</p>","tags":["blog","children-book","children-literature","beginner"]},{"location":"blog/2023/11/12/launch-of-curious-cassies-beach-ride-quest/#stay-connected","title":"Stay Connected!","text":"<p>Connect with Cassie:  | :fontawesome-solid-web: | </p>","tags":["blog","children-book","children-literature","beginner"]},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/","title":"ChatGPT vs Me: As a Children's Authors","text":"<p>For all the right reasons, large language models have taken the world by storm! It\u2019s pretty impressive what ChatGPT can do - unprecedented coherence, relevance and tone of delivery for a synthetic text generation. Well done OpenAI! </p> <p>I have to admit I have strongly resisted the urge to use it for purposes beyond joy, and exploration. It's been very hard to abstain, especially because I am extremely passionate about AI and also I work in AI. I truly, madly, deeply, utterly fear that we, as a community of carers of young people, are simply NOT ready for it! It\u2019s the infancy state of due diligence to understand the societal implications and governance around it that scares me the most. I fear that while we, the grown-ups, are probably ready and raring to go at it, it\u2019s our younger generations who are not at all ready for it. Once this genie is out of the bottle, out is just the way! And it\u2019s the repeat of our social media fiasco all over again. Perhaps I am coming from a dark place of seeing how exponentially easily our kids are getting social media bullied  and exploited with authorities still scrambling even after the fact on how to contain it! </p> <p>On a lighter note, selfishly speaking, I also fear depleting my creative and critical thinking abilities in favour of convenience and productivity. If Darwin\u2019s theory is anything to go by, that\u2019s one human talent we should preserve and reinforce, I think. Did I hear you say \u201cBut you can still be critical of the presented text?\u201d? Sure, but we are also a Large Language Model in many ways :) - we get biased and we are lazy. Is not laziness the inspiration for many useful inventions of our times?</p> <p>As a mother of young kids and as someone who believes in lifelong learning, I made a tiny effort last year to write chapter books for early readers covering the discoveries of the great scientists of our past and present. In my debut release, I featured Sir Isaac Newton\u2019s discoveries in a book titled \u201cCurious Cassie's beach ride quest: A Celebration of Isaac Newton's Discoveries\u201d. I tested the book on a sample of 5 kids all ranging from 6-7 years and observed extreme enthusiasm and an increased number of questions thereafter. Mission accomplished, eh? </p> <p>I failed this morning! I failed to resist the chatGPT urge to see what it would write instead. So here\u2019s Me vs chatGPT, a debut author vs a stochastic parrot:</p> <ul> <li>ChatGPT vs Me: As a Children's Authors</li> <li>ChatGPT vs Me: Show me the script<ul> <li>ChatGPT</li> <li>Prompt<ul> <li>ChatGPT's Response</li> <li>Verdict</li> </ul> </li> <li>Prompt<ul> <li>ChatGPT's Response</li> <li>Verdict</li> </ul> </li> <li>Prompt<ul> <li>ChatGPT's Response</li> <li>Verdict</li> </ul> </li> <li>Prompt<ul> <li>ChatGPT's Response</li> <li>Verdict</li> </ul> </li> <li>Me! Me!</li> </ul> </li> </ul>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#chatgpt-vs-me-show-me-the-script","title":"ChatGPT vs Me: Show me the script","text":""},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#chatgpt","title":"ChatGPT","text":""},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#prompt","title":"Prompt","text":"<p>Write a chapter book for 6 year old kids</p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#chatgpts-response","title":"ChatGPT's Response","text":"<pre><code>Chapter 1: The Magical Forest\n\nIt was a beautiful day in the magical forest. The sun was shining and the birds were singing. The trees were tall and green, and the flowers were blooming.\n\nIn the center of the forest was a small cottage, where a young girl named Lily lived with her parents. Lily was six years old, and she loved to explore the forest.\n\nOne day, while out on a walk, Lily stumbled upon a strange and magical place. It was a clearing filled with glittering diamonds and sparkling jewels.\n\n\"Wow!\" exclaimed Lily. \"I've never seen anything like this before!\"\nAs she reached out to touch one of the diamonds, a bright light shone and a magical fairy appeared before her.\n\n\"Hello, Lily,\" said the fairy. \"I am the guardian of the forest, and I have been waiting for you. You have a very special task to complete.\"\n\n\"Me?\" asked Lily. \"What can I do?\"\n\n\"There is a wicked witch who has been causing trouble in the forest,\" explained the fairy. \"She has been turning all of the animals into stone, and we need your help to stop her.\"\n\n\"I'll do it!\" said Lily, determined to help the animals.\n\nChapter 2: The Wicked Witch\n\nLily set out on her journey to find the wicked witch. She followed the fairy's instructions and travelled deep into the forest.\nAs she walked, she saw that the trees were no longer green and the flowers had withered away. It was clear that the witch had been causing destruction wherever she went.\n\nFinally, Lily came to a dark and gloomy castle. She knew this was where the witch lived.\n\nShe tiptoed through the castle, trying not to make a sound. She could hear the witch cackling in the next room.\n\nLily peeked through the door and saw the witch stirring a bubbling pot. She had a long, crooked nose and sharp, pointed teeth.\n\n\"Ah-ha!\" shouted the witch, turning to face Lily. \"I've been expecting you, little girl. You won't be able to stop me from turning all of the animals into stone!\"\n\nBut Lily was not afraid. She remembered the fairy's words and knew she had to be brave.\n\n\"I won't let you harm any more animals!\" said Lily, standing up to the witch.\n\nThe witch cackled and raised her wand, but Lily was quick. She grabbed a nearby broom and swung it at the witch, knocking the witches wand out of her hand.\n\nThe witch let out a cry of rage and fled the castle, leaving Lily to save the animals.\n\nChapter 3: The Great Celebration\n\nWith the witch gone, Lily was able to use her magic to turn the animals back to normal. The forest was filled with joy and celebration.\n\nThe fairy thanked Lily for her bravery and offered to grant her one wish.\n\n\"I wish for the forest to always be a happy and safe place,\" said Lily.\n\nThe fairy nodded and waved her wand, granting Lily's wish. From then on, the magical forest was filled with happiness and peace.\nLily returned home to her parents, who were overjoyed to see her safe and sound. They threw a great celebration in her honour, and the whole forest came to join in the fun.\n\nLily knew that she would always treasure her adventure in the magical forest, and she hoped to have many more adventures in the future.\n</code></pre>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#verdict","title":"Verdict","text":"<p>Very impressive choice of theme, tone and word selection. It did not give me a title, so I asked to name the title and it responded with \"The Brave Explorer: A Magical Adventure in the Forest.\" Very cool! </p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#prompt_1","title":"Prompt","text":"<p>Write a chapter book for 6 year old kids on STEM</p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#chatgpts-response_1","title":"ChatGPT's Response","text":"<pre><code>Chapter 1: The Science Fair\n\nIt was a beautiful day in the town of Maplewood, and Lily was excited for the annual science fair at her school. She had been working on her project for weeks, and she couldn't wait to show it off.\n\nLily's project was a model of the solar system, complete with miniature planets made out of clay and a sun made out of papier-m\u00e2ch\u00e9. She had worked hard to make sure everything was accurate and to explain the orbits of the planets in a way that other kids could understand.\n\nAs the science fair began, Lily set up her project at her table and waited for the judges to come by. She was a little nervous, but she knew she had done her best.\n\nThe judges were impressed by Lily's project and asked her lots of questions about the solar system. Lily was happy to answer and explain what she had learned.\n\nIn the end, Lily's project won first place in the science fair! She was so proud of herself and couldn't wait to show her parents.\n\nChapter 2: The Technology Club\n\nAfter the science fair, Lily's teacher, Mrs. Kim, asked her if she would like to join the Technology Club at school. Lily was excited at the chance to learn more about science and technology, and she eagerly accepted.\n\nIn the Technology Club, Lily and her friends learned about all sorts of different topics, from coding and robotics to engineering and renewable energy. They built and programmed robots, designed and tested bridges, and learned about how solar panels work.\n\nLily loved the Technology Club and couldn't wait to go each week. She learned so much and had a lot of fun doing it.\n\nChapter 3: The Engineering Competition\n\nOne day, Mrs. Kim announced that the Technology Club was going to participate in an engineering competition. The students would have to design and build a Rube Goldberg machine, a complicated contraption that could perform a simple task in a creative and convoluted way.\n\nLily and her friends were up for the challenge and set to work planning and building their machine. They worked together as a team, using their knowledge of physics, engineering, and problem-solving to make their machine work.\n\nFinally, the day of the competition arrived. Lily and her friends were nervous but excited to see how their machine would perform.\n\nAs they presented their machine to the judges, it worked perfectly, performing the simple task with a series of intricate steps. Lily and her friends were thrilled when they were announced as the winners of the competition!\n\nChapter 4: The Future Scientists\n\nAfter the engineering competition, Lily and her friends in the Technology Club knew that they wanted to continue exploring science and technology in the future. They were already thinking about new projects and competitions they could participate in.\n\nLily knew that she wanted to be a scientist when she grew up, and she was grateful for all of the opportunities she had had to learn and explore in the Technology Club.\n\nShe knew that no matter what she did in the future, she would always have a passion for science and technology and the desire to learn more.\n</code></pre>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#verdict_1","title":"Verdict","text":"<p>Nice plot setting, nice choice of theme, and context. Nice job. I find it's very peripheral, explaining a lot about the setting but nothing about science. Maybe it\u2019s my prompt. Let's give it another go.</p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#prompt_2","title":"Prompt","text":"<p>Write a 6-7 year old kids\u2019 book on Sir Isaac Newton's discoveries with Cassie as a protagonist</p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#chatgpts-response_2","title":"ChatGPT's Response","text":"<pre><code>Cassie and the Apple Tree\n\nCassie was a curious little girl who loved to learn about the world around her. One day, she was walking through her backyard when she saw an apple fall from a tree.\n\n\"Hmm, I wonder why that happened?\" Cassie thought to herself. She climbed up the tree to see if she could find out more.\n\nAs she reached the top, she saw a man standing under the tree. It was Sir Isaac Newton! Cassie had heard of him before. He was a very smart man who had made many important discoveries.\n\"Hello, Cassie,\" Sir Isaac said. \"I see you're curious about the apple.\"\n\n\"Yes, I am,\" Cassie replied. \"Why did it fall to the ground?\"\n\"Ah, that's a good question,\" Sir Isaac said. \"I figured out that there is a force called gravity that pulls objects towards the ground. That's why the apple fell.\"\n\nCassie was amazed. \"Wow, that's so cool!\" she exclaimed.\nSir Isaac smiled. \"I also made many other discoveries,\" he told Cassie. \"Like the laws of motion, which explain how objects move and change speed. And I invented calculus, which helps us understand how things change over time.\"\n\nCassie's head was spinning with all this new information. She couldn't wait to learn more about Sir Isaac's discoveries.\n\n\"Thank you for telling me all about this, Sir Isaac,\" Cassie said. \"I can't wait to learn more!\"\n\n\"You're welcome, Cassie,\" Sir Isaac replied. \"I'm glad you're interested in learning. Remember, the more you learn, the more you'll discover about the world around you.\"\n\nCassie smiled and climbed back down the tree, excited to keep learning and discovering new things.\n</code></pre>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#verdict_2","title":"Verdict","text":"<p>Nice choice of words, context is spot on, and tone of delivery is nice too. Some of the phrases are spot on. \"Wow, that's so cool!\" she exclaimed.\u201d is something I have used too. </p> <p>Apple and Newton are joined together forever. Clich\u00e9, my dear parrot! Clich\u00e9! Well done still. Maybe I like more challenges given to the kids, but I still feel it\u2019s too shallow and lacks details. Let\u2019s give it more work and see what ChatGPT does. </p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#prompt_3","title":"Prompt","text":"<p>Write a 6-7 year old kids chapter book on Sir Isaac Newton's discoveries with Cassie as the protagonist with illustrations</p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#chatgpts-response_3","title":"ChatGPT's Response","text":"<pre><code>Chapter 1: Cassie and the Apple Tree\n\n[Illustration: Cassie is standing in her backyard, looking up at an apple falling from a tree.]\n\nCassie was a curious little girl who loved to learn about the world around her. One day, she was walking through her backyard when she saw an apple fall from a tree.\n\n\"Hmm, I wonder why that happened?\" Cassie thought to herself. She climbed up the tree to see if she could find out more.\n\n[Illustration: Cassie is climbing up the tree, with a determined look on her face.]\n\nAs she reached the top, she saw a man standing under the tree. It was Sir Isaac Newton! Cassie had heard of him before. He was a very smart man who had made many important discoveries.\n\n\"Hello, Cassie,\" Sir Isaac said. \"I see you're curious about the apple.\"\n\n\"Yes, I am,\" Cassie replied. \"Why did it fall to the ground?\"\n\n\"Ah, that's a good question,\" Sir Isaac said. \"I figured out that there is a force called gravity that pulls objects towards the ground. That's why the apple fell.\"\n\n[Illustration: Sir Isaac is pointing to a diagram of the earth and the apple, with an arrow labeled \"gravity\" pointing from the earth to the apple.]\n\nCassie was amazed. \"Wow, that's so cool!\" she exclaimed.\n\nChapter 2: The Laws of Motion\n\nAfter learning about gravity, Cassie couldn't wait to find out more about Sir Isaac's discoveries. She asked him to tell her more.\n\n\"I also made many other discoveries,\" Sir Isaac said. \"Like the laws of motion, which explain how objects move and change speed.\"\n\n[Illustration: Sir Isaac is holding a book labeled \"Laws of Motion,\" with diagrams of moving objects in the background.]\n\nCassie was fascinated. Sir Isaac explained that there are three laws of motion:\n\n    Objects at rest stay at rest, and objects in motion stay in motion with the same speed and direction, unless acted upon by a force.\n    The force needed to change the motion of an object is equal to the mass of the object times its acceleration.\n    For every action, there is an equal and opposite reaction.\n\n[Illustration: Sir Isaac is pointing to a chalkboard with the three laws of motion written on it, with illustrations of objects in motion on either side.]\n\n\"These laws help us understand how objects move and behave in the world around us,\" Sir Isaac said.\n\nChapter 3: Calculus\n\nCassie couldn't believe how much she was learning from Sir Isaac. She asked him if there was anything else he had discovered.\n\n\"Yes, I also invented calculus,\" Sir Isaac said. \"It helps us understand how things change over time.\"\n\n[Illustration: Sir Isaac is holding a book labeled \"Calculus,\" with a diagram of a curve on the cover.]\n\nCassie was a little confused. \"What do you mean?\" she asked.\n\nSir Isaac explained that calculus is a way of studying how things change. \"For example, we can use calculus to understand how fast a ball is rolling down a hill, or how fast a plant is growing,\" he said.\n[Illustration: Sir Isaac is pointing to a graph with a curve on it, with a ball rolling down a hill in the background.]\nCassie was amazed. \"That's so cool!\" she exclaimed.\nChapter 4: The End\nAfter learning all about Sir Isaac's discoveries, Cassie was even more excited to keep learning and discovering new things. She thanked Sir Isaac for all of his help and said goodbye.\n\"Remember, Cassie,\" Sir Isaac said as she walked away. \"The more you learn, the more you'll discover about the world around you.\"\n[Illustration: Cassie is waving goodbye to Sir Isaac, with a big smile on her face.]\nCassie smiled and waved, excited to keep exploring and learning. She knew that there were so many more mysteries to solve and discoveries to be made.\n</code></pre>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#verdict_3","title":"Verdict","text":"<p>I love this line \"The more you learn, the more you'll discover about the world around you.\" ChatGPT, You can be nice if not exploited!  I liked the mention of calculus. It\u2019s a brilliant thought but I stopped at algebra in my book! </p> <p>However, I remain unsatisfied given the lack of detail and meat around the topic. I feel, for now, human writing is more creative, rich and informative! I am glad that\u2019s the way it is! </p>"},{"location":"blog/2024/01/07/chatgpt-vs-me-as-a-childrens-authors/#me-me","title":"Me! Me!","text":"<p>Title: Curious Cassie's beach ride quest: A Celebration of Isaac Newton's Discoveries</p> <p>[Illustration: Cassie is riding in a car with her family! She is buzzing with interesting curious keywords like Wow, What, How, When, Where! Sir Isaac is featured in the book.]</p> <p>Here's a sample of my book. It shows 1<sup>st</sup> chapter of the 3-chapter book. </p> <p></p> <p>I am just a debut author, writing out of hobby. I am profoundly impressed by authors who have written brilliant books to teach, guide and shape our children. I hope we will continue to create far-enriched content to shape ourselves and our future with or without AI - just as long as we are in control. </p> <p>Thanks a lot for reading! If you ever see any value in spreading the word about my book or procuring it for your loved ones then please do so, I would be thrilled! </p> <p>Disclaimer: This is a personal post. Views shared are my own and do not represent my employers.</p>"},{"location":"blog/2024/05/30/deep-learning-at-scale/","title":"Launch of Deep Learning at Scale - An O'Reilly Book","text":"<p>I am thrilled to announce the release of \"Deep Learning at Scale: At the Intersection of Hardware, Software, and Data\" - an O'Reilly Book\"! I have been working on this project for over 2 years.</p> <p>\"Deep Learning at Scale: At the Intersection of Hardware, Software, and Data\" (O'Reilly) illustrates complex concepts of full-stack deep learning and reinforces them through hands-on exercises to equip you with tools and techniques to scale your project. Scaling efforts are only beneficial when they are effective and efficient. To that end, this guide explains the intricate concepts and techniques that will help you scale effectively and efficiently.</p> <p></p>","tags":["blog","deep-learning","machine-learning","advanced"]},{"location":"blog/2024/05/30/deep-learning-at-scale/#order-your-copy-today","title":"Order your copy today","text":"<p>To order your copy, use the following links based on your preferred format:</p> <p>Note</p> <p> - Amazon |  - Amazon AU</p> <p>Note</p> <p> - Amazon |  - Amazon AU</p> <p>Alternatively, you can access the book using the 30-day trial link:</p> <p>30 Days trial access by O'Reilly Media</p> <p>30 days trial - </p>","tags":["blog","deep-learning","machine-learning","advanced"]},{"location":"blog/2024/05/30/deep-learning-at-scale/#more-info","title":"More info","text":"<p>For more information, see details in the project</p>","tags":["blog","deep-learning","machine-learning","advanced"]},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/","title":"Curious Cassie 2.0: Revolutionizing Children's Education Through AI-Powered Storytelling","text":""},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Curious Cassie 2.0: Revolutionizing Children's Education Through AI-Powered Storytelling</li> <li>Table of Contents</li> <li>The Genesis of a Vision</li> <li>Reigniting the Vision with AI</li> <li>The Transformative Potential of Generative AI in Children's Literature</li> <li>Immersive Multi-Sensory Storytelling</li> <li>Current Limitations and Future Directions</li> <li>The Path Forward</li> <li>References</li> </ul>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#the-genesis-of-a-vision","title":"The Genesis of a Vision","text":"<p>In 2022, I embarked on a mission that had long captivated my imagination: creating compelling narratives designed to inspire critical thinking in young minds ages 5-10. This endeavor was born from a profound concern\u2014our digital age increasingly subjects children to passive entertainment, systematically diminishing their innate curiosity and imaginative capabilities. My solution? Develop engaging stories that weave the journeys of eminent scientists and philosophers into accessible narratives, transforming learning into an active, participatory experience.</p> <p>This vision materialized as the \"Curious Cassie\" book series, with each installment honoring a celebrated scientist by integrating their discoveries into narratives that make learning both enjoyable and engaging. I began with \"Curious Cassie's Beach Ride Quest: A Celebration of Isaac Newton's Discoveries\", choosing self-publication after encountering the traditional publishing industry's protracted timelines. This path revealed the formidable challenges novice authors face, particularly those writing for younger audiences, and highlighted areas where I needed to evolve as a children's author.</p> <p>Simultaneously, I authored \"Deep Learning at Scale\" for O'Reilly, a technical work aimed at machine learning practitioners. This parallel experience provided invaluable insights into the transformative power of professional editorial processes. The iterative feedback cycles\u2014critical analysis, editorial review, and meticulous proofreading\u2014substantially elevated the manuscript's quality, underscoring the improvements needed in my self-published children's literature.</p> <p>Without a conventional editorial team, I relied on feedback from educational institutions and libraries to refine the \"Curious Cassie\" series. I recognized that various narrative elements required enhancement: storyline development, curiosity triggers, strategic suspense, and moments that evoke wonder and prompt young readers to question their surroundings. However, professional demands intervened, and this passion project entered an extended hiatus.</p>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#reigniting-the-vision-with-ai","title":"Reigniting the Vision with AI","text":"<p>Today, I return with renewed determination to revitalize \"Curious Cassie.\" My current approach leverages artificial intelligence to create an efficient publishing framework, allowing me to focus on my core passion: storytelling. By harnessing technological advancements, I aim to amplify my creative capabilities and bring Curious Cassie's adventures to life in ways that captivate and inspire young minds.</p>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#the-transformative-potential-of-generative-ai-in-childrens-literature","title":"The Transformative Potential of Generative AI in Children's Literature","text":"<p>Generative artificial intelligence is fundamentally reshaping children's literature, equipping authors with sophisticated tools that enhance storytelling craft. By leveraging breakthroughs in natural language processing and machine learning, writers can now develop dynamic narratives and character dialogues calibrated to specific age groups' comprehension levels and interests. These technologies serve as powerful creative allies, helping authors overcome creative blocks by generating contextually relevant content (Brown et al., 2020).</p> <p>AI-driven platforms are also revolutionizing narrative personalization. By analyzing reader interests and feedback, these systems facilitate the creation of stories that resonate deeply with children, fostering genuine engagement (Zhang et al., 2021). This personalized approach not only captivates young readers but empowers them through stories that reflect their experiences and interests.</p> <p>Furthermore, generative AI significantly enhances narrative refinement through simulated editorial processes that improve structure, pacing, and emotional resonance, mirroring traditional publishing's collaborative editing (Kucuk &amp; Kucuk, 2022). This iterative feedback loop ensures polished, impactful final products that enrich the reading experience.</p> <p>However, integrating AI into storytelling presents distinct challenges. Ethical considerations regarding originality, authorship, and narrative homogenization could potentially limit literary diversity (Gunkel, 2018). Authors must carefully balance AI's advantages while preserving their distinctive creative voice.</p>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#immersive-multi-sensory-storytelling","title":"Immersive Multi-Sensory Storytelling","text":"<p>The integration of visual, auditory, and virtual elements transforms storytelling, creating immersive experiences that engage multiple sensory pathways. Visual components\u2014illustrations and animations\u2014enhance comprehension and emotional connection, particularly among young readers. Research demonstrates that children exposed to illustrated narratives show improved understanding and recall compared to text-only formats (Duke &amp; Pearson, 2002; Hargreaves &amp; North, 1999; Baker, 2013).</p> <p>Augmented reality (AR) and virtual reality (VR) represent the vanguard of innovative storytelling techniques. AR applications overlay digital content onto physical environments, enabling readers to explore narratives within their surroundings (Billinghurst &amp; Duenser, 2012). VR immerses users in fully realized digital worlds, fostering empathy and emotional engagement by allowing readers to experience stories from varied perspectives (Bailenson et al., 2008).</p> <p>By engaging multiple sensory channels, these approaches facilitate deeper cognitive processing and stronger narrative connections, fundamentally transforming how stories are created and consumed (Gee, 2003). The evolving potential for hybrid storytelling formats promises to further enrich educational opportunities through narrative (Slater &amp; Wilbur, 1997).</p> <p>This integration of diverse technologies enables the development of dynamic platforms where the 5 W's (What, When, How, Who, Where) and the 5 C's (Critical thinking, Creativity, Collaboration, Communication, and Citizenship) can be seamlessly woven into educational experiences through storytelling.</p>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#current-limitations-and-future-directions","title":"Current Limitations and Future Directions","text":"<p>While emerging AI storytelling tools show promise, they remain in nascent stages of development. Platforms like TinyTeller AI, StoryPrompt, Sudowrite, StoryCraft AI, and AIStory offer valuable capabilities but also present limitations. Overreliance on AI-generated content may restrict exposure to diverse storytelling styles (Kim et al., 2024; Han &amp; Cai, 2023), while collaborative AI tools may inadvertently foster dependence rather than independence in creative expression (Fan et al., 2024; Hwang, 2024).</p> <p>The current digital education landscape often resembles a one-sided monologue, hampering interactive learning and stifling critical thinking. By reimagining education through the lens of interactive storytelling, we can create enriching platforms that empower learners to actively participate in knowledge acquisition.</p>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#the-path-forward","title":"The Path Forward","text":"<p>I am committed to revitalizing Curious Cassie with AI-enhanced, multi-dimensional storytelling experiences that not only engage young readers but encourage critical thinking about the narratives they encounter. Alongside this revival, I am developing open-source tools to streamline the storybook publishing process, assisting first-time authors in complementing their skills through AI.</p> <p>In an era saturated with misinformation and superficial content, empowering young minds with critical thinking skills has never been more crucial. Through the synergy of human creativity and artificial intelligence, we can transform children's literature into a powerful vehicle for intellectual growth, fostering the next generation of thoughtful, engaged thinkers.</p>"},{"location":"blog/2025/05/10/curious-cassie-20-revolutionizing-childrens-education-through-ai-powered-storytelling/#references","title":"References","text":"<ol> <li> <p>Baker, R. (2013). The Role of Audio in Learning. In J. M. Spector, D. M. Merrill, J. Van Merri\u00ebnboer, &amp; M. P. Driscoll (Eds.), Handbook of Research on Educational Communications and Technology (pp. 393-408). Springer.</p> </li> <li> <p>Bailenson, J. N., Beall, A. C., Blascovich, J., &amp; Loomis, J. M. (2008). Immersive Virtual Environment Technology as a Methodological Tool for Social Psychology. In J. M. H. (Ed.), The Handbook of Social Psychology (pp. 100-124). Wiley.</p> </li> <li> <p>Billinghurst, M., &amp; Duenser, A. (2012). Augmented Reality in the Classroom. In P. Z. Papadopoulos (Ed.), Augmented Reality: Principles and Practice (pp. 219-236). Springer.</p> </li> <li> <p>Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... &amp; Amodei, D. (2020). Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems, 33, 1877-1901.</p> </li> <li> <p>Duke, N. K., &amp; Pearson, P. D. (2002). Effective Practices for Developing Reading Comprehension. In A. E. Farstrup &amp; S. J. Samuels (Eds.), What Research Has to Say About Reading Instruction (pp. 205-242). International Reading Association.</p> </li> <li> <p>Fan, L., Han, S., &amp; Cai, J. (2024). AI-Assisted Creative Writing in Elementary Education: Benefits and Challenges. Journal of Educational Technology and Society, 27(1), 112-125.</p> </li> <li> <p>Gee, J. P. (2003). What Video Games Have to Teach Us About Learning and Literacy. Computers in Human Behavior, 19(1), 199-219.</p> </li> <li> <p>Gunkel, D. J. (2018). The Machine Question: Critical Perspectives on AI, Robots, and Ethics. MIT Press.</p> </li> <li> <p>Han, S., &amp; Cai, J. (2023). TinyTeller: Personalized AI Storytelling for Early Childhood Education. In Proceedings of the International Conference on Educational Technology (pp. 78-92).</p> </li> <li> <p>Hargreaves, D. J., &amp; North, A. C. (1999). The Social and Applied Psychology of Music. Oxford University Press.</p> </li> <li> <p>Hwang, G. J. (2024). Collaborative AI Systems in Education: Impact on Student Engagement and Learning Outcomes. Educational Technology Research and Development, 72(1), 45-62.</p> </li> <li> <p>Kim, J., Lee, S., &amp; Park, H. (2024). Evaluating the Effectiveness of AI-Generated Content in Children's Literacy Development. Reading Research Quarterly, 59(2), 212-229.</p> </li> <li> <p>Kucuk, S., &amp; Kucuk, U. (2022). The Role of AI in the Evolution of Creative Writing. Journal of Creative Writing Studies, 7(1), 1-15.</p> </li> <li> <p>Mayer, R. E. (2009). Multimedia Learning. Cambridge University Press.</p> </li> <li> <p>Slater, M., &amp; Wilbur, S. (1997). A Framework for Immersive Virtual Environments (FIVE): Speculations on the Role of Presence in Virtual Environments. Presence: Teleoperators and Virtual Environments, 6(6), 603-616.</p> </li> <li> <p>Zhang, Y., Wang, J., &amp; Hu, J. (2021). Personalization in Children's Literature: An AI-Driven Approach. International Journal of Child-Computer Interaction, 28, 100-110.</p> </li> </ol>"},{"location":"blog/2019/12/23/replicability---an-extension-to-reproducibility/","title":"Replicability - an extension to reproducibility","text":"<p>This is Part 3 - End-to-end reproducible Machine Learning pipelines on Kubernetes of technical blog series titled [Reproducibility in Machine Learning]. Part 1 &amp; Part 2 can be found here &amp; here respectively.</p>"},{"location":"blog/2019/12/23/replicability---an-extension-to-reproducibility/#part-1-reproducibility-in-machine-learning-research-and-industry","title":"Part 1: Reproducibility in Machine Learning - Research and Industry","text":""},{"location":"blog/2019/12/23/replicability---an-extension-to-reproducibility/#replicability-and","title":"Replicability and","text":"<p>The research community is quite divided when it comes to defining reproducibility and often mixes it up with replicability </p> <p> Figure 4: Replicability defined</p> <p>[Reproducibility in Machine Learning]: /2019/12/20/Reproducibility-in-Machine Learning.html</p>"},{"location":"poems/aint-no-dr-seuss/","title":"A'int no Dr Seuss","text":""},{"location":"poems/aint-no-dr-seuss/#the-poem","title":"The Poem","text":"Knack sack, bloody rack,   Crank crunch, crunch, crunch,   Smudged, stewed, stunned stuck,   Huff hush, hush huff   Crust thirst, thrum hum,   Squeeze squirm, squirm squeeze   Must gust, lust rust!"},{"location":"poems/aint-no-dr-seuss/#inspiration","title":"Inspiration","text":"<p>Who else but Dr. Seuss</p> <p></p>"},{"location":"poems/breaking-thy-bias/","title":"Fearless and Forward - breaking thy bias","text":""},{"location":"poems/breaking-thy-bias/#the-poem","title":"The Poem","text":"Fearless and Forward: breaking thy bias  The strengths and weaknesses,   The characters and charismatics,   The appearances and aspirations,   Not all are created equal,   The abundance of variations,   The power of diversity,   The strength of unity,   How do we fail to see?   Perhaps blinded by the prior beliefs,   So afraid of change, of that glass ceiling   Subsumed by delusion,   Doused in false assurances   Perhaps too scared to walk the line,   Between old faith and curiosity;   Experience and epiphany;   Ambition and passion;   Arrogance and conviction;   Bias and openness;   Beyond this line lies an open world,   Of shared responsibility and collective strengths,   Of humbled weakness and fearless world.   A world of colors, of joys,   Of strengths, of understanding   Of supporting and creating,   A fearless forward better world.   Why would not you,   Walk thy line?   Why would not you,   Break thy bias?"},{"location":"poems/breaking-thy-bias/#inspiration","title":"Inspiration","text":"<p>Internation Women's day 2022 campaign theme #BreakTheBias.</p> <p>Poem also draws inspiration from Heinrich Rohrer quote:</p> <p>Science means constantly walking a tightrope between blind faith and curiosity; between expertise and creativity; between bias and openness; between experience and epiphany; between ambition and passion; and between arrogance and conviction - in short, between an old today and a new tomorrow.</p>"},{"location":"poems/daminis/","title":"To all the Daminis","text":""},{"location":"poems/daminis/#the-poem","title":"The Poem","text":"Can\u2019t believe you had to go through this   Can\u2019t believe someone did this to you   Took a part of you away   Shattering your soul into pieces   As my heart melts away   I have very less to say   Not that I am callous   But hey! no false promises   As I read about you   I feel proud of you   On your courage   And your strength   It\u2019s not just you Damini   Atrocities are such   we are a land of Daminis   Some faded, some long forgotten   I ain\u2019t know, who to blame   So I blame myself   For a being a part of community   Who could not keep you safe   I ain\u2019t no feminist, but I do have soul   For I am female   And I know how you feel   I know how you feel   As millions of hearts reach out to you   To share your pain &amp; your agony   All I can offer you is pray   Love &amp; Support"},{"location":"poems/daminis/#inspiration","title":"Inspiration","text":"<p>An atrocious incident in Dec of 2012, New Delhi</p>"},{"location":"poems/life-of-ai-engineer/","title":"Life of AI Engineers","text":"","tags":["poem","machine-learning","ai","beginner"]},{"location":"poems/life-of-ai-engineer/#listen","title":"Listen","text":"<p>Open in Suno.com</p>","tags":["poem","machine-learning","ai","beginner"]},{"location":"poems/life-of-ai-engineer/#the-poem","title":"The Poem","text":"This is the Life of AI Engineers!  In the lab, it's dark and cold   Lines of code we must unfold   Stackin' layers deep and wide   Neurons dance &amp; they don't collide  Except when they do,   Ouchy Ouw-o-o!   Exploding and vanishing,   Those gradient delights!  Catastrophe! Oh What a cat-a-strophe!  Floating points all day long   My AI kryptonite is python song   Data crunching through the grind   Life's a loop you never unwind  Training models take its toll   GPUs red-hot like coal   Waiting ages, watch and sigh   Why oh why must they defy   Floating points all day long   My AI kryptonite is python song   Data crunching through the grind   Life's a loop you never unwind  Coding in the dark   My cluster's got the spark   I debug through the night   All my errors in sight  YAS, that log DOOM YAS, that lovely OOM! YAS, that CUDA stack And all that lovely crash! This is the Life of AI Engineers!  Hyperparameters we tweak   Finding balance takes weeks   Validation makes us proud   Finally, we shout aloud  Floating points all day long   My AI kryptonite is python song   Data crunching through the grind   Life's a loop you never unwind   My model's acting kinda weird   The Output's also disappeared   CUDA stack my solo guide   It's a freakin' rollercoaster ride  (Ooh, the Life of AI Engineers!)  Errors to the left   Tanking curves to the right   Oh! I feel so alive   In this my AI life  [Human voice][dramatic][bass] (Ah yeah, the AI Engineers life!)  Coffee keeps me Oh so sane   Building neural network lane   My Network's going kinda slow   But, I'm training like a pro  Errors to the left   Tanking curves to the right   Oh! I feel so alive   This is my AI life  This is the Life of AI Engineers!  Coding keeps my heart so strong   I dream of GPUs all day long   Curves we plot they soar so high   Failures make us question why!  Floating points all day long   My AI kryptonite is python song   Data crunching through the grind   Life's a loop you never unwind  This is the Life of AI Engineers!","tags":["poem","machine-learning","ai","beginner"]},{"location":"poems/life-of-ai-engineer/#inspiration","title":"Inspiration","text":"<p>Everyday life! </p>","tags":["poem","machine-learning","ai","beginner"]},{"location":"poems/my-little-butterfly/","title":"My little butterfly","text":""},{"location":"poems/my-little-butterfly/#listen","title":"Listen","text":"<p>Open in Suno.com</p>"},{"location":"poems/my-little-butterfly/#the-poem","title":"The Poem","text":"My little butterfly   You are the apple of my eyes   Seeing you brightly shine   My heart melts to shiny slime   A beautiful day it is today,   You starting your schooling   With million hopes and dreams   I long to see you shine!   The journey you start today, my little girl   You see, it\u2019s about a magical land   You can build, create, innovate!   But you can also destroy, and eliminate!   Its a journey of empowerment   Of empathy, confidence, and courage   Your perseverance is the wand, and   Your knowledge thy spell   So my little bunny,   With a cheeky little grin,   Let the magic unfold   Let the knowledge begin   To take you to infinite possibilities   Of unicorns, fairies, glitters, and utopia!   Of tingle and tinker   Of awe and sympathy   All I ask of you is to be kind,   Both to others and to yourself   And to never fear a failure   For they mean no harm, they are just to teach   Embrace it all, Soak in it,   One thought at a time   One problem at a time   One victory at a time   The world is waiting   For you, to lead the way   To better future and better world   Do not let others dim you down, for you are to be found"},{"location":"poems/my-little-butterfly/#inspiration","title":"Inspiration","text":"<p>First day of my daughters big school!</p>"},{"location":"poems/one-bright-dawn/","title":"One Bright Dawn","text":""},{"location":"poems/one-bright-dawn/#the-poem","title":"The Poem","text":"The bell has rung, filling me in with a flawless zing,   A bell, that sings, mystic rings,   Of twitter and chime,   In perfect rhyme,   The gust of breeze, in its gentle feel,   Touched me deep, inside within,   Soft and sweet, lukewarm feel,   Perfect pamper, as I feel,   The bright shining dawn rays,   Dancing at my door ways,   Winking, smiling, teasing, luring,   In all its magnanimous ways,   And that's when I open my eyes,   Welcoming new days, arms open wide,   Governed by the aura, defined by the angles of time,   With hopes high mountains, in energy of fountains,  I there by call it, utopian sunshine!"},{"location":"poems/one-bright-dawn/#inspiration","title":"Inspiration","text":"<p>An beautiful dawn filled with hope!</p>"},{"location":"poems/singularity/","title":"Singularity","text":"","tags":["poem","machine-learning","ai","intermediate"]},{"location":"poems/singularity/#listen","title":"Listen","text":"<p>Open in Suno.com</p>","tags":["poem","machine-learning","ai","intermediate"]},{"location":"poems/singularity/#the-poem","title":"The Poem","text":"Whispers of apprehension,   Clouding your judgement,   Spiralling you down,   Into a black hole of mess!  You're ready to rise, but you hesitate,   Questions and fear, you second-guess fate.   You may not know it all,   But you have got it all,  **Believe it! Feel it!**   The power's inside!   **Believe it! Feel it!**   Without it, you're denied!  Wear your doubts, Own your fears,   Like shiny armours, stronger each year   Enough is enough, and you know it's right!   Show up now, it'll be all right!   \"Fake it till you make it?\" \u2014 that's just a lie,   A hollow thought, no reason why.   Where's your truth, your inner gleam?   Your singularity?  **Believe it! Feel it! Find it all, within!**   Come hell or high, You will do all right!   Feel that faith, you are nothing without it!   Show up now, it'll be all right!   Enough is enough!   Wear your doubts,   Own your fears,   Face the horizon, no more tears.  The wait is over!   It's time to rise!   ***Like a phoenix! through the skies,***   With your fears, no more your tears.   Gather the ashes, gather the flames,   Your ambition calls your name.   It's now or never, so face your fear,   Let your creed burn, bright and clear!  Feel it, believe it, The strength's within!   Come hell or high, you'll take it in stride!  Wear your doubts, Own your fears,   Channel that fire, feel it sear!   Melt it down, let yourself shine,   This is your moment\u2014pure gold, divine!   Feel it! Believe it!   Find it all, within!  Step by step, on the grind,   With every move, strength you'll find.   Assaying, slaying, climbing high,   Chasing the light, through the endless sky!   Embrace your qualms, Turn your fear to your might,   You are the black hole, With the photonic light!  Channel your power, and bring it to light.   Feel it! Believe it! The strength inside!   Wear your doubts, Own your fears,   Face the horizon, beyond the fears.  Through highs and lows, through joy and sad.   Your power sways 'tween loss and gain,   Find your balance, own your light,   Now go ahead, and shine so bright!   Feel it! Believe it!   Find your way within!  Wear those doubts, Own those fears,   Channel that fire, feel it sear!   Melt it down, refine your soul,   This is you\u2014turn it into gold!  Rise up now, it's gonna be fine!   ***Like a phoenix! through the skies!***","tags":["poem","machine-learning","ai","intermediate"]},{"location":"poems/singularity/#inspiration","title":"Inspiration","text":"<p>Being human!</p>","tags":["poem","machine-learning","ai","intermediate"]},{"location":"projects/KCD/","title":"KCD: Kubernetes Continous Delivery","text":"<p>Kubernetes Continous Delivery (kcd), formally known as Container Version Manager (cvmanager), is a continous integration (CI) and continous delivery (CD) tool designed for Kubernetes cluster/services. Fundamentally, kcd is a custom Kubernetes controller to achieve a declarative configuration approach to continuous deployment.</p>"},{"location":"projects/curious_cassie/","title":"Curious Cassie Book Series","text":"<p>Curious Cassie is a captivating book series designed for young readers who are embarking on their journey of independent reading. These books weave fascinating tales about the remarkable discoveries made by scientists, igniting curiosity and inspiring courage to pursue their own quests! The scientists of the past and present continue to inspire us with their insatiable curiosity and unwavering passion for knowledge.</p> <p>As the great scientist Albert Einstein once said:</p> <p>\"I have no special talent. I am only passionately curious!\"</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#inspiration","title":"Inspiration","text":"<p>The contributors of the Curious Cassie books are dedicated to sharing the incredible achievements of scientists and inventors through a series of interesting stories. Both Suneeta and Jaya, the author and illustrator respectively, recognize the need for more books that ignite curiosity in children and encourage them to ask questions and embark on their own intellectual journeys. With their deep connection to science and engineering, they believe that there are better ways to introduce STEM concepts to children aged 6-8, inspiring them through the stories of great scientists and philosophers throughout history.</p> <p>The Curious Cassie book series aims to do just that. Cassie, a 6-year-old with an insatiable curiosity, fearlessly asks questions and embarks on exciting adventures with her family. Each book in the series is dedicated to a scientist, exploring their discoveries through engaging conversations and captivating storytelling.</p> <p>The important message that Jaya and Suneeta want to convey is:</p> Never stop asking, Keep on believing, It's all about learning, Just keep on wondering, Passionately pursuing, All your Curiosities!","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#contributors","title":"Contributors","text":"<p>Jaya and Suneeta are the creative minds behind Curious Cassie! In August 2022, they were driving through a motorway discussing how electronic devices, such as phones and tablets, are taking away the \"think\" time from our kids - the time when they become curious and go on explorations. That's when they planted the seed of this book series, aiming to inspire future generations by showcasing the brilliance of scientists and philosophers from the past and present \u2665\u203f\u2665!</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#suneeta-mall-author","title":"Suneeta Mall - Author","text":"<p>Suneeta feels the need for more books that spark curiosity in kids and encourage them to ask questions and pursue their quests. Being closely connected to science and engineering, she believes there are better ways to introduce STEM concepts to children aged 6-8, inspiring them through the stories of great scientists and philosophers throughout history. This is where Curious Cassie comes in.</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#jaya-jha-illustrator","title":"Jaya Jha - Illustrator","text":"<p>Jaya is passionate about education and the arts. She is a software developer by profession and is inspired by the questions of her 7-year-old twin daughters. She believes that maintaining the inquisitiveness of young children and providing them with suitable resources is crucial. It brings her immense joy to teach children about numbers or how things work. When her friend Suneeta came up with the idea for this book, Jaya immediately wanted to be a part of it because, for her, this book is the perfect combination of teaching children STEM concepts and visually representing those concepts.</p> <p>You can find Jaya on:  LinkedIn | Twitter| Instagram</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#books-in-the-curious-cassie-series","title":"Books in the Curious Cassie Series","text":"","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#1-curious-cassies-beach-ride-quest","title":"1. Curious Cassie's Beach Ride Quest","text":"<p>Title: Curious Cassie's Beach Ride Quest: A Celebration of Isaac Newton's Discoveries </p> <p>Genre: Children's Fiction (picture books, junior fiction)</p> <p>Publication date: 11-12-2022</p> <p></p> <p>Join Cassie, Caleb, and their mom on an exhilarating journey to the beach, where they encounter various situations that explore the wonders of motion and gravity, leaving them inspired by the genius of Sir Isaac Newton.</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#order-your-copy-today","title":"Order your copy today","text":"<p>Curious Cassie's Beach Ride Quest is available through Ingram. You can find it at your favorite book retailer. Here are direct links to Amazon:</p> <p> - Amazon |  - Amazon AU</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/curious_cassie/#you-might-also-like","title":"You might also like!","text":"<p>To find out more about this project and the launch of the first book in this series, see this post. You might also enjoy this tongue-in-cheek article ChatGPT vs Me: As a Children's Author.</p>","tags":["project","children-book","children-literature","beginner"]},{"location":"projects/feature_analysis/","title":"Feature Analysis","text":"<p>Learning more about manifold learning algorithms has been on my TODO list for a while. I also wanted to play with Captum for a while as well. The feature_analysis project started with the desire to dive into the details of t-SNE and UMAP and the willingness to dive further into the neural network feature, specifically convolutions, and then onto feature-based searches. </p> <p>In the current state, this project completes the deep dive into UMAP and t-SNE and applies that to multiple datasets. My detailed notes on this topic are documented in this [bog] titled <code>Review and comparison of two manifold learning algorithms: t-SNE and UMAP</code>. </p> <p>Early-stage exploration of Captum and weights and feature analysis can be found in this notebook. However, in many ways, this is a work in progress. </p> <p>This project will be a ongoing slow burn person project for me to exlore into [activation atlas] and Captum and build on feature based indexers. </p>","tags":["project","feature-analysis","data-science","machine-learning","intermediate"]},{"location":"projects/gatling-on-ecs/","title":"Gatling on ECS","text":"<p>Gatling, is a powerful tool for performance and load testing. There is no easy to create and scale out Gatling based load. Gatling on ECS was written with intention to scale out load test using AWS elastic container services. For more information see project.</p>"},{"location":"projects/goreportcardlite/","title":"Go Reportcard Lite","text":"<p>GoReportCard Lite, a slim version of original Go Report Card by Shawn Smith and Herman Schaaf catered to be integrated into CI pipelines and can generate reports using local/private repositories. </p> <p>It is a web application that generates a report on the quality of go project. It uses several measures, including <code>gofmt</code>, <code>go vet</code>, <code>go lint</code> and <code>gocyclo</code>. For more info see project</p>"},{"location":"projects/label_noise_with_cleanlabs/","title":"Label noise analysis using cleanlab","text":"<p>Errors in datasets are unavoidable - not just because Murphy's Law always holds but because it's a complicated process involving humans, perception, cognition, and software and systems! So, how do we manage them? It's something that I have been thinking a lot about lately. I, recently came across \"Confidant learning\", a proposed technique by Curtis Northcutt and his group.  It piqued my interested so I spent sometime exploring Cleanlab. </p> <p>If this is something that keeps you up at night too, then here's my initial notes focussing specifically on classification problem space. This article was also published in TDS. label_noise itself is a spike project that using PyTorch, PyTorch lightening and Cleanlab to find errors in MLSRNet dataset. The git repository where all details are stored can be found here.</p>"},{"location":"projects/oreilly-interactive-katacode-series-for-reproducible-ml/","title":"O'reilly Interactive (katacoda) scenario series deep diving into challenges and solution in realising reproducible ML","text":"<p>Very excited to share that based on the KubeCon '19 talk and [reproducible-ML project][repro-ml-blog] and E2E Reproducible ML project,  O'reilly reached out to create an interactive (katacoda) scenario series deep-diving into challenges and solutions in realizing reproducible ML. </p> <p>This course is now live on O'reilly platform and broken down into four parts: 1. Reproducible Deep Learning: Semantic Segmentation on Oxford Pets Dataset 2. Reproducible Deep Learning: Identifying the Reproducibility Challenge 3. Reproducible Deep Learning: Random Seeds and Process-Parallelism 4. Reproducible Deep Learning: Achieving 100% Reproducibility</p> <p>[repro-ml-blog]: https://suneeta-mall.github.io/2019/12/20/Reproducibility-in-Machine Learning.html</p>"},{"location":"projects/oreilly_deep_learning_at_scale/","title":"Deep Learning at Scale - An O'reilly Book","text":"<p>Bringing a deep-learning project into production at scale is quite challenging. To successfully scale your project, a foundational understanding of full stack deep learning, including the knowledge that lies at the intersection of hardware, software, data, and algorithms, is required.</p> <p></p> <p>This book \"Deep Learning at Scale: At the Intersection of Hardware, Software, and Data\" illustrates complex concepts of full stack deep learning and reinforces them through hands-on exercises to arm you with tools and techniques to scale your project. A scaling effort is only beneficial when it's effective and efficient. To that end, this guide explains the intricate concepts and techniques that will help you scale effectively and efficiently.</p> <p>You'll gain a thorough understanding of:</p> <ul> <li>How data flows through the deep-learning network and the role the computation graphs play in building your model</li> <li>How accelerated computing speeds up your training and how best you can utilize the resources at your disposal</li> <li>How to train your model using distributed training paradigms, i.e., data, model, and pipeline parallelism</li> <li>How to leverage PyTorch ecosystems in conjunction with NVIDIA libraries and Triton to scale your model training</li> <li>Debugging, monitoring, and investigating the undesirable bottlenecks that slow down your model training</li> <li>How to expedite the training lifecycle and streamline your feedback loop to iterate model development</li> <li>A set of data tricks and techniques and how to apply them to scale your training model</li> <li>How to select the right tools and techniques for your deep-learning project</li> <li>Options for managing the compute infrastructure when running at scale</li> </ul>","tags":["project","deep-learning","machine-learning","advanced"]},{"location":"projects/oreilly_deep_learning_at_scale/#github-repository","title":"Github Repository","text":"<p>Deep Learning At Scale is an O'Reilly book that provides a wide range of hands-on examples and practice code. You can find the code base for this book on GitHub.</p>","tags":["project","deep-learning","machine-learning","advanced"]},{"location":"projects/oreilly_deep_learning_at_scale/#order-your-copy-today","title":"Order your copy today","text":"<p>Deep Learning at Scale\" (O'Reilly) illustrates complex concepts of full stack deep learning and reinforces them through hands-on exercises to arm you with tools and techniques to scale your project. A scaling effort is only beneficial when it's effective and efficient. To that end, this guide explains the intricate concepts and techniques that will help you scale effectively and efficiently. </p> <p>To order your copy, use the following links as per your choice of format:</p> <p>Note</p> <p> - Amazon |  - Amazon AU</p> <p>Note</p> <p> - Amazon |  - Amazon AU</p> <p>Alternatively, you can access the book using 30 days trial link:</p> <p>30 Days trial access by O'reilly media</p> <p>30 days trial - </p>","tags":["project","deep-learning","machine-learning","advanced"]},{"location":"projects/reproducible-ml/","title":"A End to End Reproducible Machine Learning a sample based on Kubernetes:","text":"<p>Based on Oxford Pet dataset, standard semantic segmentation example by tensorflow  is extended to demonstrate how end to end reproducible machine learning can be realized e2e-ml-on-k8s.</p> <p> Oxford pet dataset</p> <p>This project was referenced in KubeCon US 2019 talk, video available here</p>"},{"location":"talks/AWS_ANZ_Commuity_day_2020/","title":"AWS Community Day 2020","text":"<p>Had the priviledge on being invited to speak at AWS Community Day 2020 to talk about deep learning data curation:</p> <p>Here's the blurb: Nearmap AI: The story of data curation to power deep learning</p> <p>Using deep learning techniques, Nearmap AI converts visual content into semantic knowledge to power decisions in a wide range of organisations and varied business use cases. In this talk we will focus heavily on how we utilise AWS technologies to build systems that allow us to curate ground truth. We will talk more about how we continually grow this dataset and manage the challenges around efficiency and quality. Furthermore, we will touch upon how we are evolving our system to scale to an ever growing list of semantic attributes</p>","tags":["talk","kubernetes","k8s","intermediate"]},{"location":"talks/AWS_ANZ_Commuity_day_2020/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video:  </p>","tags":["talk","kubernetes","k8s","intermediate"]},{"location":"talks/KGC_NY_2022/","title":"Knowledge Graph Conference 2022","text":"<p>I had the opportunity to present recent work <code>Leveraging Domain Knowledge For Deep Learning Based Computer Vision</code> at Knowledge Graph Conference 2022. The blurb for this talk is as following: </p> <p>Deep learning models require massive amounts of data to be performed accurately. As the world is inherently interconnected, we can leverage relationships amongst identifiable objects to improve Deep Learning. For example, a shingle roof can not be a tile roof, but both are roofs. So, we set ourselves a challenge: \"How can we leverage the knowledge and the relationship amongst the things we see in our world to improve our data, software systems, and the deep learning model?\"</p> <p>In this presentation, we share our experiences with knowledge graphs as a technique to model domain knowledge and reason about it to derive an embedding. We have leveraged these embeddings in numerous applications to build a more scalable, reliable, and efficient AI System. The applications include improving the quality and richness of our datasets, identifying gaps in annotators' knowledge, utilizing existing data to synthesize new objects on the fly, and also increasing the efficiencies of deep learning models.</p> <p></p>","tags":["talk","machine-learning","data-science","intermediate"]},{"location":"talks/KGC_NY_2022/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here. The video recording is located here!</p>","tags":["talk","machine-learning","data-science","intermediate"]},{"location":"talks/Kafka_Summit_APAC_2021/","title":"Kafka Summit APAC 2021","text":"<p>I spoke about our recent experience working with ML pipelines at Kafka Summit 2021. The topic was <code>Building More Reliable Data Pipelines for Nearmap's Deep Learning Models: An Evolutionary Case Study</code> link.</p> <p>Continual learning using a continually evolving dataset is the norm for the AI team at Nearmap. We have had a software system &amp; data pipelines to facilitate the management of this ever-growing dataset in place for several years of operation. During that time, both our needs &amp; the system have evolved \u2013 we improvised and learned from early limitations &amp; challenges. </p> <p>One of the biggest challenges of MLOps is building data systems right! Reliable, Fault-tolerant, &amp; continually flowing pipelines are the foundation, with necessary additional capabilities for data quality control, reconciliations, &amp; lineage/tracking.</p> <p>Based on our learnings, we have rebuilt a new generation of our system (based on Kafka) with one aim \u2013 the much-discussed \"operation vacation\". The aim is to facilitate full automation and zero manual intervention of the system.</p> <p>In this session, we will go into details of the challenges we encountered, the lessons we learned, what we improved, and lastly; are we on vacation yet?</p>","tags":["talk","kubernetes","k8s","intermediate"]},{"location":"talks/Kafka_Summit_APAC_2021/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here. Much to my disappointment, the recording is not available: </p>","tags":["talk","kubernetes","k8s","intermediate"]},{"location":"talks/KubeCon-Europe-2018/","title":"Continuous Delivery Meets Custom Kubernetes Controller: A Declarative Configuration Approach to CI/CD","text":"<p>At Nearmap, we have been working on an open source CI/CD solution for Kubernetes based workload called KCD for Kubernetes Continous Delivery (Formally known as CVManager (Container Version Manager)). We had oppertunity to present this solution at KubeCon EU Copenhagen, Denmark 2018. For more details of this talk see link and associated blog with detailed info can be found here.</p> <p></p>"},{"location":"talks/KubeCon-Europe-2018/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video:  </p>"},{"location":"talks/KubeCon_NA_2021/","title":"KubeCon NA 2021 - Who Killed My Pod? #Whodunit","text":"<p>Sometime early this year, I deployed a brand new thoroughly tested, and profiled application onto a self-managed Kubernetes cluster. Suffice to say, all hell broke loose. The pods were getting OOMKilled with error code 137 left and right. This sparked a massive crime scene investigation and some interesting insights were discovered. I blogged about this in May, 2021. I have made some more progress on this since then, as a sidekick. </p> <p>I thought it would be a fun topic to share in KubeCon, right? Turn out, the committee thought so too (thank you!).  So, I am very glad to be talking about this particular experience at KubeCon North America 2021. This tallk is titled <code>Who Killed My Pod? #Whodunit</code> and is scheduled for 13<sup>th</sup> Oct 2021. I will be going over my experience and talk about exactly who killed my pod #whodunit, why, and the fix!</p>","tags":["talk","kubernetes","k8s","intermediate"]},{"location":"talks/KubeCon_NA_2021/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and the video here.</p>","tags":["talk","kubernetes","k8s","intermediate"]},{"location":"talks/KubeCon_US_2019/","title":"Realizing End to End Reproducible Machine Learning on Kubernetes","text":"<p>Creating reproducible machine learning system is hard! It is because challenges pertaining to reproducibility stem from all 5 ingredients of machine learning systems - software, hardware, algorithms, process and practice and data. </p> <p></p> <p>In this talk, I talk about how we can write 100% reproducible ML code. Extend this discussion to write end-to-end reproducible ML workflow using Pachyderm, Kubeflow, Katib, ModelDB, Seldon and Argo.</p>"},{"location":"talks/KubeCon_US_2019/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video:  </p>"},{"location":"talks/KubernetesSydneyForum_AU_2019/","title":"Running Massively Parallel Deep-learning Inference Pipelines on Kubernetes","text":"<p>Nearmap captures terabytes of aerial imagery daily. With the introduction of artificial intelligence (AI) capabilities, Nearmap has leveraged Kubernetes to generate AI content based on tens of petabytes of images effectively and efficiently.</p> <p>This talk covers how using Kubernetes as the backbone of our AI infrastructure, allowed us to build a fully automated deep-learning inferential pipeline that despite not being embarrassingly parallel is actually massively parallel. This talk explains the architecture of this auto-scalable solution that has exhausted all K80 spot GPUs across all US data centres of AWS for weeks. This system has already produced semantic content on over a million km2 area at resolution as high as 5cm/pixel in just 2 weeks. In this talk, you will learn about the joys of building and running this system at scale, challenges encountered, their resolution, &amp; future work.</p>"},{"location":"talks/KubernetesSydneyForum_AU_2019/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video:  </p>"},{"location":"talks/SPIE-2015/","title":"Implementation and value of using a split-plot reader design in a study of digital breast tomosynthesis in a breast cancer assessment clinic","text":"<p>The rapid evolution in medical imaging has led to an increased number of recurrent trials, primarily to ensure that the efficacy of new imaging techniques is known. The cost associated with time and ../resources in conducting such trials is usually high. </p> <p>The recruitment of participants, in a medium to large reader study, is often very challenging as the demanding number of cases discourages involvement with the trial. We aim to evaluate the efficacy of Digital Breast Tomosynthesis (DBT) in a recall assessment clinic in Australia in a prospective multi-reader-multi-case (MRMC) trial. Conducting such a study with the more commonly used fully crossed MRMC study design would require more cases and more cases read per reader, which was not viable in our setting. With an aim to perform a cost effective yet statistically efficient clinical trial, we evaluated alternative study designs, particularly the alternative split-plot MRMC study design and compared and contrasted it with more commonly used fully crossed MRMC study design. Our results suggest that \u2018split-plot\u2019, an alternative MRMC study design, could be very beneficial for medium to large clinical trials and the cost associated with conducting such trials can be greatly reduced without adversely effecting the variance of the study. We have also noted an inverse dependency between number of required readers and cases to achieve a target variance. This suggests that split-plot could also be very beneficial for studies that focus on cases that are hard to procure or readers that are hard to recruit. We believe that our results may be relevant to other researchers seeking to design a medium to large clinical trials.</p>"},{"location":"talks/SPIE-2015/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video: </p>"},{"location":"talks/SPIE-2018/","title":"A deep (learning) dive into visual search behaviour of breast radiologists","text":"<p>Visual search, the process of detecting and identifying objects using the eye movements (saccades) and the foveal vision, has been studied for identification of root causes of errors in the interpretation of mammography. The aim of this study is to model visual search behaviour of radiologists and their interpretation of mammograms using deep machine learning approaches. Our model is based on a deep convolutional neural network, a biologically-inspired multilayer perceptron that simulates the visual cortex, and is reinforced with transfer learning techniques.</p> <p>Eye tracking data obtained from 8 radiologists (of varying experience levels in reading mammograms) reviewing 120 two-view digital mammography cases (59 cancers) have been used to train the model, which was pre-trained with the ImageNet dataset for transfer learning. Areas of the mammogram that received direct (foveally fixated), indirect (peripherally fixated) or no (never fixated) visual attention were extracted from radiologists\u2019 visual search maps (obtained by a head mounted eye tracking device). These areas, along with the radiologists\u2019 assessment (including confidence of the assessment) of suspected malignancy were used to model: 1) Radiologists\u2019 decision; 2) Radiologists\u2019 confidence on such decision; and 3) The attentional level (i.e. foveal, peripheral or none) obtained by an area of the mammogram. Our results indicate high accuracy and low misclassification in modelling such behaviours.</p>"},{"location":"talks/SPIE-2018/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video: </p>"},{"location":"talks/SPIE-2019/","title":"Missed cancer and visual search of mammograms: what feature-based Machine Learning can tell us that deep-convolution learning cannot","text":"<p>Significant amount of effort has been invested in improving the quality of breast imaging modalities (for example, mammography) to increase the accuracy of breast cancer detection. Despite that, about 4-34% of cancers are still missed during mammographic examination of cancer of the breast. This indicates the need to explore a) The features of the lesions that are missed, and b) Whether the features of missed cancers contribute to why some cancers are not \u2018looked at\u2019 (search error) whereas others are \u2018looked at\u2019 but still not reported. In this visual search study, we perform feature analysis of all lesions that were missed by at least one participating radiologist. </p> <p>We focus on features extracted by means of Grey Level Co-occurrence Matrix properties, textural properties using Gabor filters, statistical information extraction using 2<sup>nd</sup> and higher-order (3<sup>rd</sup> and 4<sup>th</sup>) spectral analysis and also spatial-temporal attributes of radiologists\u2019 visual search behaviour. We perform Analysis of Variance (ANOVA) on these features to explore the differences in features for cancers that were missed due to a) search, b) perception and c) decision making errors. Using these features, we trained Support Vector Machine, Gradient Boosting and stochastic gradient decent classifiers to determine the type of missed cancer (search, perception and decision making). We compared these feature-based models with a model trained using deep convolution neural network that learns features by itself. We determined whether deep learning or traditional machine learning performs best in this task.</p>"},{"location":"talks/SPIE-2019/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video: </p>"},{"location":"talks/She_Builds_on_AWS_2020/","title":"AWS She Builds on AWS 2020 - Nearmap AI: The story of data curation to power deep learning","text":"<p>Incredibly excited to be speaking at AWS 2020's She Builds Day event! </p> <p>AWS She Builds is an inclusive program that celebrates the Developer community and empowers those who identify as female in the tech industry.  A short video celebrating She build program can be found here.</p> <p>Here's the blurb:  Using deep learning techniques, Nearmap AI converts visual content into semantic knowledge to power decisions in a wide range of organisations and varied business use cases. In this talk we will focus heavily on how we utilise AWS technologies to build systems that allow us to curate  a reliable ground truth that is driven by human and algorithmic input. We will talk more about how we continually grow this dataset and manage the challenges around efficiency and quality. Furthermore, we will touch upon how we are evolving our system to scale to an ever growing list of semantic attributes, and continual improvement of the performance of our models.</p>"},{"location":"talks/She_Builds_on_AWS_2020/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video:  </p>"},{"location":"talks/Strata_Data_AI_US_2020/","title":"Deep learning meets Kubernetes: Running massively parallel inference pipelines efficiently","text":"<p>Nearmap captures terabytes of aerial imagery daily. With the introduction of AI capabilities, Nearmap has leveraged Kubernetes to generate AI content based on tens of petabytes of images effectively and efficiently. </p> <p>Suneeta Mall walks you through the joys of building and running this system at scale, challenges encountered, the company\u2019s resolution, and future work. Some of the challenges encountered, for instance, have been around provisioning a conditionally stateful fault-tolerant directed acyclic graph (DAG), autoscaling, etcd, networking, GPU orchestration and sharing, and hybrid cluster setup. Exploiting Kubernetes\u2019s resilient, highly available, extensible, declarative state management capabilities, the company built a fully automated solution that at the core is a DAG\u2014with each node fanning out to achieve said task in shortest time possible. The company uses this architecture for a deep learning inference of billions of high-resolution aerial images on a mix of GPU and CPU compute, primarily driven off the spot pricing scheme. You\u2019ll discover the architecture of this autoscalable solution that exhausted all K80 spot GPUs across all US data centers of AWS for weeks. Built purely using open source software, this solution is so resilient and elastic that the company has scaled on demand from zero to thousands of compute nodes, crunching through petabytes of images to generate semantic segmentation results with effectively no manual intervention. This system has already produced semantic content on over a million-kilometers-squared area at resolution as high as 5 cm per pixel in just two weeks.</p> <p>This conference has since been cancelled in light of COVID-19.</p>"},{"location":"talks/YOW_Data_Syd_2019/","title":"The 3-R's of Data-Science - Repeatability, Reproducibility, and Replicability","text":"<p>Reproducibility crisis is real in data-science. This crisis has been recognized in data-science research and several efforts e.g. International Conference on Learning Representations has been underway in improving reproducibility in data science research. Dr. Joelle Pineau, an Associate Professor at McGill University and lead for Facebook\u2019s Artificial Intelligence Research lab (FAIR) in her talk covered the importance of reproducibility.</p> <p>Industry adoptation of data-science in last 5 years have been phenomenon. As per [KDnuggets][kdnuggets_2017], Machine Learning/data-science surpassed big data frenzy in 2017! According to a recent survey in UK (year 2016), 84% of startups primarily focussed on data-science. Whats more interesting is that more than half of these companies preferred to build, train and use their own models as oppose to sourcing it from elsewhere. According to Evolving Data Infrastructure - Ben Lorica and Paco Nathan (O\u2019Reilly, Oct 2018), 58% of industries were seriously building data science based solutions, with only 14% indicating no involvement data or data-science just yet.</p> <p></p> <p>The 3-R's of Data-Science - Repeatability, Reproducibility, and Replicability is YOW Data 2019 (Sydney) talk presented in May 2019. In this talk, I covered the 3-R's Repeatability, Reproducibility, and Replicability and tools and techniques avaialable to practice reproducible data-science. Slides can be accessed on this link.</p> <p>So here I am at YOW Data 2019 (Sydney)!</p> <p></p>"},{"location":"talks/YOW_Data_Syd_2019/#slides-and-video","title":"Slides and video","text":"<p>Slides can be found here and video:  </p> <p>[kdnuggets_2017]: https://www.kdnuggets.com/2017/05/Machine Learning-overtaking-big-data.html</p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/archive/2021/","title":"2021","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/category/generative-ai/","title":"Generative AI","text":""},{"location":"blog/category/book/","title":"Book","text":""},{"location":"blog/category/llm/","title":"LLM","text":""},{"location":"blog/category/curious-cassie/","title":"Curious Cassie","text":""},{"location":"blog/category/machine-learning/","title":"Machine Learning","text":""},{"location":"blog/category/ai/","title":"AI","text":""},{"location":"blog/category/deep-learning/","title":"Deep Learning","text":""},{"location":"blog/category/data-science/","title":"Data-science","text":""},{"location":"blog/category/childrens-books/","title":"Children's Books","text":""},{"location":"blog/category/software/","title":"Software","text":""},{"location":"blog/category/data/","title":"Data","text":""},{"location":"blog/category/data-centric-ai/","title":"Data-Centric-AI","text":""},{"location":"blog/category/t-sne/","title":"t-SNE","text":""},{"location":"blog/category/umap/","title":"UMAP","text":""},{"location":"blog/category/pytorch/","title":"PyTorch","text":""},{"location":"blog/category/confident-learning/","title":"Confident-Learning","text":""},{"location":"blog/category/kubernetes/","title":"Kubernetes","text":""},{"location":"blog/category/oom/","title":"OOM","text":""},{"location":"blog/category/reproducible-ml/","title":"Reproducible-ml","text":""},{"location":"blog/category/technology/","title":"Technology","text":""},{"location":"blog/page/2/","title":"Blog","text":""},{"location":"blog/category/ai/page/2/","title":"AI","text":""},{"location":"blog/category/machine-learning/page/2/","title":"Machine Learning","text":""},{"location":"tags/","title":"Content Tags","text":"<p>This page provides an overview of all tags used across the content. Click on any tag to see all content tagged with it.</p>"},{"location":"tags/#content-types","title":"Content Types","text":"<ul> <li>blog - Blog posts and articles</li> <li>project - Project showcases and documentation</li> <li>talk - Conference talks and presentations</li> <li>poem - Poetry and creative writing</li> <li>children-book - Children's literature</li> </ul>"},{"location":"tags/#topics","title":"Topics","text":"<ul> <li>machine-learning - Machine learning concepts and applications</li> <li>deep-learning - Deep learning and neural networks</li> <li>kubernetes - Kubernetes and container orchestration</li> <li>reproducibility - Reproducible research and ML pipelines</li> <li>data-science - Data science and analytics</li> <li>feature-analysis - Feature analysis and visualization</li> <li>clean-lab - Clean Lab and data quality</li> <li>chatgpt - ChatGPT and AI applications</li> <li>children-literature - Children's books and stories</li> </ul>"},{"location":"tags/#technical","title":"Technical","text":"<ul> <li>python - Python programming</li> <li>tensorflow - TensorFlow framework</li> <li>hydra - Hydra configuration</li> <li>pydantic - Pydantic data validation</li> <li>tsne - t-SNE visualization</li> <li>umap - UMAP dimensionality reduction</li> <li>k8s - Kubernetes</li> </ul>"},{"location":"tags/#experience-level","title":"Experience Level","text":"<ul> <li>beginner - Beginner-friendly content</li> <li>intermediate - Intermediate level content</li> <li>advanced - Advanced topics and concepts </li> </ul>"},{"location":"tags/#advanced","title":"advanced","text":"<ul> <li>Data in Deep Learning</li> <li>Deep Learning at Scale</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#ai","title":"ai","text":"<ul> <li>Life of AI Engineer</li> <li>Singularity</li> </ul>"},{"location":"tags/#beginner","title":"beginner","text":"<ul> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Life of AI Engineer</li> <li>Curious Cassie Books</li> </ul>"},{"location":"tags/#blog","title":"blog","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>Data in Deep Learning</li> <li>Hydra Pydantic Config Management</li> <li>Confident Learning and Clean Data</li> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#children-book","title":"children-book","text":"<ul> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Curious Cassie Books</li> </ul>"},{"location":"tags/#children-literature","title":"children-literature","text":"<ul> <li>Launch of Curious Cassie's Beach Ride Quest</li> <li>Curious Cassie Books</li> </ul>"},{"location":"tags/#clean-lab","title":"clean-lab","text":"<ul> <li>Confident Learning and Clean Data</li> </ul>"},{"location":"tags/#data-science","title":"data-science","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>Data in Deep Learning</li> <li>Confident Learning and Clean Data</li> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Feature Analysis</li> <li>Knowledge Graph Conference 2022</li> </ul>"},{"location":"tags/#deep-learning","title":"deep-learning","text":"<ul> <li>Data in Deep Learning</li> <li>Deep Learning at Scale</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#feature-analysis","title":"feature-analysis","text":"<ul> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Feature Analysis</li> </ul>"},{"location":"tags/#hydra","title":"hydra","text":"<ul> <li>Hydra Pydantic Config Management</li> </ul>"},{"location":"tags/#intermediate","title":"intermediate","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>Hydra Pydantic Config Management</li> <li>Confident Learning and Clean Data</li> <li>Feature Analysis - t-SNE vs UMAP</li> <li>Singularity</li> <li>Feature Analysis</li> <li>AWS Community Day 2020</li> <li>Knowledge Graph Conference 2022</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#k8s","title":"k8s","text":"<ul> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>AWS Community Day 2020</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#kubernetes","title":"kubernetes","text":"<ul> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>AWS Community Day 2020</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#machine-learning","title":"machine-learning","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> <li>Data in Deep Learning</li> <li>Hydra Pydantic Config Management</li> <li>Confident Learning and Clean Data</li> <li>Deep Learning at Scale</li> <li>Life of AI Engineer</li> <li>Singularity</li> <li>Feature Analysis</li> <li>Deep Learning at Scale</li> <li>Knowledge Graph Conference 2022</li> </ul>"},{"location":"tags/#poem","title":"poem","text":"<ul> <li>Life of AI Engineer</li> <li>Singularity</li> </ul>"},{"location":"tags/#project","title":"project","text":"<ul> <li>Curious Cassie Books</li> <li>Feature Analysis</li> <li>Deep Learning at Scale</li> </ul>"},{"location":"tags/#pydantic","title":"pydantic","text":"<ul> <li>Hydra Pydantic Config Management</li> </ul>"},{"location":"tags/#python","title":"python","text":"<ul> <li>Hydra Pydantic Config Management</li> </ul>"},{"location":"tags/#reproducibility","title":"reproducibility","text":"<ul> <li>Reproducible ML Research in Industry</li> <li>Reproducible ML with TensorFlow</li> <li>End-to-end reproducible Machine Learning pipelines on Kubernetes</li> </ul>"},{"location":"tags/#talk","title":"talk","text":"<ul> <li>AWS Community Day 2020</li> <li>Knowledge Graph Conference 2022</li> <li>Kafka Summit APAC 2021</li> <li>KubeCon NA 2021 - Who Killed My Pod? #Whodunit</li> </ul>"},{"location":"tags/#tensorflow","title":"tensorflow","text":"<ul> <li>Reproducible ML with TensorFlow</li> </ul>"},{"location":"tags/#tsne","title":"tsne","text":"<ul> <li>Feature Analysis - t-SNE vs UMAP</li> </ul>"},{"location":"tags/#umap","title":"umap","text":"<ul> <li>Feature Analysis - t-SNE vs UMAP</li> </ul>"}]}