<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href="https://suneeta-mall.github.io/blog/2022/06/09/feature-analysis---t-sne-vs-umap/" rel="canonical"><link href=../../../05/16/confident-learning-and-clean-data/ rel=prev><link href=../../../../2023/11/12/launch-of-curious-cassies-beach-ride-quest/ rel=next><link rel=alternate type=application/rss+xml title="RSS feed" href=../../../../../feed_rss_created.xml><link rel=alternate type=application/rss+xml title="RSS feed of updated content" href=../../../../../feed_rss_updated.xml><link rel=icon href=../../../../../resources/site/favicon.svg><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.18"><title>Feature Analysis - t-SNE vs UMAP - Random Musings - Rambling of a curious engineer & data scientist!</title><link rel=stylesheet href=../../../../../assets/stylesheets/main.66ac8b77.min.css><link rel=stylesheet href=../../../../../assets/stylesheets/palette.06af60db.min.css><link rel="stylesheet" href="../../../../../assets/external/fonts.googleapis.com/css.49ea35f2.css"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><meta property=og:type content=website><meta property=og:title content="Feature Analysis - t-SNE vs UMAP - Random Musings - Rambling of a curious engineer & data scientist!"><meta property=og:description content=None><meta property=og:image content=https://suneeta-mall.github.io/assets/images/social/blog/posts/2022-06-09-feature_analysis_tsne_vs_umap.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://suneeta-mall.github.io/blog/2022/06/09/feature-analysis---t-sne-vs-umap/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Feature Analysis - t-SNE vs UMAP - Random Musings - Rambling of a curious engineer & data scientist!"><meta name=twitter:description content=None><meta name=twitter:image content=https://suneeta-mall.github.io/assets/images/social/blog/posts/2022-06-09-feature_analysis_tsne_vs_umap.png></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#review-and-comparison-of-two-manifold-learning-algorithms-t-sne-and-umap class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> <a href=/projects/oreilly_deep_learning_at_scale/ > <strong>ðŸŽ‰ New Book Release!</strong> Check out "Deep Learning at Scale" - An O'Reilly Book </a> </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href="https://suneeta-mall.github.io/" title="Random Musings - Rambling of a curious engineer &amp; data scientist!" class="md-header__button md-logo" aria-label="Random Musings - Rambling of a curious engineer &amp; data scientist!" data-md-component="logo"> <img src=../../../../../resources/site/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Random Musings - Rambling of a curious engineer & data scientist! </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Feature Analysis - t-SNE vs UMAP </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 1 3 3 3 3 0 0 1-3 3 3 3 0 0 1-3-3 3 3 0 0 1 3-3m0-4.5c5 0 9.27 3.11 11 7.5-1.73 4.39-6 7.5-11 7.5S2.73 16.39 1 12c1.73-4.39 6-7.5 11-7.5M3.18 12a9.821 9.821 0 0 0 17.64 0 9.821 9.821 0 0 0-17.64 0Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../../../projects/oreilly_deep_learning_at_scale/ class=md-tabs__link> Projects </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../../../ class=md-tabs__link> Blog </a> </li> <li class=md-tabs__item> <a href=../../../../../tags/ class=md-tabs__link> Tags </a> </li> <li class=md-tabs__item> <a href=../../../../../talks/KGC_NY_2022/ class=md-tabs__link> Talks </a> </li> <li class=md-tabs__item> <a href=../../../../../poems/singularity/ class=md-tabs__link> Poems </a> </li> <li class=md-tabs__item> <a href=../../../../../about/ class=md-tabs__link> About Me </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation hidden> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href="https://suneeta-mall.github.io/" title="Random Musings - Rambling of a curious engineer &amp; data scientist!" class="md-nav__button md-logo" aria-label="Random Musings - Rambling of a curious engineer &amp; data scientist!" data-md-component="logo"> <img src=../../../../../resources/site/logo.svg alt=logo> </a> Random Musings - Rambling of a curious engineer & data scientist! </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../../projects/oreilly_deep_learning_at_scale/ class=md-nav__link> <span class=md-ellipsis> Deep Learning at Scale </span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/curious_cassie/ class=md-nav__link> <span class=md-ellipsis> Curious Cassie - The Children's Books </span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/feature_analysis/ class=md-nav__link> <span class=md-ellipsis> Label Noise with Clean Lab </span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/feature_analysis/ class=md-nav__link> <span class=md-ellipsis> Feature Analysis </span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/oreilly-interactive-katacode-series-for-reproducible-ml/ class=md-nav__link> <span class=md-ellipsis> Oreilly Katacode Series </span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/reproducible-ml/ class=md-nav__link> <span class=md-ellipsis> Reproducible-ML </span> </a> </li> <li class=md-nav__item> <a href=../../../../../projects/KCD/ class=md-nav__link> <span class=md-ellipsis> KCD </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <div class="md-nav__link md-nav__container"> <a href=../../../../ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../archive/2025/ class=md-nav__link> <span class=md-ellipsis> 2025 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2022/ class=md-nav__link> <span class=md-ellipsis> 2022 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2021/ class=md-nav__link> <span class=md-ellipsis> 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2019/ class=md-nav__link> <span class=md-ellipsis> 2019 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../category/ai/ class=md-nav__link> <span class=md-ellipsis> AI </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/book/ class=md-nav__link> <span class=md-ellipsis> Book </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/childrens-books/ class=md-nav__link> <span class=md-ellipsis> Children's Books </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/confident-learning/ class=md-nav__link> <span class=md-ellipsis> Confident-Learning </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/curious-cassie/ class=md-nav__link> <span class=md-ellipsis> Curious Cassie </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/data/ class=md-nav__link> <span class=md-ellipsis> Data </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/data-centric-ai/ class=md-nav__link> <span class=md-ellipsis> Data-Centric-AI </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/data-science/ class=md-nav__link> <span class=md-ellipsis> Data-science </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/deep-learning/ class=md-nav__link> <span class=md-ellipsis> Deep Learning </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/generative-ai/ class=md-nav__link> <span class=md-ellipsis> Generative AI </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/kubernetes/ class=md-nav__link> <span class=md-ellipsis> Kubernetes </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/llm/ class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/machine-learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/oom/ class=md-nav__link> <span class=md-ellipsis> OOM </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/pytorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/reproducible-ml/ class=md-nav__link> <span class=md-ellipsis> Reproducible-ml </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/software/ class=md-nav__link> <span class=md-ellipsis> Software </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/technology/ class=md-nav__link> <span class=md-ellipsis> Technology </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/umap/ class=md-nav__link> <span class=md-ellipsis> UMAP </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/t-sne/ class=md-nav__link> <span class=md-ellipsis> t-SNE </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../../../tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Talks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Talks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../../talks/KGC_NY_2022/ class=md-nav__link> <span class=md-ellipsis> Knowledge Graph Conference 2022 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/KubeCon_NA_2021/ class=md-nav__link> <span class=md-ellipsis> KubeCon NA 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/Kafka_Summit_APAC_2021/ class=md-nav__link> <span class=md-ellipsis> Kafka Summit APAC 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/AWS_ANZ_Commuity_day_2020/ class=md-nav__link> <span class=md-ellipsis> AWS Community Day 2020 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/She_Builds_on_AWS_2020/ class=md-nav__link> <span class=md-ellipsis> AWS She Builds on AWS 2020 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/KubeCon_US_2019/ class=md-nav__link> <span class=md-ellipsis> KubeCon US 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/KubernetesSydneyForum_AU_2019/ class=md-nav__link> <span class=md-ellipsis> Kubernetes Sydney 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/YOW_Data_Syd_2019/ class=md-nav__link> <span class=md-ellipsis> YOW Data 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/KubeCon-Europe-2018/ class=md-nav__link> <span class=md-ellipsis> KubeCon EU 2018 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/SPIE-2019/ class=md-nav__link> <span class=md-ellipsis> SPIE 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/SPIE-2018/ class=md-nav__link> <span class=md-ellipsis> SPIE 2018 </span> </a> </li> <li class=md-nav__item> <a href=../../../../../talks/SPIE-2015/ class=md-nav__link> <span class=md-ellipsis> SPIE 2015 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Poems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Poems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../../poems/singularity/ class=md-nav__link> <span class=md-ellipsis> Singularity </span> </a> </li> <li class=md-nav__item> <a href=../../../../../poems/life-of-ai-engineer/ class=md-nav__link> <span class=md-ellipsis> Life of AI Engineers </span> </a> </li> <li class=md-nav__item> <a href=../../../../../poems/my-little-butterfly/ class=md-nav__link> <span class=md-ellipsis> My little Butterfly </span> </a> </li> <li class=md-nav__item> <a href=../../../../../poems/breaking-thy-bias/ class=md-nav__link> <span class=md-ellipsis> Breaking Thy Bias </span> </a> </li> <li class=md-nav__item> <a href=../../../../../poems/daminis/ class=md-nav__link> <span class=md-ellipsis> Daminis </span> </a> </li> <li class=md-nav__item> <a href=../../../../../poems/one-bright-dawn/ class=md-nav__link> <span class=md-ellipsis> One Bright Dawn </span> </a> </li> <li class=md-nav__item> <a href=../../../../../poems/aint-no-dr-seuss/ class=md-nav__link> <span class=md-ellipsis> Aint no Dr. Seuss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../../../about/ class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content md-content--post" data-md-component=content> <div class="md-sidebar md-sidebar--post" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class="md-sidebar__inner md-post"> <nav class="md-nav md-nav--primary"> <div class=md-post__back> <div class="md-nav__title md-nav__container"> <a href=../../../../ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> <span class=md-ellipsis> Back to index </span> </a> </div> </div> <div class="md-post__authors md-typeset"> <div class="md-profile md-post__profile"> <span class="md-author md-author--long"> <img src=/resources/me.png alt="Suneeta Mall"> </span> <span class=md-profile__description> <strong> Suneeta Mall </strong> <br> Builder </span> </div> </div> <ul class="md-post__meta md-nav__list"> <li class="md-nav__item md-nav__item--section"> <div class=md-post__title> <span class=md-ellipsis> Metadata </span> </div> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5v-5Z"/></svg> <time datetime="2022-06-09 00:00:00" class=md-ellipsis>June 9, 2022</time> </div> </li> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9 3v15h3V3H9m3 2 4 13 3-1-4-13-3 1M5 5v13h3V5H5M3 19v2h18v-2H3Z"/></svg> <span class=md-ellipsis> in <a href=../../../../category/machine-learning/ >Machine Learning</a>, <a href=../../../../category/ai/ >AI</a>, <a href=../../../../category/data-science/ >Data-science</a>, <a href=../../../../category/data/ >Data</a>, <a href=../../../../category/data-centric-ai/ >Data-Centric-AI</a>, <a href=../../../../category/t-sne/ >t-SNE</a>, <a href=../../../../category/umap/ >UMAP</a>, <a href=../../../../category/pytorch/ >PyTorch</a></span> </div> </li> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7h1.5Z"/></svg> <span class=md-ellipsis> 17 min read </span> </div> </li> </ul> </nav> </li> </ul> </nav> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#manifold-learning-algorithms-mla class=md-nav__link> <span class=md-ellipsis> Manifold learning algorithms (MLA) </span> </a> </li> <li class=md-nav__item> <a href=#neighbour-graphs class=md-nav__link> <span class=md-ellipsis> Neighbour graphs </span> </a> </li> <li class=md-nav__item> <a href=#t-distributed-stochastic-neighbor-embedding-t-sne class=md-nav__link> <span class=md-ellipsis> t-Distributed Stochastic Neighbor Embedding (t-SNE) </span> </a> </li> <li class=md-nav__item> <a href=#uniform-manifold-approximation-and-projection-umap class=md-nav__link> <span class=md-ellipsis> Uniform Manifold Approximation and Projection UMAP </span> </a> </li> <li class=md-nav__item> <a href=#comparison-table-t-sne-vs-umap class=md-nav__link> <span class=md-ellipsis> Comparison table: t-SNE vs UMAP </span> </a> </li> </ul> </nav> </div> </div> </div> <article class="md-content__inner md-typeset"> <nav class=md-tags> <a href=../../../../../tags/#blog class=md-tag>blog</a> <a href=../../../../../tags/#feature-analysis class=md-tag>feature-analysis</a> <a href=../../../../../tags/#data-science class=md-tag>data-science</a> <a href=../../../../../tags/#tsne class=md-tag>tsne</a> <a href=../../../../../tags/#umap class=md-tag>umap</a> <a href=../../../../../tags/#intermediate class=md-tag>intermediate</a> </nav> <h1 id=review-and-comparison-of-two-manifold-learning-algorithms-t-sne-and-umap>Review and comparison of two manifold learning algorithms: t-SNE and UMAP<a class=headerlink href=#review-and-comparison-of-two-manifold-learning-algorithms-t-sne-and-umap title="Permanent link">#</a></h1> <p>What are manifold learning algorithms? What is t-SNE and UMAP? What are the differences between <a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> and <a href="https://arxiv.org/abs/1802.03426">UMAP</a>? How can I explore the features of a dataset using <a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> and <a href="https://arxiv.org/abs/1802.03426">UMAP</a>? These are my notes from my recent exploration into <a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> and <a href="https://arxiv.org/abs/1802.03426">UMAP</a> and trying to apply them to a multi-label dataset to understand the abilities and limits of these algorithms. </p> <p>This post is broken down into the following sections:</p> <ul> <li><a href=#review-and-comparison-of-two-manifold-learning-algorithms-t-sne-and-umap>Review and comparison of two manifold learning algorithms: t-SNE and UMAP</a></li> <li><a href=#manifold-learning-algorithms-mla>Manifold learning algorithms (MLA)</a></li> <li><a href=#neighbour-graphs>Neighbour graphs</a></li> <li><a href=#t-distributed-stochastic-neighbor-embedding-t-sne>t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li> <li><a href=#uniform-manifold-approximation-and-projection-umap>Uniform Manifold Approximation and Projection UMAP</a></li> <li><a href=#comparison-table-t-sne-vs-umap>Comparison table: t-SNE vs UMAP</a></li> <li><a href=#exploring-dataset-with-t-sne--umap>Exploring dataset with t-SNE \&amp; UMAP</a></li> <li><a href=#simple-feature-dataset-like-mnist>Simple feature dataset like MNIST</a></li> <li><a href=#more-complex-datasets-like-cifar>More complex datasets like CIFAR</a></li> <li><a href=#what-to-do-when-there-is-noise-in-features>What to do when there is noise in features?</a></li> <li><a href=#how-to-do-this-for-multi-label>how to do this for multi-label</a></li> <li><a href=#can-we-apply-this-to-understand-what-neural-networks-are-doing>Can we apply this to understand what neural networks are doing?</a></li> <li><a href=#conclusion>Conclusion</a></li> </ul> <h2 id=manifold-learning-algorithms-mla>Manifold learning algorithms (MLA)<a class=headerlink href=#manifold-learning-algorithms-mla title="Permanent link">#</a></h2> <p>For us humans, high-dimensional data are very difficult to visualize and reason with. That's why we use dimensionality reduction techniques to reduce data dimensions so that the data is easy to work with and reason about. Manifold learning algorithms (MLA) are dimensionality reduction techniques that are sensitive to non-linear structures in data. The non-linearity is what sets manifold learning apart from other popular linear dimensionality reduction techniques like Principal Component Analysis (PCA) or Independent Component Analysis (ICA). Non-linearity allows MLAs to retain complex and interesting properties of data that would otherwise be lost in linear reduction/projection. Because of this property, MLA is a very handy algorithm to analyze data - to reduce data dimensions to 2D or 3D, and visualize and explore them to find patterns in datasets.</p> <p><a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> (t-Distributed Stochastic Neighbor Embedding) and Uniform Manifold Approximation and Projection <a href="https://arxiv.org/abs/1802.03426">UMAP</a> are the two examples of MLA, that I will cover in this post. I will compare and contrast them and provide a good intuition of how they work and how to choose one over the other.</p> <p>Note that, MLAs are tweaks and generalizations of existing linear dimensionality reduction frameworks themselves. Similar to linear dimensionality reduction techniques, MLAs are predominantly unsupervised even though supervised variants exist. The scope of this post is unsupervised techniques, however.</p> <p>So what does non-linearity buys us? The following shows the difference in reduction using PCA vs t-SNE, as shown in <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">McInnes</a> excellent talk:</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/PCA_vs_t-SNE_on_MNIST.jpg> Comparison of t-SNE and UMAP on MNIST dataset. (Image from <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">McInnes</a> talk)</p> </blockquote> <p>As we can see, PCA retains some structure. However, it is very well pronounced in t-SNE, and clusters are more clearly separated. </p> <h2 id=neighbour-graphs>Neighbour graphs<a class=headerlink href=#neighbour-graphs title="Permanent link">#</a></h2> <p><a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> and <a href="https://arxiv.org/abs/1802.03426">UMAP</a> are neighbor graph technique that models data points as nodes, with weighted edges representing the distance between the nodes. Through various optimizations and iterations, this graph and layout are tuned to best represent the data as the distance is derived from the "closeness" of the features of the data itself. This graph is then projected on reduced dimensional space a.k.a. embedded space. This is a very different technique than matrix factorization as employed by PCA, ICA for example.</p> <h2 id=t-distributed-stochastic-neighbor-embedding-t-sne>t-Distributed Stochastic Neighbor Embedding (t-SNE)<a class=headerlink href=#t-distributed-stochastic-neighbor-embedding-t-sne title="Permanent link">#</a></h2> <p><a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> uses Gaussian joint probability measures to estimate the pairwise distances between the data points in the original dimension. Similarly, the student's t-distribution is used to estimate the pairwise distances between the data points in the embedded space (i.e. lower dimension or target dimension). t-SNE then uses the gradient descent technique to minimize the divergence between the two distributions in original and embedded space using the Kullback-Leibler (KL) divergence technique.</p> <p><code>Perplexity</code> in t-SNE is effectively the number of nearest neighbors considered in producing the conditional probability measure. A larger perplexity may obscure small structures in the dataset while small perplexity will result in very localized output ignoring global information. Perplexity must be less than the size of data (number of data points) then; otherwise, we are looking at getting a blobby mass. The recommended range for perplexity lies between 5-50, with a more general rule that the larger the data, the larger the perplexity.</p> <p>Because of the use of KL divergence, t-SNE preserves the local structure in the original space, however, global structure preservation is not guaranteed. Having said that, when initialization with PCA is applied, the global structure is somewhat preserved. </p> <p>Talking more about structures, the scale of distances between points in the embedded space is not uniform in t-SNE as t-SNE uses varying distance scales. That's why it is recommended to explore data under different configurations to tease out patterns in the dataset. Learning rate and number of iterations are two additional parameters that help with refining the descent to reveal structures in the dataset in the embedded space. As highlighted in this great <a href="https://distill.pub/2016/misread-tsne/">distill</a> article on t-SNE, more than one plot may be needed to understand the structures of the dataset.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/tsne-topo.jpg> Different patterns are revealed under different t-SNE configurations, as shown by <a href="https://distill.pub/2016/misread-tsne/">distill</a> article. (Image from <a href="https://distill.pub/2016/misread-tsne/">distill</a>).</p> </blockquote> <p>t-SNE is known to be very slow with the order of complexity given by O(dN^2) where d is the number of output dimensions and N is the number of samples. Barnes-Hut variation of t-SNE improves the performance [O(dN log N)] however Barnes-Hut can only work with dense datasets and provide at most 3d embedding space. The efficiency gain in Barnes-Hut is coming from changes in gradient calculation which are done with <code>O(n log n)</code> complexity, that uses approximation techniques which leads to about 3% error in nearest neighbor calculation.</p> <p>Because of these performance implications, a common recommendation is to use PCA to reduce the dimension before applying t-SNE. This should be considered very carefully especially if the point of using t-SNE was to explore into non-linearity of the dataset. Pre-processing with linear techniques like PCA will destroy non-linear structures if present.</p> <h2 id=uniform-manifold-approximation-and-projection-umap>Uniform Manifold Approximation and Projection <a href="https://arxiv.org/abs/1802.03426">UMAP</a><a class=headerlink href=#uniform-manifold-approximation-and-projection-umap title="Permanent link">#</a></h2> <p><a href="https://arxiv.org/abs/1802.03426">UMAP</a> is based on pure combinatorial mathematics that is well covered in the <a href="https://arxiv.org/abs/1802.03426">paper</a> and is also well explained by author McInnes in his <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">talk</a> and <a href=umap_doco>library documentation</a> is pretty well written too. Similar to <a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a>, <a href="https://arxiv.org/abs/1802.03426">UMAP</a> is also a topological neighbor graph modeling technique. There are several differences b/w <a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">t-SNE</a> and <a href="https://arxiv.org/abs/1802.03426">UMAP</a> with the main one being that UMAP retains not only local but global structure in the data.</p> <p>There is a great post that goes into detail about <a href="https://pair-code.github.io/understanding-umap/index.html">how UMAP works</a>. High level, UMAP uses combinatorial topological modeling with the help of simplices to capture the data and applies Riemannian metrics to enforce the uniformity in the distribution. Fuzzy logic is also applied to the graph to adjust the probability distance if the radius grows. Once the graphs are built then optimization techniques are applied to make the embedded space graph very similar to the original space one. UMAP uses binary cross-entropy as a cost function and stochastic gradient descent to iterate on the graph for embedded space. Both t-SNE and UMAP use the same framework to achieve manifold projections however implementation details vary. <a href="https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668">Oskolkov</a>'s post covers in great detail the nuances of both the techniques and is an excellent read.</p> <p>UMAP is faster for several reasons, mainly, it uses random projection trees and nearest neighbor descent to find approximate neighbors quickly. As shown in the figure below, similar to t-SNE, UMAP also varies the distance density in the embedded space.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/umap-math.jpg> Manifold reprojection used by UMAP, as presented by <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">McInnes</a> in his talk. (Image from <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">McInnes</a> talk)</p> </blockquote> <p>Here's an example of UMAP retaining both local and global structure in embedded space:</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/umap-topo.jpg> Example of UMAP reprojecting a point-cloud mammoth structure on 2-D space. (Image provided by the author, produced using tool <a href="https://pair-code.github.io/understanding-umap/index.html">1</a>)</p> </blockquote> <p>Here's a side-by-side comparison of t-SNE and UMAP on reducing the dimensionality of a mammoth. As shown, UMAP retains the global structure but it's not that well retained by t-SNE. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/tsne-vs-umap.jpg> Side by side comparison of t-SNE and UMAP projections of the mammoth data used in the previous figure. (Image provided by the author, produced using tool <a href="https://pair-code.github.io/understanding-umap/index.html">1</a>) </p> </blockquote> <p>The explanation for this difference lies in the loss function. As shown in the following figure, UMAP uses binary cross-entropy that penalizes both local (clumps) and global (gaps) structures. In t-SNE however, due to KL Divergence as the choice of the cost function, the focus remains on getting the clumps i.e. local structure right.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/ce-umap.jpg> Cots function used in UMAP as discussed in <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">McInnes</a> talk. (Image from <a href="https://www.youtube.com/watch?v=nq6iPZVUxZU">McInnes</a> talk)</p> </blockquote> <p>The first part of the equation is the same in both t-SNE (coming from KL divergence) and UMAP. UMAP only has the second part that contributes to getting the gaps right i.e. getting the global structure right.</p> <h2 id=comparison-table-t-sne-vs-umap>Comparison table: t-SNE vs UMAP<a class=headerlink href=#comparison-table-t-sne-vs-umap title="Permanent link">#</a></h2> <table> <thead> <tr> <th>Characteristics</th> <th>t-SNE</th> <th>UMAP</th> </tr> </thead> <tbody> <tr> <td>Computational complexity</td> <td>O(dN^2) <br>(Barnes-Hut with O(dN log N) )</td> <td>O(d*n^1.14) <br>(<a href="https://github.com/lmcinnes/umap/issues/8">emprical-estimates</a> O(dN log N))</td> </tr> <tr> <td>Local structure preservation</td> <td>Y</td> <td>Y</td> </tr> <tr> <td>Global structure preservation</td> <td>N <br>(somewhat when <code>init=PCA</code>)</td> <td>Y</td> </tr> <tr> <td></td> <td></td> <td></td> </tr> <tr> <td>Cost Function</td> <td>KL Divergence</td> <td>Cross Entropy</td> </tr> <tr> <td>Initialization</td> <td>Random <br> (PCA as alternate)</td> <td>Graph Laplacian</td> </tr> <tr> <td>Optimization algorithm</td> <td>Gradient Descent (GD)</td> <td>Stochastic Gradient Descent (SGD)</td> </tr> <tr> <td>Distribution for modelling distance probabilities</td> <td>Student's t-distribution</td> <td>family of curves (1+a*y<sup>(2b))</sup>-1</td> </tr> <tr> <td>Nearest neighbors hyperparameter</td> <td>2^Shannon entropy</td> <td>nearest neighbor k</td> </tr> </tbody> </table> <h1 id=exploring-dataset-with-t-sne-umap>Exploring dataset with t-SNE &amp; UMAP<a class=headerlink href=#exploring-dataset-with-t-sne-umap title="Permanent link">#</a></h1> <p>Now that we have covered theoretical differences, let's apply these techniques to a few datasets and do a few side-by-side comparisons between t-SNE and UMAP.</p> <p>Source code and other content used in this exercise are available in this git repository - <a href="https://github.com/suneeta-mall/feature_analysis">feature_analysis</a>. The notebook for MNIST analysis is available <a href="https://github.com/suneeta-mall/feature_analysis/blob/master/docs/MNIST_TSNE_vs_UMAP.ipynb">here</a>. Likewise, the notebook for CIFAR analysis is available <a href="https://github.com/suneeta-mall/feature_analysis/blob/master/docs/CIFAR10_TSNE_vs_UMAP.ipynb">here</a>.</p> <h2 id=simple-feature-dataset-like-mnist>Simple feature dataset like MNIST<a class=headerlink href=#simple-feature-dataset-like-mnist title="Permanent link">#</a></h2> <p>The following figure reprojects MNIST image features on the 2D embedded space under different perplexity settings. As shown, increasing the perplexity, makes the local clusters very packed together. In this case, PCA based initialization technique was chosen because I want to retain the global structure as much as possible. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/mnist_t-sne_dif_perplex.jpg> Reprojection of MNIST image features on the 2D embedded space using t-SNE under different perplexity settings. (Image provided by author)</p> </blockquote> <p>It's quite interesting to see that the digits that are packed close together are: 1. 7,9,4 2. 3,5,8 3. 6 &amp; 0 4. 1 &amp; 2 5. That 6 is more close to 5 than 1 6. Likewise 7 is closer to 1 than 0.</p> <p>At a high level this co-relation makes sense, the features of the digits that are quite similar are more closely packed than digitals that are very different. Its also, interesting to note that 8 and 9 have anomalies that map closely to 0 in rare cases in embedded space. So what's going on? Following image overlays randomly selected images on the clusters produced by t-SNE @ perplexity of 50.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/mnist_tsne_with_img.jpg> Reprojection of MNIST image features on the 2D embedded space using t-SNE @ perplexity=50 with randomly selected image overlay. (Image provided by author)</p> </blockquote> <p>As we pan around this image, we can see a distinct shift in the characteristics of the digits. For example, the 2 digits at the top are very cursive and have a round little circle at the joint of the two whereas as we travel to the lower part of the cluster of 2s, we can see how sharply written the bottom 2s are. The bottom 2s features are sharp angular joints. Likewise, the top part of the cluster of 1s is quite slanty whereas the bottom 1s are upright. </p> <p>It's quite interesting to see that the 8's occasionally clustered together with 0's are quite round in the middle and do not have the sharp joint in the middle. </p> <p>So, what does MNIST data look like with UMAP? UMAP's embedded space also reflects the same grouping as discussed above. In fact, UMAP and t-SNE clustering in terms of digits grouping are very much alike. It appears to me that UMAP and t-SNE are mirror reflections when it comes to how digits are grouped. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/umap_mnist.jpg> Reprojection of MNIST image features on the 2D embedded space using UMAP. (Image provided by author)</p> </blockquote> <p>It's also very interesting to note how similar-looking 1s are that are reprojected to the same coordinates in the embedded space.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/ones_umap.jpg> One example of samples that get reprojected to the same coordinates in the embedded space using UMAP. (Image provided by author)</p> </blockquote> <p>Not all the data points that collide in embedded space will look exactly similar, the similarity is more in the reduced dimensional space. One such example is shown below. Here 1 and 0 are reprojected to the same coordinates. As we can see the strokes on the left side of 0 are very similar to strokes of 1. The circle of zero is not quite complete either. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/one-vs-zero.jpg> One example of two different digits getting reprojected to the same coordinates in the embedded space using UMAP. (Image provided by author)</p> </blockquote> <p>Here's also an example of samples falling into the same neighborhood in the embedded space that look quite distinct despite sharing some commonality (the strokes around the mouth of 4 and incomplete 8s)! </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/umap_odd_case.jpg> Example of 4 and 8s reprojected to the nearby coordinates in the embedded space using UMAP. (Image provided by author)</p> </blockquote> <p>Its unpredictable what tangible features have been leveraged to calculate the similarities amongst data points in the embedded space. This is because the main focus of MLAs has been distance measures and the embedded space is derived based on best effort using unsupervised techniques with evident data loss (due to dimensionality reduction). </p> <p>This was MNIST, where digits are captured with empty backgrounds. These are very easy cases because all the signals in the feature vectors are true signals that correspond to the digit as its drawn. When we start talking about visualizing data where there are noises in the signals then that case poses certain challenges. For example, taking the case of <a href="https://www.cs.toronto.edu/~kriz/cifar.html">cifar</a> dataset, the images of things are captured with a varying background as they are all-natural images unlike MNIST with a black background. In the following section, let's have a look at what happens when we apply t-SNE and UMA to the CIFAR dataset.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/CIFAR10-vs-MNIST.jpg> High-level differences between <a href="https://www.cs.toronto.edu/~kriz/cifar.html">cifar</a> and MNIST dataset. (Image provided by author)</p> </blockquote> <h2 id=more-complex-datasets-like-cifar>More complex datasets like CIFAR<a class=headerlink href=#more-complex-datasets-like-cifar title="Permanent link">#</a></h2> <p>The following figure shows the resultant embedding of CIFAR images after applying UMAP. As shown below results are less than impressive to delineate amongst CIFAR classes or perform any sort of features analysis. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/cifar-10-tsne.jpg> Results of CIFAR image feature visualization using t-SNE under different perplexity settings. (Image provided by author)</p> </blockquote> <p>So, what's going on? Let's overlay the images and see if we can find some patterns and make sense of the one big lump we are seeing. The following figure overlays the image. It's really hard to find a consistent similarity between neighboring points. Often we see cars and vehicles nearby but not consistently. They are intermixed with flowers and other classes. It's simply too much noise in the feature vector to do any meaningful convergence. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/cifar-10-t-sne-with-images.jpg> Results of CIFAR image feature visualization using t-SNE. Shows images in an overlay on randomly selected points. (Image provided by author)</p> </blockquote> <p>In the above two figures, we looked at analyzing CIFAR with t-SNE. The following plot is produced by using UMAP. As we can see it's not convincing either. Much like t-SNE, UMAP is also providing one big lump and no meaningful insights. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/cifar-umap.jpg> Results of CIFAR image feature visualization using UMAP. (Image provided by author)</p> </blockquote> <p>Following show images of 2 cats that are projected to the same location in embedded space. There is some similarity between the two images like nose, and sharp ears obviously but also the two images have varying distinct features.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/cifar-umap-collison.jpg> Results of CIFAR image feature visualization using UMAP showing samples of cats that are reprojected into the same located in the embedded space. (Image provided by author)</p> </blockquote> <p>Likewise, if we look at the following figure where deer and frog are co-located in embedded space, we can see the image texture is very similar. This texture however is the result of normalization and grayscale conversion. As we can see, a lot goes on in nature scenes and without a clear understanding of which features to focus on, one's features can be other's noise. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/umap_frog_deer.jpg> Results of CIFAR image feature visualization using UMAP. Shows images in an overlay on randomly selected points. (Image provided by author)</p> </blockquote> <p>t-SNE and UMAP are feature visualization techniques and perform best when the data vector represents the feature sans noise. </p> <h2 id=what-to-do-when-there-is-noise-in-features>What to do when there is noise in features?<a class=headerlink href=#what-to-do-when-there-is-noise-in-features title="Permanent link">#</a></h2> <p>So, what can we do if there are noises in our feature vectors? We can apply techniques that reduce noises from feature vectors before applying manifold learning algorithms. Given the emphasis on nonlinearity in both t-SNE and UMAP (to preserve nonlinear features), it is better to choose a noise reduction technique that is nonlinear. </p> <p><a href="https://www.deeplearningbook.org/contents/autoencoders.html">Autoencoder</a> is a class of unsupervised deep learning techniques that learns the latent representation of the input dataset eliminating noises. Autoencoder can be non-linear depending on the choices of layers in the network. For example, using a convolution layer will allow for non-linearity. If noises are present in the feature vector then an autoencoder can be applied to learn latent features of a dataset and to transform samples to noise-free samples before applying manifold algorithms. <a href="https://arxiv.org/abs/1802.03426">UMAP</a> has native integration with Tensorflow for similar use cases that is surfaced as <a href="https://umap-learn.readthedocs.io/en/latest/parametric_umap.html">parametric UMAP</a>. Why parametric because autoencoders/neural networks are parametric! i.e. increasing data size will not increase parameters - the parameters may be large but will be fixed and limited. This approach of transforming input feature vectors to the latest representation not only helps with noise reduction but also with complex and very high dimensional feature vectors. </p> <p>The following figure shows the results of applying autoencoder before performing manifold algorithm t-SNE and UMAP for feature visualization. As we can see in the result, the clumps are much more compact and the gaps are wider. The proximity of MNIST classes remains unchanged, however - which is very nice to see.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/umap_tsne-parametric_umap.jpg> Results of applying autoencoder on MNIST before applying manifold algorithm t-SNE and UMAP. (Image provided by author)</p> </blockquote> <p>So how does it affects the features that contribute to proximities/neighborhood of data? The manifold algorithm is still the same however it's now applying on latent feature vector as produced by autoencoders and not raw features. So effectively, the proximity factor is now calculated on latent representation and not directly on perceptible features. Given the digit clusters are still holding global structure and it's just more packed together within the classes, we can get the sense that it's doing the right things if intra-class clumps can be explained. Let's look at some examples. The following shows a reprojection in the embedded space where 4,9 and 1 are clustered together into larger clusters of 1s. If we look closely the backbone of all these numbers is slanting at about 45 degrees and perhaps that has been the main driving factor. The protruding belly of 4 and 9 are largely ignored but also they are not very prominent. </p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/MNIST-Parametric-UMAP.jpg> Example of co-located 1s, 4 &amp; 9 in embedded space obtained by applying Paramertic UMAP on MNIST. (Image provided by author)</p> </blockquote> <p>More importantly, looking at the dataset (in the following figure), there are not as many 9s or 4s that have a backbone at that steep slant of 45 degrees. This is more easily shown in the full-scale overlay in the following figure (sparsely chosen images to show to make it more comprehensible). We can see all samples are upright 4s and 9s where there is a slant the protrusion is more prominent. Anyhow, we don't need to get overboard with this as manifold algorithms are not feature detection algorithms and certainly can't be compared to the likes of more powerful feature extraction techniques like convolution. The goal with manifold is to find global and local structures in the dataset. These algorithms work best if signals in datasets are noise-free where noise includes features/characteristics we want ignored in the analysis. A rich natural background is a very good case of noise as shown already in the CIFAR case.</p> <blockquote> <p><img alt src=../../../../../resources/feature-analysis/overlay_on_t-SNE_parametric.jpg> Images overlaid on t-SNE of auto-encoded features derived from MNIST dataset. (Image provided by author)</p> </blockquote> <h2 id=how-to-do-this-for-multi-label>how to do this for multi-label<a class=headerlink href=#how-to-do-this-for-multi-label title="Permanent link">#</a></h2> <p>In the early day of learning about this, I found myself wondering how would we do the feature analysis on a multi-label dataset? Multi-class is certainly the easy case - each sample only needs to be color-coded for one class so is easy to visualize. We are also expecting class-specific data to be clumped together mostly (perhaps not always and depends on intent but may be more commonly).</p> <p>If multi-label data consists of exclusive classes similar to <a href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html">Satnford Cars Dataset</a> where options within the make and the models of cars are mutually exclusive, then splitting the visualization to the group of exclusive cases could be very helpful. </p> <p>However, if the multi-label dataset is more alike <a href="https://paperswithcode.com/dataset/mlrsnet">MLRSNet</a> where classes are independent then it's best to first analyze the data class agnostic and explore if there are any patterns in features and proceed based on this.</p> <h1 id=can-we-apply-this-to-understand-what-neural-networks-are-doing>Can we apply this to understand what neural networks are doing?<a class=headerlink href=#can-we-apply-this-to-understand-what-neural-networks-are-doing title="Permanent link">#</a></h1> <p>A lot of work has been done in the area of explainability and feature understanding that is very well documented in <a href="https://distill.pub/2019/activation-atlas/">distill</a> blogs. The underlined idea is that we can take the activation of the layers of the neural network and explore what features it is that that particular layer is paying attention to. The activations are essentially the signal that is fired for a given input to the layer. These signals then formulate the feature vector for further analysis to understand where and what the layer is paying more attention to. T-SNE and UMAP are heavily used in these analyses. </p> <p>The <a href="https://distill.pub/2019/activation-atlas/">distill</a> blogs are very well documented and highly recommended for reading if this is something that is of interest to you.</p> <h2 id=conclusion>Conclusion<a class=headerlink href=#conclusion title="Permanent link">#</a></h2> <p>This post was focused on the fundamentals of manifold learning algorithms, and diving into the details of t-SNE and UMAP. This post also compared and contrasted t-SNE and UMAP and presented some analysis of MNIST and CIFAR datasets. We also covered what to do if we have a very high dimensional dataset and also if we have noises in the dataset. Lastly, we touched on what to do if your dataset is multi-label. </p> <p>In the follow-up, I will cover how we can utilize t-SNE and UMAP to better understand what neural networks are doing and apply it in conjunction with convolutions as feature extractors. </p> <p>[umap_doco] https://umap-learn.readthedocs.io/en/latest/how_umap_works.html</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="May 11, 2025 02:20:20">May 11, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="May 11, 2025 02:20:20">May 11, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../../05/16/confident-learning-and-clean-data/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Confident Learning and Clean Data"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Confident Learning and Clean Data </div> </div> </a> <a href=../../../../2023/11/12/launch-of-curious-cassies-beach-ride-quest/ class="md-footer__link md-footer__link--next" aria-label="Next: Launch of Curious Cassie's Beach Ride Quest"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Launch of Curious Cassie's Beach Ride Quest </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> </div> <div class=md-social> <a href="https://www.linkedin.com/in/suneeta-mall-a6a0507/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href="https://github.com/suneeta-mall" target="_blank" rel="noopener" title="github.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href="https://x.com/suneetamall/" target="_blank" rel="noopener" title="x.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9L389.2 48zm-24.8 373.8h39.1L151.1 88h-42l255.3 333.8z"/></svg> </a> <a href="https://www.medium.com/@suneetamall" target="_blank" rel="noopener" title="www.medium.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M180.5 74.262C80.813 74.262 0 155.633 0 256s80.819 181.738 180.5 181.738S361 356.373 361 256 280.191 74.262 180.5 74.262Zm288.25 10.646c-49.845 0-90.245 76.619-90.245 171.095s40.406 171.1 90.251 171.1 90.251-76.619 90.251-171.1H559c0-94.503-40.4-171.095-90.248-171.095Zm139.506 17.821c-17.526 0-31.735 68.628-31.735 153.274s14.2 153.274 31.735 153.274S640 340.631 640 256c0-84.649-14.215-153.271-31.742-153.271Z"/></svg> </a> <a href="https://scholar.google.com.au/citations?hl=en&amp;user=WD712CUAAAAJ" target="_blank" rel="noopener" title="scholar.google.com.au" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M390.9 298.5s0 .1.1.1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64 1.7-3.6 3.6-7.2 5.6-10.7 4.4-7.6 9.4-14.7 15-21.3 27.4-32.6 68.5-53.3 114.4-53.3 33.6 0 64.6 11.1 89.6 29.9 9.1 6.9 17.4 14.7 24.8 23.5 5.6 6.6 10.6 13.8 15 21.3 2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0l256 202.7-94.7 77.1z"/></svg> </a> <a href="https://www.researchgate.net/profile/Suneeta_Mall3" target="_blank" rel="noopener" title="www.researchgate.net" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 32v448h448V32H0zm262.2 334.4c-6.6 3-33.2 6-50-14.2-9.2-10.6-25.3-33.3-42.2-63.6-8.9 0-14.7 0-21.4-.6v46.4c0 23.5 6 21.2 25.8 23.9v8.1c-6.9-.3-23.1-.8-35.6-.8-13.1 0-26.1.6-33.6.8v-8.1c15.5-2.9 22-1.3 22-23.9V225c0-22.6-6.4-21-22-23.9V193c25.8 1 53.1-.6 70.9-.6 31.7 0 55.9 14.4 55.9 45.6 0 21.1-16.7 42.2-39.2 47.5 13.6 24.2 30 45.6 42.2 58.9 7.2 7.8 17.2 14.7 27.2 14.7v7.3zm22.9-135c-23.3 0-32.2-15.7-32.2-32.2V167c0-12.2 8.8-30.4 34-30.4s30.4 17.9 30.4 17.9l-10.7 7.2s-5.5-12.5-19.7-12.5c-7.9 0-19.7 7.3-19.7 19.7v26.8c0 13.4 6.6 23.3 17.9 23.3 14.1 0 21.5-10.9 21.5-26.8h-17.9v-10.7h30.4c0 20.5 4.7 49.9-34 49.9zm-116.5 44.7c-9.4 0-13.6-.3-20-.8v-69.7c6.4-.6 15-.6 22.5-.6 23.3 0 37.2 12.2 37.2 34.5 0 21.9-15 36.6-39.7 36.6z"/></svg> </a> <a href="https://suneeta-mall.github.io/feed_rss_created.xml" target="_blank" rel="noopener" title="suneeta-mall.github.io" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 64c0-17.7 14.3-32 32-32 229.8 0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7 0 64zm0 352a64 64 0 1 1 128 0 64 64 0 1 1-128 0zm32-256c159.1 0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7 0-32-14.3-32-32s14.3-32 32-32z"/></svg> </a> <a href=mailto:suneetamall@gmail.com target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l217.6 163.2c11.4 8.5 27 8.5 38.4 0l217.6-163.2c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48H48zM0 176v208c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V176L294.4 339.2a63.9 63.9 0 0 1-76.8 0L0 176z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "content.tabs.link", "navigation.indexes", "navigation.instant", "navigation.instant.preview", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "toc.follow", "header.autohide", "announce.dismiss", "navigation.footer", "navigation.breadcrumbs", "navigation.expand", "navigation.sections", "navigation.tracking", "navigation.top", "search.highlight", "search.share", "toc.follow", "toc.integrate", {"git-revision-date-localized": {"enable_creation_date": true, "type": "date"}}], "search": "../../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../../../../assets/javascripts/bundle.3220b9d7.min.js></script> </body> </html>