<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href="https://suneeta-mall.github.io/blog/category/confident-learning/" rel="canonical"><link href=../childrens-books/ rel=prev><link href=../curious-cassie/ rel=next><link rel=alternate type=application/rss+xml title="RSS feed" href=../../../feed_rss_created.xml><link rel=alternate type=application/rss+xml title="RSS feed of updated content" href=../../../feed_rss_updated.xml><link rel=icon href=../../../resources/site/favicon.svg><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.18"><title>Confident-Learning - Random Musings - Rambling of a curious engineer & data scientist!</title><link rel=stylesheet href=../../../assets/stylesheets/main.66ac8b77.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel="stylesheet" href="../../../assets/external/fonts.googleapis.com/css.49ea35f2.css"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><meta property=og:type content=website><meta property=og:title content="Confident-Learning - Random Musings - Rambling of a curious engineer & data scientist!"><meta property=og:description content=None><meta property=og:image content=https://suneeta-mall.github.io/assets/images/social/blog/category/confident-learning.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://suneeta-mall.github.io/blog/category/confident-learning/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Confident-Learning - Random Musings - Rambling of a curious engineer & data scientist!"><meta name=twitter:description content=None><meta name=twitter:image content=https://suneeta-mall.github.io/assets/images/social/blog/category/confident-learning.png></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#confident-learning class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> <a href=/projects/oreilly_deep_learning_at_scale/ > <strong>ðŸŽ‰ New Book Release!</strong> Check out "Deep Learning at Scale" - An O'Reilly Book </a> </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href="https://suneeta-mall.github.io/" title="Random Musings - Rambling of a curious engineer &amp; data scientist!" class="md-header__button md-logo" aria-label="Random Musings - Rambling of a curious engineer &amp; data scientist!" data-md-component="logo"> <img src=../../../resources/site/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Random Musings - Rambling of a curious engineer & data scientist! </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Confident-Learning </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 1 3 3 3 3 0 0 1-3 3 3 3 0 0 1-3-3 3 3 0 0 1 3-3m0-4.5c5 0 9.27 3.11 11 7.5-1.73 4.39-6 7.5-11 7.5S2.73 16.39 1 12c1.73-4.39 6-7.5 11-7.5M3.18 12a9.821 9.821 0 0 0 17.64 0 9.821 9.821 0 0 0-17.64 0Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../projects/oreilly_deep_learning_at_scale/ class=md-tabs__link> Projects </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Blog </a> </li> <li class=md-tabs__item> <a href=../../../tags/ class=md-tabs__link> Tags </a> </li> <li class=md-tabs__item> <a href=../../../talks/KGC_NY_2022/ class=md-tabs__link> Talks </a> </li> <li class=md-tabs__item> <a href=../../../poems/singularity/ class=md-tabs__link> Poems </a> </li> <li class=md-tabs__item> <a href=../../../about/ class=md-tabs__link> About Me </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href="https://suneeta-mall.github.io/" title="Random Musings - Rambling of a curious engineer &amp; data scientist!" class="md-nav__button md-logo" aria-label="Random Musings - Rambling of a curious engineer &amp; data scientist!" data-md-component="logo"> <img src=../../../resources/site/logo.svg alt=logo> </a> Random Musings - Rambling of a curious engineer & data scientist! </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../projects/oreilly_deep_learning_at_scale/ class=md-nav__link> <span class=md-ellipsis> Deep Learning at Scale </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/curious_cassie/ class=md-nav__link> <span class=md-ellipsis> Curious Cassie - The Children's Books </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/feature_analysis/ class=md-nav__link> <span class=md-ellipsis> Label Noise with Clean Lab </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/feature_analysis/ class=md-nav__link> <span class=md-ellipsis> Feature Analysis </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/oreilly-interactive-katacode-series-for-reproducible-ml/ class=md-nav__link> <span class=md-ellipsis> Oreilly Katacode Series </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/reproducible-ml/ class=md-nav__link> <span class=md-ellipsis> Reproducible-ML </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/KCD/ class=md-nav__link> <span class=md-ellipsis> KCD </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../archive/2025/ class=md-nav__link> <span class=md-ellipsis> 2025 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2022/ class=md-nav__link> <span class=md-ellipsis> 2022 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2021/ class=md-nav__link> <span class=md-ellipsis> 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2019/ class=md-nav__link> <span class=md-ellipsis> 2019 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3 checked> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ai/ class=md-nav__link> <span class=md-ellipsis> AI </span> </a> </li> <li class=md-nav__item> <a href=../book/ class=md-nav__link> <span class=md-ellipsis> Book </span> </a> </li> <li class=md-nav__item> <a href=../childrens-books/ class=md-nav__link> <span class=md-ellipsis> Children's Books </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Confident-Learning </span> </a> </li> <li class=md-nav__item> <a href=../curious-cassie/ class=md-nav__link> <span class=md-ellipsis> Curious Cassie </span> </a> </li> <li class=md-nav__item> <a href=../data/ class=md-nav__link> <span class=md-ellipsis> Data </span> </a> </li> <li class=md-nav__item> <a href=../data-centric-ai/ class=md-nav__link> <span class=md-ellipsis> Data-Centric-AI </span> </a> </li> <li class=md-nav__item> <a href=../data-science/ class=md-nav__link> <span class=md-ellipsis> Data-science </span> </a> </li> <li class=md-nav__item> <a href=../deep-learning/ class=md-nav__link> <span class=md-ellipsis> Deep Learning </span> </a> </li> <li class=md-nav__item> <a href=../generative-ai/ class=md-nav__link> <span class=md-ellipsis> Generative AI </span> </a> </li> <li class=md-nav__item> <a href=../kubernetes/ class=md-nav__link> <span class=md-ellipsis> Kubernetes </span> </a> </li> <li class=md-nav__item> <a href=../llm/ class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> <li class=md-nav__item> <a href=../machine-learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../oom/ class=md-nav__link> <span class=md-ellipsis> OOM </span> </a> </li> <li class=md-nav__item> <a href=../pytorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../reproducible-ml/ class=md-nav__link> <span class=md-ellipsis> Reproducible-ml </span> </a> </li> <li class=md-nav__item> <a href=../software/ class=md-nav__link> <span class=md-ellipsis> Software </span> </a> </li> <li class=md-nav__item> <a href=../technology/ class=md-nav__link> <span class=md-ellipsis> Technology </span> </a> </li> <li class=md-nav__item> <a href=../umap/ class=md-nav__link> <span class=md-ellipsis> UMAP </span> </a> </li> <li class=md-nav__item> <a href=../t-sne/ class=md-nav__link> <span class=md-ellipsis> t-SNE </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Talks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Talks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../talks/KGC_NY_2022/ class=md-nav__link> <span class=md-ellipsis> Knowledge Graph Conference 2022 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/KubeCon_NA_2021/ class=md-nav__link> <span class=md-ellipsis> KubeCon NA 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/Kafka_Summit_APAC_2021/ class=md-nav__link> <span class=md-ellipsis> Kafka Summit APAC 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/AWS_ANZ_Commuity_day_2020/ class=md-nav__link> <span class=md-ellipsis> AWS Community Day 2020 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/She_Builds_on_AWS_2020/ class=md-nav__link> <span class=md-ellipsis> AWS She Builds on AWS 2020 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/KubeCon_US_2019/ class=md-nav__link> <span class=md-ellipsis> KubeCon US 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/KubernetesSydneyForum_AU_2019/ class=md-nav__link> <span class=md-ellipsis> Kubernetes Sydney 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/YOW_Data_Syd_2019/ class=md-nav__link> <span class=md-ellipsis> YOW Data 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/KubeCon-Europe-2018/ class=md-nav__link> <span class=md-ellipsis> KubeCon EU 2018 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/SPIE-2019/ class=md-nav__link> <span class=md-ellipsis> SPIE 2019 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/SPIE-2018/ class=md-nav__link> <span class=md-ellipsis> SPIE 2018 </span> </a> </li> <li class=md-nav__item> <a href=../../../talks/SPIE-2015/ class=md-nav__link> <span class=md-ellipsis> SPIE 2015 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Poems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Poems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../poems/singularity/ class=md-nav__link> <span class=md-ellipsis> Singularity </span> </a> </li> <li class=md-nav__item> <a href=../../../poems/life-of-ai-engineer/ class=md-nav__link> <span class=md-ellipsis> Life of AI Engineers </span> </a> </li> <li class=md-nav__item> <a href=../../../poems/my-little-butterfly/ class=md-nav__link> <span class=md-ellipsis> My little Butterfly </span> </a> </li> <li class=md-nav__item> <a href=../../../poems/breaking-thy-bias/ class=md-nav__link> <span class=md-ellipsis> Breaking Thy Bias </span> </a> </li> <li class=md-nav__item> <a href=../../../poems/daminis/ class=md-nav__link> <span class=md-ellipsis> Daminis </span> </a> </li> <li class=md-nav__item> <a href=../../../poems/one-bright-dawn/ class=md-nav__link> <span class=md-ellipsis> One Bright Dawn </span> </a> </li> <li class=md-nav__item> <a href=../../../poems/aint-no-dr-seuss/ class=md-nav__link> <span class=md-ellipsis> Aint no Dr. Seuss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../about/ class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <div class=md-content__inner> <header class=md-typeset> <h1 id=confident-learning>Confident-Learning<a class=headerlink href=#confident-learning title="Permanent link">#</a></h1> </header> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=/resources/me.png alt="Suneeta Mall"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2022-05-16 00:00:00">May 16, 2022</time></li> <li class=md-meta__item> in <a href=../machine-learning/ class=md-meta__link>Machine Learning</a>, <a href=../ai/ class=md-meta__link>AI</a>, <a href=../deep-learning/ class=md-meta__link>Deep Learning</a>, <a href=../data/ class=md-meta__link>Data</a>, <a href=../data-centric-ai/ class=md-meta__link>Data-Centric-AI</a></li> <li class=md-meta__item> 16 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=confident-learning-label-errors-are-imperative-so-what-can-you-do><a href=../../2022/05/16/confident-learning-and-clean-data/ class=toclink>Confident Learning: Label errors are imperative! So what can you do?</a></h2> <p>What makes deep-learning so great, despite what you may have heard, is data! There is an old saying, that sums it up pretty well:</p> <blockquote> <p>The model is only as good as the <span style=color:red>data</span>! <br></p> </blockquote> <p>Which brings us to the real question, exactly how good is your data? Collecting ground truth/training datasets is incredibly expensive, laborious, and time-consuming. The process of labeling involves searching for the object of interest and applying prior knowledge and heuristics to come to a final decision. A decision to represent if the object (of interest) is present and if so, annotate it to provide extra information like bounding box, and segmentation mask. </p> <p>There are several factors at play in this process that leads to error in the dataset. The question is what can we do about it? In this post, I will touch on some of the reasons why labeling error occurs, why the errors in labels are imperative, and what are the tools and techniques one can use to manage errors in the label datasets. Then, I will dive into theÂ detail of <a href="https://arxiv.org/abs/1911.00068">confident learning</a>. I will also demonstrate the use of <a href="https://github.com/cleanlab/cleanlab">cleanlab</a>, a <a href="https://arxiv.org/abs/1911.00068">confident learning</a> implementation [1], to easily find noise inÂ the data.</p> <p><strong>Disclaimer</strong>: Before diving into the details, I would like to acknowledge that, at the time of writing this post, I am not affiliated with or sponsored by <a href="https://github.com/cleanlab/cleanlab">cleanlab</a> in any capacity.</p> <p>This post is broken down into the following sections:</p> <ul> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#confident-learning-label-errors-are-imperative-so-what-can-you-do>Confident Learning: Label errors are imperative! So what can you do?</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#reasons-for-labeling-errors>Reasons for labeling errors</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#labeling-efficiency-tricks-that-increase-the-risk-of-labeling-errors>Labeling efficiency tricks that increase the risk of labeling errors</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#errors-in-labels-are-imperative>Errors in labels are imperative</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#exactly-what-is-confident-learning>Exactly, what is Confident learning?</a><ul> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#fundamentals>Fundamentals</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#limitations-of-cl>Limitations of CL</a></li> </ul> </li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#hands-on-of-label-noise-analysis-using-cleanlab-for-multi-label-classification>Hands on of label noise analysis using cleanlab for multi-label classification</a><ul> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#model-info>Model info</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#exploration-in-noise-using-cleanlab>Exploration in noise using cleanlab</a></li> </ul> </li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#conclusion>Conclusion</a></li> <li><a href=../../2022/05/16/confident-learning-and-clean-data/#references>References</a></li> </ul> <h3 id=reasons-for-labeling-errors><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#reasons-for-labeling-errors>Reasons for labeling errors</a></h3> <p>Let's first look at some of the reasons why errors in the labels may be present. One broad class for such errors is tooling/software bugs. These can be controlled and managed using good software best practices like tests covering both software and the data. The other class of errors is the one where the mistakes are coming from the labelers themselves. These are incredibly harder issues to track. Because labelers are the oracle in this process of deep learning after all! If we don't trust them, then who do we trust?</p> <p>There is a very interesting work by <a href="https://www.researchgate.net/publication/225041737_Automated_detection_of_heuristics_and_biases_among_pathologists_in_a_computer-based_system">Rebecca Crowley</a> where she provides a detailed chart of a range of reasons why an object (of interest) may be missed while searching in a scene or also why a wrong final decision may be made by them [4]. Some directly impacting labeling in my view are:</p> <ol> <li><strong>Search Satisficing</strong>: The tendency to call off a search once something has been found, leading to premature stopping, thus increasing the chance of missing annotations[4]. This more applies to scenarios where more than one annotation is needed. For example, multi-label or segmentation annotation (dog and pen are in the image but the labeler only annotates for the dog and does not spend enough time to spot the pen and capture in labels).</li> <li><strong>Overconfidence &amp; Under-confidence</strong>: This type of labeling error relates to one's feeling-of-knowing [4] that is over or underestimated.</li> <li><strong>Availability</strong>: There is an implicit bias in annotating it wrongly if something is frequently occurring or rarely occurring [4]. It is particularly true for challenging labeling tasks. For instance, if the cancer prevalence rate in a location is 0.01%, then the labeler, when labeling a not-so-straightforward case, is more likely to mark a non-cancer than cancer.</li> <li><strong>Anchoring/Confirmation bias</strong>: When a labeler makes a pre-emptive decision [4] about a labeling task outcome and then looks for information to support that decision. For example, believing they are looking at a cancerous case, they start to search for abnormality in the image to support the finding that this case is cancer. In this unfair search/decision process, they are more likely to make mistakes.</li> <li><strong>Gambler's Fallacy</strong>: When they are encountered with a repeated pattern of similar cases, then they are likely to deviate and favor an outcome that breaks that pattern [4].</li> <li>Amongst all these, <strong>Cognitive Overload</strong> is also a valid and fair reason for errors in labels.</li> </ol> <h3 id=labeling-efficiency-tricks-that-increase-the-risk-of-labeling-errors><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#labeling-efficiency-tricks-that-increase-the-risk-of-labeling-errors>Labeling efficiency tricks that increase the risk of labeling errors</a></h3> <p>Given the process to procure a labeling dataset is expensive, some clever tricks and techniques are occasionally applied to optimize the labeling funnel. While some focus on optimization through labeling experience such as <a href="https://arxiv.org/abs/1903.06874">Fast Interactive Object Annotation</a><sup>[5]</sup>, other techniques focus on using auto-labeling techniques to reduce the labeling burden a bit to aid the labelers. Tesla has a very powerful mechanism to realize auto-labeling at scale as talked about in the <a href="https://www.youtube.com/watch?v=a510m7s_SVI">2021 CVPR by Karpathy</a>. They sure have the advantage of having feedback (not just the event that's worth labeling but also what did the driver do or if that led to a mishap). It's an advantage that not all deep-learning practicing organizations have! Impressive nonetheless! Then we also have the weakly supervised class of training regimes that I won't go into detail about (perhaps a topic for another day)!</p> <p>The thing is, the cleverer tricks you employ to optimize this process, the higher the chances of error in your dataset. For instance, using the model in the loop for labeling is being increasingly used to optimize the labeling process (<a href="https://suneeta-mall.github.io/talks/She_Builds_on_AWS_2020.html">as detailed in this presentation</a>), as an auto-labeling/pre-label trick, wherein predicted labels are shown to the labelers and the labeler only fine-tunes the annotation instead of annotating from the get-go. This process has two main challenges:</p> <p>a) It may introduce a whole gamut of bias in labels <a href="../../2022/05/16/confident-learning-and-clean-data/# reasons-for-labeling-errors">as discussed above in (Reasons for labeling errors</a>.</p> <p>b) If the model is not on par with human labelers, the labor, and boredom of correcting a garbage prior label increase the risk of errors in the dataset. This is a classic case of cognitive overload.</p> <p>If this example was not enough, let's take a case of auto labeling <a href="https://suneeta-mall.github.io/talks/KGC_NY_2022.html">using ontology/knowledge graph</a>. Here, the risk of error propagation is too high if the knowledge encoded in the ontology/knowledge graph is biased. For example, if it's an ocean water body it cants be a swimming pool. Because well, contrary to common knowledge ocean pools do exist. Or if it's a house it's not a waterbody - because you know lake houses do exist!</p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/47f76ecac3e3bcc2b5b21e30ea10d336.jpeg> <span style=text-align:center;>Ocean Pool/Rock Pool @Mona Vale NSW AU (Image is taken from the internet! @credit: unknown)</span></p> </blockquote> <h3 id=errors-in-labels-are-imperative><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#errors-in-labels-are-imperative>Errors in labels are imperative</a></h3> <p>Given the challenges discussed so far, It is fair to say that errors are imperative. The oracle in this process are labelers and they are only just human!</p> <blockquote> <p>I am <span style=color:red>not perfect</span>; I am only <span style=color:red>human</span></p> </blockquote> <p>Evidently, there is <em>an estimated average of at least 3.3% errors across the 10 popular datasets, where for example label errors comprise at least 6% of the ImageNet validation set</em> <sup><a href="https://arxiv.org/abs/2103.14749">2</a></sup>.</p> <p>Assuming, human labelers will produce a perfectly clean dataset is, well, overreaching to say the least. If one cares, one can employ multiple labelers to reduce the error by removing the noise through consensus. This is a great technique to produce a high-quality dataset but it's also many times more expensive and slow thus impractical as standard modus-operandi. Besides being expensive, this does not guarantee a clean dataset either. This is evident from <a href="https://arxiv.org/abs/2103.14749">Northcutt's NeurIPS 2021</a><sup>[2]</sup> work on analyzing errors in the test set of popular datasets that reported order of hundred samples across popular datasets where an agreement could not be reached on true ground truth despite looking at collating outcomes from labelers (see table 2 in the paper for reference).</p> <p>For the last few years, I have been using model-in-loop to find samples where there are disagreements in the dataset with the models. Some of the other techniques that I have found useful are leveraging loss functions, as called out by Andrej Karpathy! More recently, I have seen a huge benefit of deploying <a href="https://suneeta-mall.github.io/talks/KGC_NY_2022.html">ontology-based violations</a> to find samples that are either a) labeling errors or b) extreme edge cases that we were not aware of (aka out of distribution [OOD] samples). </p> <blockquote class=twitter-tweet><p dir=ltr>When you sort your dataset descending by loss you are guaranteed to find something unexpected, strange and helpful.</p>&mdash; Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/1311884485676294151?ref_src=twsrc%5Etfw">October 2, 2020</a></blockquote> <script async= src="../../../assets/external/platform.twitter.com/widgets.js" charset="utf-8"></script> <p><br></p> <p>However, I realized I have been living in oblivion when I came across project <a href="https://github.com/cleanlab/cleanlab">cleanlab</a> from <a href="https://twitter.com/cgnorthcutt">Northcutt</a>'s group and started digging in a bunch of literature around this exact space! I was excited to uncover all the literature that proposed the tricks and tips I have been using to date without being aware of them. Well no more!! In the following sections, I will cover what I have learned reading through this literature.</p> <h3 id=exactly-what-is-confident-learning><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#exactly-what-is-confident-learning>Exactly, what is Confident learning?</a></h3> <blockquote> <p>All models are wrong, but some are <span style=color:red>useful</span>!</p> </blockquote> <p><a href="https://arxiv.org/abs/1911.00068">Confident learning</a><sup>[1]</sup> (CL) is all about using all the useful information we have at hand to find noise in the dataset and improve the quality of the dataset. It's about using one oracle (the labelers) and testing it using another oracle in the build i.e. the model! At a very high level, this is exactly what we have been more generally calling model-in-the-loop!</p> <blockquote> <p>Learning exists in the context of data, yet notions of confidence typically focus on model predictions, not label quality!<sup><a href="https://arxiv.org/abs/1911.00068">1</a></sup></p> </blockquote> <p><a href="https://arxiv.org/abs/1911.00068">Confident learning</a> (CL) is a class of learning where the focus is to learn well despite some noise in the dataset. This is achieved by accurately and directly characterizing the uncertainty of label noise in the data. The foundation CL depends on is that <code>Label noise is class-conditional, depending only on the latent true class, not the data</code> <sup><a href="https://arxiv.org/abs/1911.00068">1</a></sup>. For instance, a <code>leopard</code> is likely to be mistakenly labeled as a <code>jaguar</code>. This is a very strong argument and in practice untrue. I can argue that the scene (ie the data) has implications for the labeler's decisions. For instance, a dingy sailing in water is less likely to be labeled as a car if it's in water. In other words, would not a dingy being transported in a lorry is more likely to be labeled as a car than when it was sailing on the water? so data and context do matters! <br> This assumption is a classic case of, <code>in statistics any assumption is fair if you can solve for x!</code>. Now that we have taken a dig at this, it's fair to say that this assumption is somewhat true even if not entirely. </p> <p>Another assumption CL makes is that rate of error in the dataset is &lt; &frac12;. This is a fair assumption and is coming from <a href="http://homepages.math.uic.edu/~lreyzin/papers/angluin88b.pdf">Angluin &amp; Laird</a>'s<sup>[3]</sup> proposed method for the class conditional noise process which is used in CL to calculate the joint distribution of noisy and true labels.</p> <p>In <a href="https://arxiv.org/abs/1911.00068">Confident learning</a>, a reasonably well performant model is used to estimate the errors in the dataset. First, the model's prediction is obtained then, using a class-specific threshold setting confident joint distribution matrix is obtained; which is then normalized to obtain an estimation of the error matrix. This estimated error matrix then builds the foundation for dataset pruning, counting, and ranking samples in the dataset.</p> <blockquote> <p>Estimating the joint distribution is challenging as it requires disambiguation of epistemic uncertainty (model-predicted probabilities) from aleatoric uncertainty (noisy labels) but useful because its marginals yield important statistics used in the literature, including latent noise transition rates latent prior of uncorrupted labels, and inverse noise rates. <sup><a href="https://arxiv.org/abs/1911.00068">1</a></sup>.</p> <p><img alt src=../../../resources/data-centric-ai/cleanlab/cl.jpg> <a href="https://arxiv.org/abs/1911.00068">Confident learning</a> in pictures<sup><a href="https://arxiv.org/abs/1911.00068">1</a></sup>.</p> </blockquote> <p>The role of a class-specific threshold is useful to handle variations in model performance for each class. This technique is also helpful to handle collisions in predicted labels. </p> <p>What's great about <a href="https://arxiv.org/abs/1911.00068">Confident learning</a> and <a href="https://github.com/cleanlab/cleanlab">cleanlab</a> (its python implementation of it) is that while it does not propose any groundbreaking algorithm, it has done something that is rarely done. Bring together antecedent works into a very good technical framework that is so powerful that it rightfully questions major datasets that shape the evolution of deep learning. Their work on the <a href="https://arxiv.org/abs/2103.14749">analysis</a> of 10 popular datasets including MNIST is well appreciated. This is also a reminder that we are massively overfitting the entire deep learning landscape to datasets like MNIST, and ImageNet, as they are pretty much, must use the dataset to benchmark and qualify bigger and better algorithms and that, they have at least 3.3% errors if not 20% (as estimated by <a href="https://arxiv.org/abs/2103.14749">Northcutt's group</a>)!</p> <p>This approach was used in side by side comparison where samples were pruned either randomly (shown in orange in below fig) or more strategically via CL to remove noisy samples only (shown in blue below fig). The accuracy results as shown below. CL is doing better than random prune!</p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/cl_result.jpg> Borrowed from <a href="https://arxiv.org/abs/1911.00068">Confident learning</a><sup><a href="https://arxiv.org/abs/1911.00068">1</a></sup></p> </blockquote> <p>Following are an example of some of the samples that CL flags as noisy/erroneous, also including the edge cases where a) neither were true and b) Its either the CL suggestion or provided label but unclear which of the two are correct (non-agreement):</p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/cl_results_image.jpg> Examples of samples corrected using <a href="https://arxiv.org/abs/2103.14749">Confident learning</a><sup><a href="https://arxiv.org/abs/2103.14749">2</a></sup>.</p> </blockquote> <p>CL is not 100% accurate. At the best, it is an effort to estimate noise using an epistemic uncertainty predictor [the model]. Having said that these examples it fails on are quite challenging as well. </p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/fail_cl.jpg> Examples of samples <a href="https://arxiv.org/abs/2103.14749">Confident learning</a> struggled with!<sup><a href="https://arxiv.org/abs/2103.14749">2</a></sup></p> </blockquote> <h4 id=fundamentals><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#fundamentals>Fundamentals</a></h4> <p>Let's look at the fundamentals CL builds on and dig in a bit on the antecedent and related works that formulate the foundation upon which <a href="https://arxiv.org/abs/1911.00068">Confident learning</a>(<a href="https://github.com/cleanlab/cleanlab">cleanlab</a>) is built!</p> <ol> <li> <p>As discussed above already, is class conditional noise proposed by <a href="http://homepages.math.uic.edu/~lreyzin/papers/angluin88b.pdf">Angluin &amp; Laird</a> is the main concept utilized by CL. </p> </li> <li> <p>The use of weighted loss functions to estimate the probability of misclassification, as used in <sup><a href="https://proceedings.neurips.cc/paper/2013/file/3871bd64012152bfb53fdf04b401193f-Paper.pdf">7</a></sup>, is quite relevant to the field of CL, although it's not directly used in the CL technique as proposed by the <a href="https://arxiv.org/abs/1911.00068">Confident learning</a> framework paper. </p> </li> <li> <p>Use of iterative noise cross-validation [INCV] techniques, as proposed in Chen <em>et.</em> al<sup>[8]</sup>, that utilize a model-in-the-loop approach to finding noisy samples. This algorithm is shown below:</p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/INCV.jpg> <a href="https://arxiv.org/abs/1905.05040">Chen</a>'s INCV algorithm</p> </blockquote> </li> <li> <p>CL does not directly use <a href="https://arxiv.org/abs/1712.05055">MentorNet</a><sup>[6]</sup>. However, it is very relatable work that builds on a data-driven training approach. In simplistic terms, there is a teacher network that builds a curriculum of easy to hard samples (derived using loss measures) and the student is trained off this curriculum.</p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/M-Net.jpg> <a href="https://arxiv.org/abs/1712.05055">MentorNet</a> architecture</p> </blockquote> </li> <li> <p>There are other variations to data-driven teaching, one noticeable example is <a href="https://arxiv.org/abs/1804.06872">Co-teaching</a><sup>[9]</sup> which looks to be teaching each other in pairs and passing the non-noisy samples (calculated based on loss measures) to each other during learning. The main issue <a href="https://arxiv.org/abs/1804.06872">Co-teaching</a> tries to solve is the memorization effects that are present in <a href="https://arxiv.org/abs/1712.05055">MentorNet</a><sup>[6]</sup>. (aka M-Net] but not in <a href="https://arxiv.org/abs/1804.06872">Co-teaching</a><sup>[9]</sup> due to data share.</p> <blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/m-d-co-teach.jpg> <a href="https://arxiv.org/abs/1804.06872">Co-teaching</a> approach in contrast with <a href="https://arxiv.org/abs/1712.05055">MentorNet</a> aka M-Net</p> </blockquote> </li> <li> <p>The understanding that small losses are a good indicator of useful samples and highly likely correct samples whereas jumpy, high loss producing samples are, well, interesting! They can be extreme edge cases or out-of-distribution samples or also can indicate wrongness. This only holds for reasonably performant models with abilities at least better than random chance if not more!</p> </li> </ol> <h4 id=limitations-of-cl><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#limitations-of-cl>Limitations of CL</a></h4> <p>One thing that CL entirely ignores about label errors is when one or more true label is entirely missed. This is more likely to happen in multi-label settings and even more complex labeling setting like segmentation or detection than in multi-class classifications. For example, if there is a TV and water bottle in an image and the only annotation present is for the TV, and the water bottle is missed entirely! This is currently not modeled in CL as relies on building a pairwise class-conditional distribution between the given label and the true label. If the given label was a cat but the actual label was the dog for example. The framework itself does not allow it to model for the missing label when a true label is present. </p> <p>Pairwise class-conditional distribution as proposed in CL also limits its use in multi-label settings. Explicitly when multiple labels can co-exist on the same data. For example, both the roof and swimming pool can be present in the image and they are not necessarily exclusive. This limitation comes from pairwise (single class gives vs single class predicted) modeling. This is different from say <a href="http://ai.stanford.edu/~jkrause/cars/car_dataset.html">Stanford Car Dataset</a> where make and model are predicted as multiple labels but they are exclusive ie a vehicle can be ute or hatchback but that is exclusive to it being made by Toyota or Volvo. Exclusivity in this case allows for modeling Pairwise class-conditional distribution. These are more multi-label multi-class modeled using multi-headed networks. True multi-label datasets can't be modeled like these pairwise joint distributions. They can perhaps be modeled using more complex joint distribution formulations but that would not scale very well. <a href="https://arxiv.org/abs/1911.00068">Confident learning</a><sup>[1]</sup> as it stands currently is a computationally expensive algorithm with an order of complexity being O(m2 + nm). </p> <p>Having said these, it is probably something that is not explained in the literature as it seems that <a href="https://github.com/cleanlab/cleanlab">cleanlab</a> itself supports multi-label classification. Conceptually I am unclear how multi-label works given the said theory. The support for multi-label is developing as issues are being addressed on this tool <a href="https://github.com/cleanlab/cleanlab/issues/263">1</a>,<a href="https://github.com/cleanlab/cleanlab/issues/55">2</a>.</p> <h3 id=hands-on-of-label-noise-analysis-using-cleanlab-for-multi-label-classification><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#hands-on-of-label-noise-analysis-using-cleanlab-for-multi-label-classification>Hands on of label noise analysis using cleanlab for multi-label classification</a></h3> <p>Now that we have covered the background and theoretical foundations, let's try the <a href="https://arxiv.org/abs/1911.00068">confident learning</a> out in detecting label noise using its implementation <a href="https://github.com/cleanlab/cleanlab">cleanlab</a>. Specifically, I will use multi-label classification given the uncertainty around it (as discussed above)!. For this hands-on, I will use <a href="https://paperswithcode.com/dataset/mlrsnet">MLRSNet</a> dataset. This spike is built using ResNet as a multi-label image classifier predicting 6 classes that can co-exist at the same time. These classes are <code>['airplane', 'airport', 'buildings', 'cars', 'runway', 'trees']</code> and derived off <a href="https://paperswithcode.com/dataset/mlrsnet">MLRSNet</a> subset - i.e. only using <code>airplane</code> and <code>airport</code>.</p> <p>The source code and <a href="https://github.com/suneeta-mall/label_noise/blob/master/label_noise_notebook.ipynb">this notebook</a> for this project is <a href="https://github.com/suneeta-mall/label-noise">label-noise</a> Github repository. <a href="https://github.com/suneeta-mall/label_noise/blob/master/label_noise_notebook.ipynb">The notebook</a> checks how well <a href="https://github.com/cleanlab/cleanlab">cleanlab</a> performs in detecting label noise and identifies out-of-distribution samples, weird samples, and also errors!</p> <h4 id=model-info><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#model-info>Model info</a></h4> <p>Train and validation loss from the model trained using <a href="https://github.com/suneeta-mall/label-noise">label-noise</a> for 19 epochs. Note, for this spike, I opted out of n-fold cross-validation (CV). Using CV can lead to better results but its a not quick.</p> <p><img alt src=../../../resources/data-centric-ai/cleanlab/model_measures.jpg></p> <blockquote> <p>Training logs for the model used in this exercise (Image provided by author)</p> </blockquote> <h4 id=exploration-in-noise-using-cleanlab><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#exploration-in-noise-using-cleanlab>Exploration in noise using cleanlab</a></h4> <p>As shown in <a href="https://github.com/suneeta-mall/label_noise/blob/master/label_noise_notebook.ipynb">this notebook</a>, the filter approach provided a list of samples that were deemed noisy. This flagged 38% of out-of-samples as noisy/erroneous. </p> <p>Ranking provided an order in the samples on a 0-1 scale for label quality, the higher the number, the better quality the sample. I looked in <code>get_self_confidence_for_each_label</code> approach for out-of-distribution (OOD) samples and also entropy-based ordering. The distribution for each is as follows:</p> <p><img alt src=../../../resources/data-centric-ai/cleanlab/rank_entropy.jpg></p> <blockquote> <p>Confidance order of entropy-based ordering</p> </blockquote> <p><img alt src=../../../resources/data-centric-ai/cleanlab/rank_self_confidance.jpg></p> <blockquote> <p>Confidance order of self_confidence ordering</p> </blockquote> <p>The samples picked as lowest quality or confidence is indeed rightfully chosen. There is an airplane that was missed in the image (shown in the highlighted overlay) and also another sample is OOD! <img alt src=../../../resources/data-centric-ai/cleanlab/Errors_flagged_in_ranking.jpg></p> <p>What's more interesting is all three methods of filtering, ranked by self-confidence and entropy all flagged these two samples! So we increase the threshold, and while there are false positives (for noise) there is some good example of errors.</p> <table> <thead> <tr> <th>False Positive</th> <th>True Positive</th> </tr> </thead> <tbody> <tr> <td><img alt src=../../../resources/data-centric-ai/cleanlab/fp_cl.jpg></td> <td><img alt src=../../../resources/data-centric-ai/cleanlab/Increasing_threshold_error.jpg></td> </tr> </tbody> </table> <p>I am not sure if I am following how to interpret the <a href="https://github.com/cleanlab/cleanlab/issues/263">pair-wise count for multi-label</a>, so that's left for another day!</p> <h3 id=conclusion><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#conclusion>Conclusion</a></h3> <p>As discussed in this post, there are several reasons why label errors are unavoidable. While no small-efforts are required to minimize the errors in the dataset, management of the errors in the dataset is also warranted. The management to find noisy data, out of distribution data, or data that represents a systematic flaw (software/tooling issues or issues in the understanding of a concept that defines the target class). Approaches like model-in-loop, or additional information like ontology to find such noises or errors in the dataset are effective techniques. Confident learning provides a solid foundation for analyzing a dataset of noisy or OOD samples â€” a technique that's quite effective for multi-class approaches, with the evolving support for multi-label classification. Now, on to cleaning the dataset! Happy cleaning!</p> <h3 id=references><a class=toclink href=../../2022/05/16/confident-learning-and-clean-data/#references>References</a></h3> <ol> <li>C. G. Northcutt, L. Jiang, and I. Chuang. Confident learning: Estimating uncertainty in dataset labels. Journal of Artificial Intelligence Research, 70:1373â€“1411, 2021. <a href="https://arxiv.org/abs/1911.00068">1911.00068</a></li> <li>Northcutt, C. G., Athalye, A., and Mueller, J. (2021). Pervasive label errors in test sets destabilize machine learning benchmarks. In International Conference on Learning Representations Workshop Track (ICLR). <a href="https://arxiv.org/abs/2103.14749">2103.14749</a></li> <li>D. Angluin and P. Laird. Learning from noisy examples. Machine Learning, 2(4):343â€“370, 1988. <a href="http://homepages.math.uic.edu/~lreyzin/papers/angluin88b.pdf">link</a></li> <li>Crowley RS, Legowski E, Medvedeva O, Reitmeyer K, Tseytlin E, Castine M, Jukic D, Mello-Thoms C. Automated detection of heuristics and biases among pathologists in a computer-based system. Adv Health Sci Educ Theory Pract. 2013 Aug;18(3):343-63. doi: 10.1007/s10459-012-9374-z. Epub 2012 May 23. PMID: 22618855; PMCID: PMC3728442. <a href="https://pubmed.ncbi.nlm.nih.gov/22618855/">link</a></li> <li>Huan Ling and Jun Gao and Amlan Kar and Wenzheng Chen and Sanja Fidler, Fast Interactive Object Annotation with Curve-GCN. CVPR, 2019 <a href="https://arxiv.org/abs/1903.06874">link</a></li> <li>Jiang, L., Zhou, Z., Leung, T., Li, L.-J., and Fei-Fei, L. (2018). Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In International Conference on Machine Learning (ICML).<a href="https://arxiv.org/abs/1712.05055">1712.05055</a>.</li> <li>N. Natarajan, I. S. Dhillon, P. K. Ravikumar, and A. Tewari. Learning with noisy labels. In Conference on Neural Information Processing Systems (NeurIPS), pages 1196â€“1204, 2013. <a href="https://proceedings.neurips.cc/paper/2013/file/3871bd64012152bfb53fdf04b401193f-Paper.pdf">NurIPS 2013</a></li> <li>P. Chen, B. B. Liao, G. Chen, and S. Zhang. Understanding and utilizing deep neural networks trained with noisy labels. In International Conference on Machine Learning (ICML), 2019.<a href="https://arxiv.org/abs/1905.05040">1905.05040</a></li> <li>Han, B., Yao, Q., Yu, X., Niu, G., Xu, M., Hu, W., Tsang, I., and Sugiyama, M. (2018). Co-teaching: Robust training of deep neural networks with extremely noisy labels. In Conference on Neural Information Processing Systems (NeurIPS). <a href="https://arxiv.org/abs/1804.06872">1804.06872</a></li> </ol> </div> </article> <nav class=md-pagination> </nav> </div> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../childrens-books/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Children's Books"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Children's Books </div> </div> </a> <a href=../curious-cassie/ class="md-footer__link md-footer__link--next" aria-label="Next: Curious Cassie"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Curious Cassie </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> </div> <div class=md-social> <a href="https://www.linkedin.com/in/suneeta-mall-a6a0507/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href="https://github.com/suneeta-mall" target="_blank" rel="noopener" title="github.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href="https://x.com/suneetamall/" target="_blank" rel="noopener" title="x.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9L389.2 48zm-24.8 373.8h39.1L151.1 88h-42l255.3 333.8z"/></svg> </a> <a href="https://www.medium.com/@suneetamall" target="_blank" rel="noopener" title="www.medium.com" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M180.5 74.262C80.813 74.262 0 155.633 0 256s80.819 181.738 180.5 181.738S361 356.373 361 256 280.191 74.262 180.5 74.262Zm288.25 10.646c-49.845 0-90.245 76.619-90.245 171.095s40.406 171.1 90.251 171.1 90.251-76.619 90.251-171.1H559c0-94.503-40.4-171.095-90.248-171.095Zm139.506 17.821c-17.526 0-31.735 68.628-31.735 153.274s14.2 153.274 31.735 153.274S640 340.631 640 256c0-84.649-14.215-153.271-31.742-153.271Z"/></svg> </a> <a href="https://scholar.google.com.au/citations?hl=en&amp;user=WD712CUAAAAJ" target="_blank" rel="noopener" title="scholar.google.com.au" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M390.9 298.5s0 .1.1.1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64 1.7-3.6 3.6-7.2 5.6-10.7 4.4-7.6 9.4-14.7 15-21.3 27.4-32.6 68.5-53.3 114.4-53.3 33.6 0 64.6 11.1 89.6 29.9 9.1 6.9 17.4 14.7 24.8 23.5 5.6 6.6 10.6 13.8 15 21.3 2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0l256 202.7-94.7 77.1z"/></svg> </a> <a href="https://www.researchgate.net/profile/Suneeta_Mall3" target="_blank" rel="noopener" title="www.researchgate.net" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 32v448h448V32H0zm262.2 334.4c-6.6 3-33.2 6-50-14.2-9.2-10.6-25.3-33.3-42.2-63.6-8.9 0-14.7 0-21.4-.6v46.4c0 23.5 6 21.2 25.8 23.9v8.1c-6.9-.3-23.1-.8-35.6-.8-13.1 0-26.1.6-33.6.8v-8.1c15.5-2.9 22-1.3 22-23.9V225c0-22.6-6.4-21-22-23.9V193c25.8 1 53.1-.6 70.9-.6 31.7 0 55.9 14.4 55.9 45.6 0 21.1-16.7 42.2-39.2 47.5 13.6 24.2 30 45.6 42.2 58.9 7.2 7.8 17.2 14.7 27.2 14.7v7.3zm22.9-135c-23.3 0-32.2-15.7-32.2-32.2V167c0-12.2 8.8-30.4 34-30.4s30.4 17.9 30.4 17.9l-10.7 7.2s-5.5-12.5-19.7-12.5c-7.9 0-19.7 7.3-19.7 19.7v26.8c0 13.4 6.6 23.3 17.9 23.3 14.1 0 21.5-10.9 21.5-26.8h-17.9v-10.7h30.4c0 20.5 4.7 49.9-34 49.9zm-116.5 44.7c-9.4 0-13.6-.3-20-.8v-69.7c6.4-.6 15-.6 22.5-.6 23.3 0 37.2 12.2 37.2 34.5 0 21.9-15 36.6-39.7 36.6z"/></svg> </a> <a href="https://suneeta-mall.github.io/feed_rss_created.xml" target="_blank" rel="noopener" title="suneeta-mall.github.io" class="md-social__link"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 64c0-17.7 14.3-32 32-32 229.8 0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7 0 64zm0 352a64 64 0 1 1 128 0 64 64 0 1 1-128 0zm32-256c159.1 0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7 0-32-14.3-32-32s14.3-32 32-32z"/></svg> </a> <a href=mailto:suneetamall@gmail.com target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l217.6 163.2c11.4 8.5 27 8.5 38.4 0l217.6-163.2c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48H48zM0 176v208c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V176L294.4 339.2a63.9 63.9 0 0 1-76.8 0L0 176z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "content.tabs.link", "navigation.indexes", "navigation.instant", "navigation.instant.preview", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "toc.follow", "header.autohide", "announce.dismiss", "navigation.footer", "navigation.breadcrumbs", "navigation.expand", "navigation.sections", "navigation.tracking", "navigation.top", "search.highlight", "search.share", "toc.follow", "toc.integrate", {"git-revision-date-localized": {"enable_creation_date": true, "type": "date"}}], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../../assets/javascripts/bundle.3220b9d7.min.js></script> </body> </html>